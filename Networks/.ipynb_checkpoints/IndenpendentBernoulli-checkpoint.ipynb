{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 1\n"
     ]
    }
   ],
   "source": [
    "from Utils.loadset import getDataSet\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "tfpl = tfp.layers\n",
    "tfd = tfp.distributions\n",
    "import os\n",
    "from trainer import Trainer\n",
    "try:\n",
    "    from Utils.connection_cfg import *\n",
    "except Exception as e:\n",
    "    PSWD = None\n",
    "    USRN = None\n",
    "    \n",
    "from Utils.Data import dataWrapper\n",
    "from Utils.transform import Binarize\n",
    "\n",
    "dimension = (64,64)\n",
    "channels = 5\n",
    "optimizer = Adam( lr = 1e-5 )\n",
    "tfd = tfp.distributions\n",
    "\n",
    "def NLL(y_true, y_hat):\n",
    "    return -y_hat.log_prob(y_true)\n",
    "\n",
    "def mixd(output):\n",
    "    rate = tf.math.exp(output[0,:,:,0]) #A \n",
    "    s = tf.math.sigmoid(output[0,:,:,1])\n",
    "    components = [tfd.Deterministic(loc=tf.zeros_like(rate)), #E\n",
    "     tfd.Poisson(rate=rate) #F \n",
    "     ]\n",
    "    mixture = tfd.Mixture(\n",
    "          cat=tfd.Categorical(probs=tf.stack([1-s, s],axis=-1)),#D\n",
    "          components=components)\n",
    "    \n",
    "    return mixture\n",
    "    \n",
    "def testnetBernoulli(input_shape,\n",
    "           n_predictions=1,\n",
    "           simpleclassification=None,\n",
    "           flatten_output=False,\n",
    "           activation_hidden=\"relu\",\n",
    "           activation_output=\"relu\"):\n",
    "\n",
    "\n",
    "    inputs = Input(shape=input_shape) \n",
    "\n",
    "    conv01 = Conv2D(10, kernel_size=(3, 3), padding=\"same\")(inputs)       # 10 x 64x64\n",
    "    conv01 = Activation(activation_hidden)(conv01)\n",
    "    conv01_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv01)            # 10 x 32x32\n",
    "\n",
    "\n",
    "    conv02 = Conv2D(20, kernel_size=(3, 3), padding=\"same\")(conv01_pool)  # 20 x 32x32\n",
    "    conv02 = Activation(activation_hidden)(conv02)\n",
    "    conv02_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv02)            # 20 x 16x16\n",
    "\n",
    "\n",
    "    conv03 = Conv2D(20, kernel_size=(3, 3), padding=\"same\")(conv02_pool)  # 20 x 16x16\n",
    "    conv03 = Activation(activation_hidden)(conv03)\n",
    "    conv03_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv03)            # 20 x 8x8\n",
    "\n",
    "\n",
    "    conv04 = Conv2D(20, kernel_size=(3, 3), padding=\"same\")(conv03_pool)  # 20 x 8x8\n",
    "    conv04 = Activation(activation_hidden)(conv04)\n",
    "    conv04_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv04)            # 20 x 4x4\n",
    "\n",
    "\n",
    "    ### UPSAMPLING:\n",
    "    up04 = UpSampling2D((2, 2))(conv04_pool)    # 20 x 8x8\n",
    "    up04 = concatenate([conv04, up04], axis=3)  # 20+20 x 8x8\n",
    "\n",
    "\n",
    "    up03 = UpSampling2D((2, 2))(up04)           # 40 x 16x16\n",
    "    up03 = concatenate([conv03, up03], axis=3)  # 20+40 x 16x16\n",
    "\n",
    "\n",
    "    up02 = UpSampling2D((2, 2))(up03)           # 60 x 32x32\n",
    "    up02 = concatenate([conv02, up02], axis=3)  # 20+60 x 32x32\n",
    "\n",
    "\n",
    "    up01 = UpSampling2D((2, 2))(up02)           # 80 x 64x64\n",
    "    up01 = concatenate([conv01, up01], axis=3)  # 10+80 x 64x64\n",
    "\n",
    "\n",
    "    output = Conv2D(1, (1, 1), activation=tf.exp)(up01)  # 1 x 64x64\n",
    "    #output = tfkl.Flatten()(output)\n",
    "    output = tfpl.IndependentBernoulli((1), tfd.Bernoulli.logits)(output)\n",
    "    #outpus = tfd.Independent(tfd.Poisson(),name=\"image\")(output)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "def provideData(flatten=False,dimension=dimension,batch_size=10,transform=None,preTransformation=None):\n",
    "\n",
    "    getDataSet(DatasetFolder,year=[2017],username=USRN,pswd=PSWD)\n",
    "    train,test = dataWrapper(PathToData,\n",
    "                            dimension=dimension,\n",
    "                            channels=channels,\n",
    "                            batch_size=batch_size,\n",
    "                            overwritecsv=True,\n",
    "                            flatten=flatten,\n",
    "                            onlyUseYears=[2017],\n",
    "                            transform=transform,\n",
    "                            preTransformation=preTransformation)\n",
    "    \n",
    "    return train,test\n",
    "DatasetFolder = \"./Data/RAW\"\n",
    "PathToData = os.path.join(DatasetFolder,\"MonthPNGData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mFound Year \u001b[0m:  2017 => won't download this year again... please check for consistency\n",
      "\u001b[32mFinished Loading Dataset\n",
      " \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train, test = provideData(flatten=False,dimension=dimension,batch_size=1,transform=[Binarize()],preTransformation=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Load file failed]  ./model_data/testnetBernoulli_function/testnetBernoulli_function64x64x5.h5\n",
      "[Load file failed]  ./model_data/testnetBernoulli_function/testnetBernoulli_function64x64x5history.json\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 64, 5)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 10)   460         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 10)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 10)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 20)   1820        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 20)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 20)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 20)   3620        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 16, 16, 20)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 20)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 20)     3620        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 8, 8, 20)     0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 20)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 8, 8, 20)     0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 40)     0           activation_3[0][0]               \n",
      "                                                                 up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 40)   0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 60)   0           activation_2[0][0]               \n",
      "                                                                 up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 60)   0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 80)   0           activation_1[0][0]               \n",
      "                                                                 up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 80)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 90)   0           activation[0][0]                 \n",
      "                                                                 up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 1)    91          concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "independent_bernoulli (Independ ((None, 64, 64, 1),  0           conv2d_4[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 9,611\n",
      "Trainable params: 9,611\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "len train,val 10 10\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 10 steps, validate for 10 steps\n",
      "Epoch 1/2000\n",
      "10/10 [==============================] - 2s 209ms/step - loss: 82.4056 - mse: 0.9767 - mae: 0.9749 - val_loss: 74.4316 - val_mse: 0.8670 - val_mae: 0.8576\n",
      "Epoch 2/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 82.4168 - mse: 0.9754 - mae: 0.9748 - val_loss: 74.4004 - val_mse: 0.8638 - val_mae: 0.8564\n",
      "Epoch 3/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 82.3295 - mse: 0.9730 - mae: 0.9732 - val_loss: 74.2369 - val_mse: 0.8582 - val_mae: 0.8532\n",
      "Epoch 4/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 82.2963 - mse: 0.9712 - mae: 0.9724 - val_loss: 74.1856 - val_mse: 0.8540 - val_mae: 0.8517\n",
      "Epoch 5/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 82.2681 - mse: 0.9693 - mae: 0.9716 - val_loss: 74.0236 - val_mse: 0.8484 - val_mae: 0.8485\n",
      "Epoch 6/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 82.1719 - mse: 0.9668 - mae: 0.9700 - val_loss: 73.9923 - val_mse: 0.8449 - val_mae: 0.8474\n",
      "Epoch 7/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 82.1657 - mse: 0.9652 - mae: 0.9696 - val_loss: 73.8574 - val_mse: 0.8397 - val_mae: 0.8447\n",
      "Epoch 8/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 82.1176 - mse: 0.9633 - mae: 0.9686 - val_loss: 73.7397 - val_mse: 0.8346 - val_mae: 0.8422\n",
      "Epoch 9/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 82.0480 - mse: 0.9609 - mae: 0.9672 - val_loss: 73.6904 - val_mse: 0.8309 - val_mae: 0.8410\n",
      "Epoch 10/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 82.0261 - mse: 0.9593 - mae: 0.9666 - val_loss: 73.5303 - val_mse: 0.8252 - val_mae: 0.8379\n",
      "Epoch 11/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 81.9869 - mse: 0.9573 - mae: 0.9657 - val_loss: 73.4863 - val_mse: 0.8215 - val_mae: 0.8367\n",
      "Epoch 12/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 81.9148 - mse: 0.9548 - mae: 0.9643 - val_loss: 73.3583 - val_mse: 0.8163 - val_mae: 0.8342\n",
      "Epoch 13/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 81.8786 - mse: 0.9529 - mae: 0.9635 - val_loss: 73.2437 - val_mse: 0.8114 - val_mae: 0.8319\n",
      "Epoch 14/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 81.8192 - mse: 0.9506 - mae: 0.9623 - val_loss: 73.1441 - val_mse: 0.8065 - val_mae: 0.8299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 81.7626 - mse: 0.9483 - mae: 0.9611 - val_loss: 72.9992 - val_mse: 0.8011 - val_mae: 0.8272\n",
      "Epoch 16/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 81.7090 - mse: 0.9460 - mae: 0.9600 - val_loss: 72.9496 - val_mse: 0.7967 - val_mae: 0.8258\n",
      "Epoch 17/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 81.6585 - mse: 0.9437 - mae: 0.9589 - val_loss: 72.7647 - val_mse: 0.7906 - val_mae: 0.8226\n",
      "Epoch 18/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 81.5835 - mse: 0.9410 - mae: 0.9574 - val_loss: 72.7152 - val_mse: 0.7863 - val_mae: 0.8213\n",
      "Epoch 19/2000\n",
      "10/10 [==============================] - ETA: 0s - loss: 81.4511 - mse: 0.9384 - mae: 0.95 - 0s 10ms/step - loss: 81.5689 - mse: 0.9393 - mae: 0.9569 - val_loss: 72.5553 - val_mse: 0.7801 - val_mae: 0.8183\n",
      "Epoch 20/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 81.4695 - mse: 0.9361 - mae: 0.9550 - val_loss: 72.4260 - val_mse: 0.7748 - val_mae: 0.8159\n",
      "Epoch 21/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 81.4647 - mse: 0.9344 - mae: 0.9546 - val_loss: 72.3077 - val_mse: 0.7689 - val_mae: 0.8136\n",
      "Epoch 22/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 81.3644 - mse: 0.9312 - mae: 0.9527 - val_loss: 72.1745 - val_mse: 0.7634 - val_mae: 0.8111\n",
      "Epoch 23/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 81.2805 - mse: 0.9281 - mae: 0.9510 - val_loss: 72.0003 - val_mse: 0.7568 - val_mae: 0.8079\n",
      "Epoch 24/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 81.2344 - mse: 0.9258 - mae: 0.9500 - val_loss: 71.9205 - val_mse: 0.7512 - val_mae: 0.8060\n",
      "Epoch 25/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 81.1656 - mse: 0.9230 - mae: 0.9486 - val_loss: 71.7491 - val_mse: 0.7450 - val_mae: 0.8030\n",
      "Epoch 26/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 81.1087 - mse: 0.9201 - mae: 0.9472 - val_loss: 71.5648 - val_mse: 0.7377 - val_mae: 0.7996\n",
      "Epoch 27/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 81.0299 - mse: 0.9172 - mae: 0.9457 - val_loss: 71.4402 - val_mse: 0.7317 - val_mae: 0.7972\n",
      "Epoch 28/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 80.9681 - mse: 0.9142 - mae: 0.9443 - val_loss: 71.2803 - val_mse: 0.7248 - val_mae: 0.7941\n",
      "Epoch 29/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 80.8848 - mse: 0.9111 - mae: 0.9426 - val_loss: 71.1154 - val_mse: 0.7178 - val_mae: 0.7910\n",
      "Epoch 30/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 80.8078 - mse: 0.9079 - mae: 0.9410 - val_loss: 70.9762 - val_mse: 0.7112 - val_mae: 0.7882\n",
      "Epoch 31/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 80.7401 - mse: 0.9047 - mae: 0.9395 - val_loss: 70.7682 - val_mse: 0.7033 - val_mae: 0.7844\n",
      "Epoch 32/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 80.6399 - mse: 0.9008 - mae: 0.9374 - val_loss: 70.5803 - val_mse: 0.6956 - val_mae: 0.7808\n",
      "Epoch 33/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 80.5771 - mse: 0.8978 - mae: 0.9360 - val_loss: 70.3736 - val_mse: 0.6878 - val_mae: 0.7771\n",
      "Epoch 34/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 80.4743 - mse: 0.8940 - mae: 0.9339 - val_loss: 70.2395 - val_mse: 0.6808 - val_mae: 0.7740\n",
      "Epoch 35/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 80.3898 - mse: 0.8903 - mae: 0.9321 - val_loss: 69.9829 - val_mse: 0.6719 - val_mae: 0.7695\n",
      "Epoch 36/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 80.2967 - mse: 0.8861 - mae: 0.9300 - val_loss: 69.7950 - val_mse: 0.6639 - val_mae: 0.7659\n",
      "Epoch 37/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 80.2312 - mse: 0.8830 - mae: 0.9285 - val_loss: 69.6101 - val_mse: 0.6559 - val_mae: 0.7621\n",
      "Epoch 38/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 80.0662 - mse: 0.8773 - mae: 0.9253 - val_loss: 69.3814 - val_mse: 0.6471 - val_mae: 0.7575\n",
      "Epoch 39/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 79.9803 - mse: 0.8736 - mae: 0.9234 - val_loss: 69.1194 - val_mse: 0.6379 - val_mae: 0.7528\n",
      "Epoch 40/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 79.8938 - mse: 0.8693 - mae: 0.9214 - val_loss: 68.9414 - val_mse: 0.6304 - val_mae: 0.7492\n",
      "Epoch 41/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 79.7669 - mse: 0.8647 - mae: 0.9189 - val_loss: 68.7102 - val_mse: 0.6210 - val_mae: 0.7445\n",
      "Epoch 42/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 79.6467 - mse: 0.8596 - mae: 0.9163 - val_loss: 68.4416 - val_mse: 0.6114 - val_mae: 0.7393\n",
      "Epoch 43/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 79.5966 - mse: 0.8562 - mae: 0.9149 - val_loss: 68.1941 - val_mse: 0.6021 - val_mae: 0.7344\n",
      "Epoch 44/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 79.3759 - mse: 0.8488 - mae: 0.9105 - val_loss: 67.9284 - val_mse: 0.5926 - val_mae: 0.7292\n",
      "Epoch 45/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 79.2469 - mse: 0.8438 - mae: 0.9079 - val_loss: 67.6744 - val_mse: 0.5831 - val_mae: 0.7242\n",
      "Epoch 46/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 79.1575 - mse: 0.8390 - mae: 0.9056 - val_loss: 67.3999 - val_mse: 0.5733 - val_mae: 0.7186\n",
      "Epoch 47/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 78.9800 - mse: 0.8327 - mae: 0.9021 - val_loss: 67.1153 - val_mse: 0.5632 - val_mae: 0.7129\n",
      "Epoch 48/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 78.8762 - mse: 0.8274 - mae: 0.8996 - val_loss: 66.8203 - val_mse: 0.5533 - val_mae: 0.7072\n",
      "Epoch 49/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 78.6979 - mse: 0.8208 - mae: 0.8959 - val_loss: 66.5502 - val_mse: 0.5436 - val_mae: 0.7014\n",
      "Epoch 50/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 78.5402 - mse: 0.8144 - mae: 0.8925 - val_loss: 66.2824 - val_mse: 0.5340 - val_mae: 0.6956\n",
      "Epoch 51/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 78.4208 - mse: 0.8091 - mae: 0.8898 - val_loss: 65.9400 - val_mse: 0.5232 - val_mae: 0.6892\n",
      "Epoch 52/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 78.1736 - mse: 0.8005 - mae: 0.8848 - val_loss: 65.6422 - val_mse: 0.5135 - val_mae: 0.6827\n",
      "Epoch 53/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 78.0261 - mse: 0.7938 - mae: 0.8814 - val_loss: 65.3430 - val_mse: 0.5035 - val_mae: 0.6766\n",
      "Epoch 54/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 77.8482 - mse: 0.7867 - mae: 0.8775 - val_loss: 65.0475 - val_mse: 0.4936 - val_mae: 0.6704\n",
      "Epoch 55/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 77.6700 - mse: 0.7799 - mae: 0.8737 - val_loss: 64.7083 - val_mse: 0.4835 - val_mae: 0.6632\n",
      "Epoch 56/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 77.4727 - mse: 0.7717 - mae: 0.8693 - val_loss: 64.3636 - val_mse: 0.4730 - val_mae: 0.6562\n",
      "Epoch 57/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 77.2527 - mse: 0.7638 - mae: 0.8648 - val_loss: 64.0837 - val_mse: 0.4638 - val_mae: 0.6499\n",
      "Epoch 58/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 77.0796 - mse: 0.7562 - mae: 0.8607 - val_loss: 63.7187 - val_mse: 0.4534 - val_mae: 0.6423\n",
      "Epoch 59/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 76.8614 - mse: 0.7482 - mae: 0.8562 - val_loss: 63.3289 - val_mse: 0.4422 - val_mae: 0.6340\n",
      "Epoch 60/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 76.6086 - mse: 0.7385 - mae: 0.8507 - val_loss: 63.0489 - val_mse: 0.4339 - val_mae: 0.6279\n",
      "Epoch 61/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 76.4413 - mse: 0.7314 - mae: 0.8468 - val_loss: 62.7627 - val_mse: 0.4257 - val_mae: 0.6216\n",
      "Epoch 62/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 76.1481 - mse: 0.7205 - mae: 0.8405 - val_loss: 62.3058 - val_mse: 0.4134 - val_mae: 0.6119\n",
      "Epoch 63/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 10ms/step - loss: 75.8884 - mse: 0.7113 - mae: 0.8351 - val_loss: 62.0531 - val_mse: 0.4065 - val_mae: 0.6066\n",
      "Epoch 64/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 75.7007 - mse: 0.7030 - mae: 0.8305 - val_loss: 61.6712 - val_mse: 0.3960 - val_mae: 0.5975\n",
      "Epoch 65/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 75.4360 - mse: 0.6937 - mae: 0.8250 - val_loss: 61.3283 - val_mse: 0.3871 - val_mae: 0.5898\n",
      "Epoch 66/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 75.1389 - mse: 0.6823 - mae: 0.8183 - val_loss: 60.9362 - val_mse: 0.3776 - val_mae: 0.5820\n",
      "Epoch 67/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 74.8667 - mse: 0.6720 - mae: 0.8122 - val_loss: 60.6259 - val_mse: 0.3691 - val_mae: 0.5740\n",
      "Epoch 68/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 74.5837 - mse: 0.6618 - mae: 0.8061 - val_loss: 60.2573 - val_mse: 0.3605 - val_mae: 0.5659\n",
      "Epoch 69/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 74.2930 - mse: 0.6511 - mae: 0.7996 - val_loss: 59.8802 - val_mse: 0.3517 - val_mae: 0.5581\n",
      "Epoch 70/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 74.0268 - mse: 0.6412 - mae: 0.7937 - val_loss: 59.5631 - val_mse: 0.3440 - val_mae: 0.5498\n",
      "Epoch 71/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 73.6624 - mse: 0.6284 - mae: 0.7857 - val_loss: 59.1727 - val_mse: 0.3354 - val_mae: 0.5419\n",
      "Epoch 72/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 73.4246 - mse: 0.6189 - mae: 0.7800 - val_loss: 58.8467 - val_mse: 0.3277 - val_mae: 0.5337\n",
      "Epoch 73/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 73.0924 - mse: 0.6076 - mae: 0.7728 - val_loss: 58.4926 - val_mse: 0.3203 - val_mae: 0.5256\n",
      "Epoch 74/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 72.7149 - mse: 0.5945 - mae: 0.7644 - val_loss: 58.1556 - val_mse: 0.3127 - val_mae: 0.5174\n",
      "Epoch 75/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 72.4529 - mse: 0.5845 - mae: 0.7582 - val_loss: 57.8027 - val_mse: 0.3054 - val_mae: 0.5094\n",
      "Epoch 76/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 72.1394 - mse: 0.5739 - mae: 0.7514 - val_loss: 57.4812 - val_mse: 0.2987 - val_mae: 0.5018\n",
      "Epoch 77/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 71.7173 - mse: 0.5592 - mae: 0.7417 - val_loss: 57.1136 - val_mse: 0.2918 - val_mae: 0.4934\n",
      "Epoch 78/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 71.4998 - mse: 0.5512 - mae: 0.7366 - val_loss: 56.7824 - val_mse: 0.2846 - val_mae: 0.4848\n",
      "Epoch 79/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 70.9827 - mse: 0.5346 - mae: 0.7252 - val_loss: 56.4668 - val_mse: 0.2793 - val_mae: 0.4782\n",
      "Epoch 80/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 70.7781 - mse: 0.5267 - mae: 0.7202 - val_loss: 56.1293 - val_mse: 0.2729 - val_mae: 0.4700\n",
      "Epoch 81/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 70.2443 - mse: 0.5101 - mae: 0.7085 - val_loss: 55.7602 - val_mse: 0.2655 - val_mae: 0.4603\n",
      "Epoch 82/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 70.0110 - mse: 0.5014 - mae: 0.7027 - val_loss: 55.5441 - val_mse: 0.2619 - val_mae: 0.4553\n",
      "Epoch 83/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 69.5217 - mse: 0.4859 - mae: 0.6916 - val_loss: 55.1126 - val_mse: 0.2544 - val_mae: 0.4452\n",
      "Epoch 84/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 69.2329 - mse: 0.4759 - mae: 0.6846 - val_loss: 54.9192 - val_mse: 0.2510 - val_mae: 0.4402\n",
      "Epoch 85/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 68.8581 - mse: 0.4642 - mae: 0.6761 - val_loss: 54.4950 - val_mse: 0.2439 - val_mae: 0.4300\n",
      "Epoch 86/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 68.4472 - mse: 0.4511 - mae: 0.6665 - val_loss: 54.3013 - val_mse: 0.2408 - val_mae: 0.4252\n",
      "Epoch 87/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 68.0524 - mse: 0.4386 - mae: 0.6572 - val_loss: 53.9695 - val_mse: 0.2351 - val_mae: 0.4166\n",
      "Epoch 88/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 67.7498 - mse: 0.4290 - mae: 0.6501 - val_loss: 53.6731 - val_mse: 0.2306 - val_mae: 0.4096\n",
      "Epoch 89/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 67.2402 - mse: 0.4142 - mae: 0.6386 - val_loss: 53.4003 - val_mse: 0.2265 - val_mae: 0.4028\n",
      "Epoch 90/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 66.8425 - mse: 0.4019 - mae: 0.6289 - val_loss: 53.1077 - val_mse: 0.2218 - val_mae: 0.3955\n",
      "Epoch 91/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 66.5026 - mse: 0.3915 - mae: 0.6208 - val_loss: 52.8501 - val_mse: 0.2183 - val_mae: 0.3892\n",
      "Epoch 92/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 66.1712 - mse: 0.3813 - mae: 0.6128 - val_loss: 52.5328 - val_mse: 0.2136 - val_mae: 0.3811\n",
      "Epoch 93/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 65.6875 - mse: 0.3678 - mae: 0.6015 - val_loss: 52.3292 - val_mse: 0.2108 - val_mae: 0.3759\n",
      "Epoch 94/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 65.3276 - mse: 0.3573 - mae: 0.5928 - val_loss: 52.1140 - val_mse: 0.2076 - val_mae: 0.3700\n",
      "Epoch 95/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 64.9167 - mse: 0.3456 - mae: 0.5828 - val_loss: 51.8037 - val_mse: 0.2039 - val_mae: 0.3629\n",
      "Epoch 96/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 64.6353 - mse: 0.3373 - mae: 0.5759 - val_loss: 51.6464 - val_mse: 0.2015 - val_mae: 0.3583\n",
      "Epoch 97/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 64.0403 - mse: 0.3221 - mae: 0.5622 - val_loss: 51.3722 - val_mse: 0.1982 - val_mae: 0.3516\n",
      "Epoch 98/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 63.8304 - mse: 0.3152 - mae: 0.5565 - val_loss: 51.1374 - val_mse: 0.1955 - val_mae: 0.3456\n",
      "Epoch 99/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 63.4111 - mse: 0.3042 - mae: 0.5464 - val_loss: 50.9224 - val_mse: 0.1918 - val_mae: 0.3395\n",
      "Epoch 100/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 62.9735 - mse: 0.2930 - mae: 0.5358 - val_loss: 50.6867 - val_mse: 0.1900 - val_mae: 0.3343\n",
      "Epoch 101/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 62.6069 - mse: 0.2833 - mae: 0.5266 - val_loss: 50.5476 - val_mse: 0.1885 - val_mae: 0.3303\n",
      "Epoch 102/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 62.2246 - mse: 0.2739 - mae: 0.5175 - val_loss: 50.2774 - val_mse: 0.1845 - val_mae: 0.3232\n",
      "Epoch 103/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 61.9974 - mse: 0.2669 - mae: 0.5111 - val_loss: 50.1604 - val_mse: 0.1837 - val_mae: 0.3199\n",
      "Epoch 104/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 61.4337 - mse: 0.2541 - mae: 0.4978 - val_loss: 49.9386 - val_mse: 0.1814 - val_mae: 0.3144\n",
      "Epoch 105/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 61.1496 - mse: 0.2468 - mae: 0.4906 - val_loss: 49.7335 - val_mse: 0.1799 - val_mae: 0.3096\n",
      "Epoch 106/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 60.7893 - mse: 0.2382 - mae: 0.4816 - val_loss: 49.5735 - val_mse: 0.1776 - val_mae: 0.3048\n",
      "Epoch 107/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 60.4149 - mse: 0.2295 - mae: 0.4723 - val_loss: 49.4123 - val_mse: 0.1755 - val_mae: 0.3000\n",
      "Epoch 108/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 60.1376 - mse: 0.2228 - mae: 0.4653 - val_loss: 49.2269 - val_mse: 0.1747 - val_mae: 0.2961\n",
      "Epoch 109/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 59.6971 - mse: 0.2128 - mae: 0.4538 - val_loss: 49.0878 - val_mse: 0.1725 - val_mae: 0.2915\n",
      "Epoch 110/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 59.4070 - mse: 0.2065 - mae: 0.4468 - val_loss: 48.9210 - val_mse: 0.1713 - val_mae: 0.2874\n",
      "Epoch 111/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 59.0587 - mse: 0.1987 - mae: 0.4378 - val_loss: 48.7735 - val_mse: 0.1702 - val_mae: 0.2836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 58.7381 - mse: 0.1917 - mae: 0.4296 - val_loss: 48.5970 - val_mse: 0.1689 - val_mae: 0.2791\n",
      "Epoch 113/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 58.3953 - mse: 0.1845 - mae: 0.4208 - val_loss: 48.5211 - val_mse: 0.1680 - val_mae: 0.2765\n",
      "Epoch 114/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 58.1479 - mse: 0.1788 - mae: 0.4141 - val_loss: 48.3485 - val_mse: 0.1676 - val_mae: 0.2728\n",
      "Epoch 115/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 57.6625 - mse: 0.1701 - mae: 0.4024 - val_loss: 48.2256 - val_mse: 0.1657 - val_mae: 0.2685\n",
      "Epoch 116/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 57.5600 - mse: 0.1665 - mae: 0.3986 - val_loss: 48.0960 - val_mse: 0.1646 - val_mae: 0.2655\n",
      "Epoch 117/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 57.1105 - mse: 0.1587 - mae: 0.3879 - val_loss: 47.9714 - val_mse: 0.1644 - val_mae: 0.2619\n",
      "Epoch 118/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 56.8207 - mse: 0.1528 - mae: 0.3799 - val_loss: 47.8539 - val_mse: 0.1629 - val_mae: 0.2589\n",
      "Epoch 119/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 56.6081 - mse: 0.1482 - mae: 0.3740 - val_loss: 47.7339 - val_mse: 0.1630 - val_mae: 0.2557\n",
      "Epoch 120/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 56.2225 - mse: 0.1419 - mae: 0.3647 - val_loss: 47.6322 - val_mse: 0.1618 - val_mae: 0.2524\n",
      "Epoch 121/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 55.9500 - mse: 0.1366 - mae: 0.3570 - val_loss: 47.5175 - val_mse: 0.1614 - val_mae: 0.2499\n",
      "Epoch 122/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 55.7526 - mse: 0.1325 - mae: 0.3515 - val_loss: 47.4234 - val_mse: 0.1602 - val_mae: 0.2469\n",
      "Epoch 123/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 55.3377 - mse: 0.1262 - mae: 0.3412 - val_loss: 47.3281 - val_mse: 0.1600 - val_mae: 0.2441\n",
      "Epoch 124/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 55.1443 - mse: 0.1226 - mae: 0.3359 - val_loss: 47.2130 - val_mse: 0.1604 - val_mae: 0.2418\n",
      "Epoch 125/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 54.9604 - mse: 0.1188 - mae: 0.3305 - val_loss: 47.1352 - val_mse: 0.1586 - val_mae: 0.2389\n",
      "Epoch 126/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 54.6353 - mse: 0.1140 - mae: 0.3222 - val_loss: 47.0404 - val_mse: 0.1593 - val_mae: 0.2367\n",
      "Epoch 127/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 54.3479 - mse: 0.1095 - mae: 0.3144 - val_loss: 46.9681 - val_mse: 0.1577 - val_mae: 0.2339\n",
      "Epoch 128/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 54.1489 - mse: 0.1059 - mae: 0.3087 - val_loss: 46.8635 - val_mse: 0.1587 - val_mae: 0.2321\n",
      "Epoch 129/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 53.9268 - mse: 0.1027 - mae: 0.3031 - val_loss: 46.8026 - val_mse: 0.1572 - val_mae: 0.2294\n",
      "Epoch 130/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 53.7283 - mse: 0.0992 - mae: 0.2972 - val_loss: 46.7117 - val_mse: 0.1579 - val_mae: 0.2278\n",
      "Epoch 131/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 53.3784 - mse: 0.0951 - mae: 0.2886 - val_loss: 46.6448 - val_mse: 0.1572 - val_mae: 0.2255\n",
      "Epoch 132/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 53.2543 - mse: 0.0924 - mae: 0.2846 - val_loss: 46.5842 - val_mse: 0.1563 - val_mae: 0.2233\n",
      "Epoch 133/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 52.9862 - mse: 0.0888 - mae: 0.2773 - val_loss: 46.4949 - val_mse: 0.1565 - val_mae: 0.2211\n",
      "Epoch 134/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 52.8371 - mse: 0.0867 - mae: 0.2734 - val_loss: 46.4435 - val_mse: 0.1567 - val_mae: 0.2199\n",
      "Epoch 135/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 52.5580 - mse: 0.0829 - mae: 0.2655 - val_loss: 46.3698 - val_mse: 0.1572 - val_mae: 0.2184\n",
      "Epoch 136/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 52.3872 - mse: 0.0807 - mae: 0.2610 - val_loss: 46.3124 - val_mse: 0.1562 - val_mae: 0.2161\n",
      "Epoch 137/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 52.1987 - mse: 0.0781 - mae: 0.2557 - val_loss: 46.2512 - val_mse: 0.1560 - val_mae: 0.2143\n",
      "Epoch 138/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 52.0377 - mse: 0.0759 - mae: 0.2513 - val_loss: 46.1967 - val_mse: 0.1561 - val_mae: 0.2129\n",
      "Epoch 139/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 51.8365 - mse: 0.0734 - mae: 0.2456 - val_loss: 46.1425 - val_mse: 0.1551 - val_mae: 0.2108\n",
      "Epoch 140/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 51.5963 - mse: 0.0708 - mae: 0.2390 - val_loss: 46.0832 - val_mse: 0.1566 - val_mae: 0.2101\n",
      "Epoch 141/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 51.4698 - mse: 0.0689 - mae: 0.2354 - val_loss: 46.0416 - val_mse: 0.1549 - val_mae: 0.2079\n",
      "Epoch 142/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 51.3496 - mse: 0.0672 - mae: 0.2318 - val_loss: 45.9806 - val_mse: 0.1556 - val_mae: 0.2066\n",
      "Epoch 143/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 51.0864 - mse: 0.0650 - mae: 0.2251 - val_loss: 45.9319 - val_mse: 0.1554 - val_mae: 0.2053\n",
      "Epoch 144/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 50.9229 - mse: 0.0630 - mae: 0.2204 - val_loss: 45.8890 - val_mse: 0.1555 - val_mae: 0.2041\n",
      "Epoch 145/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 50.8335 - mse: 0.0614 - mae: 0.2174 - val_loss: 45.8480 - val_mse: 0.1558 - val_mae: 0.2031\n",
      "Epoch 146/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 50.6080 - mse: 0.0596 - mae: 0.2115 - val_loss: 45.7855 - val_mse: 0.1556 - val_mae: 0.2013\n",
      "Epoch 147/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 50.5070 - mse: 0.0578 - mae: 0.2080 - val_loss: 45.7719 - val_mse: 0.1553 - val_mae: 0.2005\n",
      "Epoch 148/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 50.3670 - mse: 0.0569 - mae: 0.2047 - val_loss: 45.7154 - val_mse: 0.1553 - val_mae: 0.1990\n",
      "Epoch 149/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 50.1795 - mse: 0.0549 - mae: 0.1991 - val_loss: 45.6784 - val_mse: 0.1556 - val_mae: 0.1981\n",
      "Epoch 150/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 50.0598 - mse: 0.0537 - mae: 0.1957 - val_loss: 45.6353 - val_mse: 0.1551 - val_mae: 0.1966\n",
      "Epoch 151/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 49.9100 - mse: 0.0523 - mae: 0.1915 - val_loss: 45.6049 - val_mse: 0.1555 - val_mae: 0.1959\n",
      "Epoch 152/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 49.7987 - mse: 0.0511 - mae: 0.1882 - val_loss: 45.5632 - val_mse: 0.1562 - val_mae: 0.1953\n",
      "Epoch 153/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 49.6082 - mse: 0.0499 - mae: 0.1832 - val_loss: 45.5344 - val_mse: 0.1547 - val_mae: 0.1932\n",
      "Epoch 154/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 49.5521 - mse: 0.0487 - mae: 0.1810 - val_loss: 45.4953 - val_mse: 0.1562 - val_mae: 0.1933\n",
      "Epoch 155/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 49.3801 - mse: 0.0477 - mae: 0.1765 - val_loss: 45.4690 - val_mse: 0.1549 - val_mae: 0.1915\n",
      "Epoch 156/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 49.2792 - mse: 0.0463 - mae: 0.1731 - val_loss: 45.4334 - val_mse: 0.1553 - val_mae: 0.1909\n",
      "Epoch 157/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 49.1672 - mse: 0.0458 - mae: 0.1703 - val_loss: 45.4044 - val_mse: 0.1555 - val_mae: 0.1901\n",
      "Epoch 158/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 49.0487 - mse: 0.0447 - mae: 0.1668 - val_loss: 45.3758 - val_mse: 0.1555 - val_mae: 0.1891\n",
      "Epoch 159/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 48.9149 - mse: 0.0438 - mae: 0.1631 - val_loss: 45.3431 - val_mse: 0.1562 - val_mae: 0.1888\n",
      "Epoch 160/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 9ms/step - loss: 48.8333 - mse: 0.0428 - mae: 0.1604 - val_loss: 45.3211 - val_mse: 0.1548 - val_mae: 0.1870\n",
      "Epoch 161/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 48.7073 - mse: 0.0419 - mae: 0.1567 - val_loss: 45.2933 - val_mse: 0.1556 - val_mae: 0.1868\n",
      "Epoch 162/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 48.6512 - mse: 0.0413 - mae: 0.1550 - val_loss: 45.2720 - val_mse: 0.1558 - val_mae: 0.1863\n",
      "Epoch 163/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 48.4824 - mse: 0.0408 - mae: 0.1508 - val_loss: 45.2411 - val_mse: 0.1557 - val_mae: 0.1852\n",
      "Epoch 164/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 48.4061 - mse: 0.0397 - mae: 0.1480 - val_loss: 45.2196 - val_mse: 0.1559 - val_mae: 0.1848\n",
      "Epoch 165/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 48.3387 - mse: 0.0395 - mae: 0.1464 - val_loss: 45.1961 - val_mse: 0.1558 - val_mae: 0.1840\n",
      "Epoch 166/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 48.1945 - mse: 0.0386 - mae: 0.1422 - val_loss: 45.1727 - val_mse: 0.1560 - val_mae: 0.1836\n",
      "Epoch 167/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 48.1445 - mse: 0.0379 - mae: 0.1404 - val_loss: 45.1521 - val_mse: 0.1559 - val_mae: 0.1827\n",
      "Epoch 168/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 48.0607 - mse: 0.0373 - mae: 0.1379 - val_loss: 45.1322 - val_mse: 0.1558 - val_mae: 0.1818\n",
      "Epoch 169/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 47.9386 - mse: 0.0370 - mae: 0.1347 - val_loss: 45.1105 - val_mse: 0.1558 - val_mae: 0.1813\n",
      "Epoch 170/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 47.8827 - mse: 0.0361 - mae: 0.1326 - val_loss: 45.0906 - val_mse: 0.1564 - val_mae: 0.1811\n",
      "Epoch 171/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 47.8212 - mse: 0.0358 - mae: 0.1310 - val_loss: 45.0713 - val_mse: 0.1556 - val_mae: 0.1800\n",
      "Epoch 172/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 47.7155 - mse: 0.0355 - mae: 0.1281 - val_loss: 45.0548 - val_mse: 0.1565 - val_mae: 0.1801\n",
      "Epoch 173/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 47.6173 - mse: 0.0348 - mae: 0.1250 - val_loss: 45.0363 - val_mse: 0.1558 - val_mae: 0.1791\n",
      "Epoch 174/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 47.5812 - mse: 0.0346 - mae: 0.1240 - val_loss: 45.0193 - val_mse: 0.1561 - val_mae: 0.1786\n",
      "Epoch 175/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 47.4763 - mse: 0.0340 - mae: 0.1209 - val_loss: 45.0015 - val_mse: 0.1566 - val_mae: 0.1785\n",
      "Epoch 176/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 47.4426 - mse: 0.0338 - mae: 0.1200 - val_loss: 44.9879 - val_mse: 0.1560 - val_mae: 0.1776\n",
      "Epoch 177/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 47.3648 - mse: 0.0330 - mae: 0.1171 - val_loss: 44.9685 - val_mse: 0.1563 - val_mae: 0.1773\n",
      "Epoch 178/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 47.2535 - mse: 0.0332 - mae: 0.1146 - val_loss: 44.9555 - val_mse: 0.1563 - val_mae: 0.1767\n",
      "Epoch 179/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 47.2165 - mse: 0.0327 - mae: 0.1133 - val_loss: 44.9391 - val_mse: 0.1563 - val_mae: 0.1763\n",
      "Epoch 180/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 47.1874 - mse: 0.0321 - mae: 0.1119 - val_loss: 44.9276 - val_mse: 0.1567 - val_mae: 0.1762\n",
      "Epoch 181/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 47.0611 - mse: 0.0323 - mae: 0.1090 - val_loss: 44.9093 - val_mse: 0.1570 - val_mae: 0.1759\n",
      "Epoch 182/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 47.0462 - mse: 0.0318 - mae: 0.1082 - val_loss: 44.9010 - val_mse: 0.1563 - val_mae: 0.1751\n",
      "Epoch 183/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 46.9701 - mse: 0.0315 - mae: 0.1059 - val_loss: 44.8859 - val_mse: 0.1563 - val_mae: 0.1744\n",
      "Epoch 184/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 46.9160 - mse: 0.0312 - mae: 0.1043 - val_loss: 44.8732 - val_mse: 0.1566 - val_mae: 0.1744\n",
      "Epoch 185/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 46.8797 - mse: 0.0307 - mae: 0.1028 - val_loss: 44.8599 - val_mse: 0.1573 - val_mae: 0.1745\n",
      "Epoch 186/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 46.7893 - mse: 0.0311 - mae: 0.1009 - val_loss: 44.8495 - val_mse: 0.1559 - val_mae: 0.1730\n",
      "Epoch 187/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 46.7494 - mse: 0.0305 - mae: 0.0993 - val_loss: 44.8376 - val_mse: 0.1567 - val_mae: 0.1733\n",
      "Epoch 188/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 46.7194 - mse: 0.0300 - mae: 0.0980 - val_loss: 44.8250 - val_mse: 0.1575 - val_mae: 0.1735\n",
      "Epoch 189/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 46.6320 - mse: 0.0305 - mae: 0.0962 - val_loss: 44.8175 - val_mse: 0.1563 - val_mae: 0.1723\n",
      "Epoch 190/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 46.6192 - mse: 0.0296 - mae: 0.0950 - val_loss: 44.8050 - val_mse: 0.1572 - val_mae: 0.1727\n",
      "Epoch 191/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 46.5535 - mse: 0.0298 - mae: 0.0934 - val_loss: 44.7905 - val_mse: 0.1569 - val_mae: 0.1719\n",
      "Epoch 192/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 46.4843 - mse: 0.0298 - mae: 0.0916 - val_loss: 44.7893 - val_mse: 0.1565 - val_mae: 0.1715\n",
      "Epoch 193/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 46.4838 - mse: 0.0292 - mae: 0.0911 - val_loss: 44.7731 - val_mse: 0.1576 - val_mae: 0.1719\n",
      "Epoch 194/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 46.3952 - mse: 0.0295 - mae: 0.0890 - val_loss: 44.7671 - val_mse: 0.1563 - val_mae: 0.1706\n",
      "Epoch 195/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 46.3795 - mse: 0.0293 - mae: 0.0884 - val_loss: 44.7533 - val_mse: 0.1575 - val_mae: 0.1712\n",
      "Epoch 196/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 46.3259 - mse: 0.0289 - mae: 0.0865 - val_loss: 44.7522 - val_mse: 0.1568 - val_mae: 0.1705\n",
      "Epoch 197/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 46.2865 - mse: 0.0292 - mae: 0.0858 - val_loss: 44.7351 - val_mse: 0.1573 - val_mae: 0.1705\n",
      "Epoch 198/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 46.2545 - mse: 0.0285 - mae: 0.0842 - val_loss: 44.7351 - val_mse: 0.1569 - val_mae: 0.1700\n",
      "Epoch 199/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 46.2203 - mse: 0.0286 - mae: 0.0835 - val_loss: 44.7228 - val_mse: 0.1572 - val_mae: 0.1699\n",
      "Epoch 200/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 46.1769 - mse: 0.0285 - mae: 0.0821 - val_loss: 44.7145 - val_mse: 0.1574 - val_mae: 0.1699\n",
      "Epoch 201/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 46.1410 - mse: 0.0284 - mae: 0.0811 - val_loss: 44.7074 - val_mse: 0.1568 - val_mae: 0.1690\n",
      "Epoch 202/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 46.0880 - mse: 0.0282 - mae: 0.0794 - val_loss: 44.6996 - val_mse: 0.1573 - val_mae: 0.1693\n",
      "Epoch 203/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 46.0662 - mse: 0.0282 - mae: 0.0788 - val_loss: 44.6925 - val_mse: 0.1576 - val_mae: 0.1693\n",
      "Epoch 204/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 46.0346 - mse: 0.0279 - mae: 0.0777 - val_loss: 44.6822 - val_mse: 0.1573 - val_mae: 0.1686\n",
      "Epoch 205/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.9985 - mse: 0.0280 - mae: 0.0767 - val_loss: 44.6802 - val_mse: 0.1576 - val_mae: 0.1687\n",
      "Epoch 206/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.9756 - mse: 0.0281 - mae: 0.0763 - val_loss: 44.6743 - val_mse: 0.1568 - val_mae: 0.1679\n",
      "Epoch 207/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 45.9231 - mse: 0.0277 - mae: 0.0743 - val_loss: 44.6645 - val_mse: 0.1574 - val_mae: 0.1681\n",
      "Epoch 208/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.9030 - mse: 0.0278 - mae: 0.0739 - val_loss: 44.6590 - val_mse: 0.1578 - val_mae: 0.1683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.8735 - mse: 0.0276 - mae: 0.0729 - val_loss: 44.6499 - val_mse: 0.1575 - val_mae: 0.1676\n",
      "Epoch 210/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 45.8470 - mse: 0.0278 - mae: 0.0723 - val_loss: 44.6497 - val_mse: 0.1575 - val_mae: 0.1677\n",
      "Epoch 211/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.8090 - mse: 0.0274 - mae: 0.0709 - val_loss: 44.6382 - val_mse: 0.1575 - val_mae: 0.1673\n",
      "Epoch 212/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.7958 - mse: 0.0276 - mae: 0.0708 - val_loss: 44.6353 - val_mse: 0.1575 - val_mae: 0.1672\n",
      "Epoch 213/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 45.7498 - mse: 0.0275 - mae: 0.0693 - val_loss: 44.6322 - val_mse: 0.1571 - val_mae: 0.1667\n",
      "Epoch 214/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.7270 - mse: 0.0274 - mae: 0.0686 - val_loss: 44.6246 - val_mse: 0.1577 - val_mae: 0.1670\n",
      "Epoch 215/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.7153 - mse: 0.0271 - mae: 0.0679 - val_loss: 44.6191 - val_mse: 0.1579 - val_mae: 0.1671\n",
      "Epoch 216/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 45.6891 - mse: 0.0268 - mae: 0.0669 - val_loss: 44.6140 - val_mse: 0.1573 - val_mae: 0.1662\n",
      "Epoch 217/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.6455 - mse: 0.0276 - mae: 0.0665 - val_loss: 44.6090 - val_mse: 0.1577 - val_mae: 0.1664\n",
      "Epoch 218/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.6240 - mse: 0.0271 - mae: 0.0653 - val_loss: 44.6041 - val_mse: 0.1580 - val_mae: 0.1666\n",
      "Epoch 219/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.6066 - mse: 0.0271 - mae: 0.0649 - val_loss: 44.5987 - val_mse: 0.1579 - val_mae: 0.1663\n",
      "Epoch 220/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.5923 - mse: 0.0271 - mae: 0.0644 - val_loss: 44.5954 - val_mse: 0.1571 - val_mae: 0.1654\n",
      "Epoch 221/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.5504 - mse: 0.0271 - mae: 0.0632 - val_loss: 44.5889 - val_mse: 0.1583 - val_mae: 0.1664\n",
      "Epoch 222/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.5481 - mse: 0.0269 - mae: 0.0630 - val_loss: 44.5870 - val_mse: 0.1572 - val_mae: 0.1653\n",
      "Epoch 223/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.5164 - mse: 0.0270 - mae: 0.0621 - val_loss: 44.5815 - val_mse: 0.1578 - val_mae: 0.1656\n",
      "Epoch 224/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 45.4952 - mse: 0.0269 - mae: 0.0615 - val_loss: 44.5751 - val_mse: 0.1581 - val_mae: 0.1657\n",
      "Epoch 225/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 45.4701 - mse: 0.0270 - mae: 0.0608 - val_loss: 44.5756 - val_mse: 0.1576 - val_mae: 0.1651\n",
      "Epoch 226/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 45.4579 - mse: 0.0269 - mae: 0.0604 - val_loss: 44.5669 - val_mse: 0.1581 - val_mae: 0.1654\n",
      "Epoch 227/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.4397 - mse: 0.0264 - mae: 0.0593 - val_loss: 44.5672 - val_mse: 0.1574 - val_mae: 0.1647\n",
      "Epoch 228/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.4019 - mse: 0.0271 - mae: 0.0590 - val_loss: 44.5622 - val_mse: 0.1580 - val_mae: 0.1651\n",
      "Epoch 229/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.3971 - mse: 0.0270 - mae: 0.0587 - val_loss: 44.5575 - val_mse: 0.1580 - val_mae: 0.1649\n",
      "Epoch 230/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.3738 - mse: 0.0268 - mae: 0.0579 - val_loss: 44.5542 - val_mse: 0.1579 - val_mae: 0.1648\n",
      "Epoch 231/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 45.3696 - mse: 0.0264 - mae: 0.0573 - val_loss: 44.5505 - val_mse: 0.1582 - val_mae: 0.1649\n",
      "Epoch 232/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 45.3416 - mse: 0.0267 - mae: 0.0568 - val_loss: 44.5473 - val_mse: 0.1576 - val_mae: 0.1642\n",
      "Epoch 233/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 45.3206 - mse: 0.0268 - mae: 0.0562 - val_loss: 44.5434 - val_mse: 0.1585 - val_mae: 0.1649\n",
      "Epoch 234/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.3015 - mse: 0.0269 - mae: 0.0558 - val_loss: 44.5406 - val_mse: 0.1580 - val_mae: 0.1643\n",
      "Epoch 235/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.3003 - mse: 0.0263 - mae: 0.0552 - val_loss: 44.5380 - val_mse: 0.1575 - val_mae: 0.1638\n",
      "Epoch 236/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 45.2654 - mse: 0.0270 - mae: 0.0548 - val_loss: 44.5331 - val_mse: 0.1584 - val_mae: 0.1645\n",
      "Epoch 237/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.2677 - mse: 0.0264 - mae: 0.0543 - val_loss: 44.5312 - val_mse: 0.1580 - val_mae: 0.1641\n",
      "Epoch 238/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.2415 - mse: 0.0265 - mae: 0.0537 - val_loss: 44.5275 - val_mse: 0.1579 - val_mae: 0.1638\n",
      "Epoch 239/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 45.2214 - mse: 0.0268 - mae: 0.0534 - val_loss: 44.5270 - val_mse: 0.1576 - val_mae: 0.1635\n",
      "Epoch 240/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.2218 - mse: 0.0263 - mae: 0.0529 - val_loss: 44.5214 - val_mse: 0.1586 - val_mae: 0.1643\n",
      "Epoch 241/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 45.1936 - mse: 0.0267 - mae: 0.0524 - val_loss: 44.5206 - val_mse: 0.1575 - val_mae: 0.1632\n",
      "Epoch 242/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 45.1837 - mse: 0.0263 - mae: 0.0517 - val_loss: 44.5169 - val_mse: 0.1585 - val_mae: 0.1641\n",
      "Epoch 243/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.1751 - mse: 0.0266 - mae: 0.0518 - val_loss: 44.5144 - val_mse: 0.1578 - val_mae: 0.1632\n",
      "Epoch 244/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 45.1530 - mse: 0.0264 - mae: 0.0509 - val_loss: 44.5111 - val_mse: 0.1586 - val_mae: 0.1639\n",
      "Epoch 245/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 45.1449 - mse: 0.0267 - mae: 0.0510 - val_loss: 44.5080 - val_mse: 0.1579 - val_mae: 0.1631\n",
      "Epoch 246/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.1280 - mse: 0.0266 - mae: 0.0503 - val_loss: 44.5081 - val_mse: 0.1581 - val_mae: 0.1634\n",
      "Epoch 247/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.1297 - mse: 0.0258 - mae: 0.0496 - val_loss: 44.5042 - val_mse: 0.1580 - val_mae: 0.1630\n",
      "Epoch 248/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.1017 - mse: 0.0269 - mae: 0.0499 - val_loss: 44.5018 - val_mse: 0.1582 - val_mae: 0.1632\n",
      "Epoch 249/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 45.0884 - mse: 0.0262 - mae: 0.0488 - val_loss: 44.4995 - val_mse: 0.1580 - val_mae: 0.1629\n",
      "Epoch 250/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.0868 - mse: 0.0265 - mae: 0.0490 - val_loss: 44.4972 - val_mse: 0.1581 - val_mae: 0.1629\n",
      "Epoch 251/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.0734 - mse: 0.0261 - mae: 0.0482 - val_loss: 44.4946 - val_mse: 0.1588 - val_mae: 0.1635\n",
      "Epoch 252/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.0503 - mse: 0.0270 - mae: 0.0485 - val_loss: 44.4933 - val_mse: 0.1577 - val_mae: 0.1624\n",
      "Epoch 253/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 45.0517 - mse: 0.0261 - mae: 0.0476 - val_loss: 44.4906 - val_mse: 0.1581 - val_mae: 0.1627\n",
      "Epoch 254/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 45.0318 - mse: 0.0267 - mae: 0.0475 - val_loss: 44.4886 - val_mse: 0.1582 - val_mae: 0.1627\n",
      "Epoch 255/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 45.0246 - mse: 0.0261 - mae: 0.0468 - val_loss: 44.4868 - val_mse: 0.1583 - val_mae: 0.1628\n",
      "Epoch 256/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 45.0175 - mse: 0.0265 - mae: 0.0469 - val_loss: 44.4843 - val_mse: 0.1583 - val_mae: 0.1627\n",
      "Epoch 257/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 10ms/step - loss: 45.0071 - mse: 0.0263 - mae: 0.0464 - val_loss: 44.4826 - val_mse: 0.1583 - val_mae: 0.1626\n",
      "Epoch 258/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.9945 - mse: 0.0264 - mae: 0.0461 - val_loss: 44.4806 - val_mse: 0.1583 - val_mae: 0.1625\n",
      "Epoch 259/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.9804 - mse: 0.0266 - mae: 0.0460 - val_loss: 44.4775 - val_mse: 0.1585 - val_mae: 0.1627\n",
      "Epoch 260/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.9740 - mse: 0.0261 - mae: 0.0452 - val_loss: 44.4774 - val_mse: 0.1584 - val_mae: 0.1626\n",
      "Epoch 261/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.9653 - mse: 0.0264 - mae: 0.0452 - val_loss: 44.4747 - val_mse: 0.1581 - val_mae: 0.1622\n",
      "Epoch 262/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.9568 - mse: 0.0266 - mae: 0.0452 - val_loss: 44.4747 - val_mse: 0.1579 - val_mae: 0.1620\n",
      "Epoch 263/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.9484 - mse: 0.0262 - mae: 0.0445 - val_loss: 44.4703 - val_mse: 0.1587 - val_mae: 0.1625\n",
      "Epoch 264/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.9356 - mse: 0.0263 - mae: 0.0442 - val_loss: 44.4710 - val_mse: 0.1580 - val_mae: 0.1619\n",
      "Epoch 265/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.9335 - mse: 0.0263 - mae: 0.0443 - val_loss: 44.4680 - val_mse: 0.1589 - val_mae: 0.1626\n",
      "Epoch 266/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.9168 - mse: 0.0266 - mae: 0.0440 - val_loss: 44.4670 - val_mse: 0.1580 - val_mae: 0.1617\n",
      "Epoch 267/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.9114 - mse: 0.0260 - mae: 0.0432 - val_loss: 44.4647 - val_mse: 0.1587 - val_mae: 0.1624\n",
      "Epoch 268/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.9063 - mse: 0.0265 - mae: 0.0436 - val_loss: 44.4638 - val_mse: 0.1581 - val_mae: 0.1618\n",
      "Epoch 269/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.8912 - mse: 0.0266 - mae: 0.0432 - val_loss: 44.4610 - val_mse: 0.1583 - val_mae: 0.1619\n",
      "Epoch 270/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.8929 - mse: 0.0261 - mae: 0.0428 - val_loss: 44.4614 - val_mse: 0.1579 - val_mae: 0.1615\n",
      "Epoch 271/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.8744 - mse: 0.0266 - mae: 0.0427 - val_loss: 44.4587 - val_mse: 0.1590 - val_mae: 0.1625\n",
      "Epoch 272/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.8734 - mse: 0.0260 - mae: 0.0420 - val_loss: 44.4578 - val_mse: 0.1577 - val_mae: 0.1612\n",
      "Epoch 273/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.8665 - mse: 0.0264 - mae: 0.0423 - val_loss: 44.4563 - val_mse: 0.1585 - val_mae: 0.1618\n",
      "Epoch 274/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.8615 - mse: 0.0259 - mae: 0.0416 - val_loss: 44.4545 - val_mse: 0.1583 - val_mae: 0.1616\n",
      "Epoch 275/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.8497 - mse: 0.0263 - mae: 0.0417 - val_loss: 44.4534 - val_mse: 0.1584 - val_mae: 0.1617\n",
      "Epoch 276/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.8382 - mse: 0.0268 - mae: 0.0418 - val_loss: 44.4520 - val_mse: 0.1584 - val_mae: 0.1616\n",
      "Epoch 277/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.8337 - mse: 0.0262 - mae: 0.0411 - val_loss: 44.4501 - val_mse: 0.1590 - val_mae: 0.1621\n",
      "Epoch 278/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.8313 - mse: 0.0264 - mae: 0.0412 - val_loss: 44.4500 - val_mse: 0.1578 - val_mae: 0.1610\n",
      "Epoch 279/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.8220 - mse: 0.0263 - mae: 0.0408 - val_loss: 44.4480 - val_mse: 0.1591 - val_mae: 0.1621\n",
      "Epoch 280/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.8154 - mse: 0.0263 - mae: 0.0406 - val_loss: 44.4472 - val_mse: 0.1580 - val_mae: 0.1610\n",
      "Epoch 281/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.8089 - mse: 0.0263 - mae: 0.0404 - val_loss: 44.4458 - val_mse: 0.1584 - val_mae: 0.1614\n",
      "Epoch 282/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.8036 - mse: 0.0262 - mae: 0.0401 - val_loss: 44.4438 - val_mse: 0.1589 - val_mae: 0.1619\n",
      "Epoch 283/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.7962 - mse: 0.0263 - mae: 0.0400 - val_loss: 44.4439 - val_mse: 0.1580 - val_mae: 0.1610\n",
      "Epoch 284/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.7869 - mse: 0.0263 - mae: 0.0397 - val_loss: 44.4421 - val_mse: 0.1584 - val_mae: 0.1613\n",
      "Epoch 285/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.7839 - mse: 0.0264 - mae: 0.0397 - val_loss: 44.4410 - val_mse: 0.1588 - val_mae: 0.1616\n",
      "Epoch 286/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.7770 - mse: 0.0267 - mae: 0.0398 - val_loss: 44.4400 - val_mse: 0.1581 - val_mae: 0.1609\n",
      "Epoch 287/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.7736 - mse: 0.0259 - mae: 0.0389 - val_loss: 44.4389 - val_mse: 0.1584 - val_mae: 0.1611\n",
      "Epoch 288/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.7653 - mse: 0.0268 - mae: 0.0395 - val_loss: 44.4373 - val_mse: 0.1590 - val_mae: 0.1617\n",
      "Epoch 289/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.7618 - mse: 0.0260 - mae: 0.0387 - val_loss: 44.4373 - val_mse: 0.1582 - val_mae: 0.1609\n",
      "Epoch 290/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.7573 - mse: 0.0263 - mae: 0.0388 - val_loss: 44.4357 - val_mse: 0.1583 - val_mae: 0.1610\n",
      "Epoch 291/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.7499 - mse: 0.0263 - mae: 0.0386 - val_loss: 44.4348 - val_mse: 0.1585 - val_mae: 0.1611\n",
      "Epoch 292/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.7446 - mse: 0.0263 - mae: 0.0384 - val_loss: 44.4337 - val_mse: 0.1586 - val_mae: 0.1612\n",
      "Epoch 293/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.7378 - mse: 0.0262 - mae: 0.0381 - val_loss: 44.4327 - val_mse: 0.1583 - val_mae: 0.1609\n",
      "Epoch 294/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.7344 - mse: 0.0262 - mae: 0.0380 - val_loss: 44.4316 - val_mse: 0.1590 - val_mae: 0.1615\n",
      "Epoch 295/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.7288 - mse: 0.0265 - mae: 0.0381 - val_loss: 44.4311 - val_mse: 0.1580 - val_mae: 0.1604\n",
      "Epoch 296/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.7244 - mse: 0.0263 - mae: 0.0377 - val_loss: 44.4298 - val_mse: 0.1585 - val_mae: 0.1610\n",
      "Epoch 297/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.7221 - mse: 0.0263 - mae: 0.0377 - val_loss: 44.4290 - val_mse: 0.1585 - val_mae: 0.1609\n",
      "Epoch 298/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.7136 - mse: 0.0264 - mae: 0.0376 - val_loss: 44.4281 - val_mse: 0.1587 - val_mae: 0.1610\n",
      "Epoch 299/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.7084 - mse: 0.0265 - mae: 0.0375 - val_loss: 44.4272 - val_mse: 0.1585 - val_mae: 0.1609\n",
      "Epoch 300/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.7064 - mse: 0.0262 - mae: 0.0371 - val_loss: 44.4258 - val_mse: 0.1588 - val_mae: 0.1611\n",
      "Epoch 301/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.6988 - mse: 0.0262 - mae: 0.0368 - val_loss: 44.4259 - val_mse: 0.1581 - val_mae: 0.1604\n",
      "Epoch 302/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.6977 - mse: 0.0265 - mae: 0.0371 - val_loss: 44.4245 - val_mse: 0.1591 - val_mae: 0.1613\n",
      "Epoch 303/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.6942 - mse: 0.0259 - mae: 0.0364 - val_loss: 44.4240 - val_mse: 0.1580 - val_mae: 0.1602\n",
      "Epoch 304/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.6834 - mse: 0.0269 - mae: 0.0371 - val_loss: 44.4230 - val_mse: 0.1589 - val_mae: 0.1611\n",
      "Epoch 305/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 10ms/step - loss: 44.6824 - mse: 0.0261 - mae: 0.0362 - val_loss: 44.4221 - val_mse: 0.1587 - val_mae: 0.1609\n",
      "Epoch 306/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.6793 - mse: 0.0266 - mae: 0.0367 - val_loss: 44.4216 - val_mse: 0.1584 - val_mae: 0.1605\n",
      "Epoch 307/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.6733 - mse: 0.0264 - mae: 0.0363 - val_loss: 44.4208 - val_mse: 0.1582 - val_mae: 0.1603\n",
      "Epoch 308/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.6706 - mse: 0.0263 - mae: 0.0361 - val_loss: 44.4194 - val_mse: 0.1591 - val_mae: 0.1611\n",
      "Epoch 309/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.6687 - mse: 0.0261 - mae: 0.0358 - val_loss: 44.4196 - val_mse: 0.1581 - val_mae: 0.1602\n",
      "Epoch 310/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.6630 - mse: 0.0263 - mae: 0.0359 - val_loss: 44.4184 - val_mse: 0.1586 - val_mae: 0.1606\n",
      "Epoch 311/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.6594 - mse: 0.0264 - mae: 0.0358 - val_loss: 44.4177 - val_mse: 0.1589 - val_mae: 0.1609\n",
      "Epoch 312/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.6550 - mse: 0.0262 - mae: 0.0355 - val_loss: 44.4170 - val_mse: 0.1586 - val_mae: 0.1605\n",
      "Epoch 313/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.6512 - mse: 0.0263 - mae: 0.0355 - val_loss: 44.4164 - val_mse: 0.1584 - val_mae: 0.1603\n",
      "Epoch 314/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.6475 - mse: 0.0263 - mae: 0.0354 - val_loss: 44.4156 - val_mse: 0.1583 - val_mae: 0.1602\n",
      "Epoch 315/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.6438 - mse: 0.0263 - mae: 0.0353 - val_loss: 44.4149 - val_mse: 0.1587 - val_mae: 0.1606\n",
      "Epoch 316/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.6382 - mse: 0.0263 - mae: 0.0351 - val_loss: 44.4141 - val_mse: 0.1591 - val_mae: 0.1610\n",
      "Epoch 317/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.6388 - mse: 0.0266 - mae: 0.0354 - val_loss: 44.4134 - val_mse: 0.1585 - val_mae: 0.1604\n",
      "Epoch 318/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.6304 - mse: 0.0266 - mae: 0.0351 - val_loss: 44.4133 - val_mse: 0.1585 - val_mae: 0.1603\n",
      "Epoch 319/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.6305 - mse: 0.0261 - mae: 0.0346 - val_loss: 44.4124 - val_mse: 0.1583 - val_mae: 0.1601\n",
      "Epoch 320/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.6272 - mse: 0.0265 - mae: 0.0350 - val_loss: 44.4117 - val_mse: 0.1589 - val_mae: 0.1607\n",
      "Epoch 321/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.6249 - mse: 0.0262 - mae: 0.0346 - val_loss: 44.4111 - val_mse: 0.1586 - val_mae: 0.1604\n",
      "Epoch 322/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.6181 - mse: 0.0261 - mae: 0.0343 - val_loss: 44.4102 - val_mse: 0.1587 - val_mae: 0.1605\n",
      "Epoch 323/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.6166 - mse: 0.0265 - mae: 0.0346 - val_loss: 44.4102 - val_mse: 0.1581 - val_mae: 0.1599\n",
      "Epoch 324/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.6153 - mse: 0.0264 - mae: 0.0344 - val_loss: 44.4088 - val_mse: 0.1589 - val_mae: 0.1606\n",
      "Epoch 325/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.6091 - mse: 0.0263 - mae: 0.0341 - val_loss: 44.4092 - val_mse: 0.1586 - val_mae: 0.1603\n",
      "Epoch 326/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.6076 - mse: 0.0263 - mae: 0.0341 - val_loss: 44.4082 - val_mse: 0.1583 - val_mae: 0.1599\n",
      "Epoch 327/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.6055 - mse: 0.0265 - mae: 0.0343 - val_loss: 44.4076 - val_mse: 0.1586 - val_mae: 0.1603\n",
      "Epoch 328/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.6016 - mse: 0.0264 - mae: 0.0340 - val_loss: 44.4070 - val_mse: 0.1590 - val_mae: 0.1606\n",
      "Epoch 329/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5969 - mse: 0.0266 - mae: 0.0341 - val_loss: 44.4061 - val_mse: 0.1586 - val_mae: 0.1602\n",
      "Epoch 330/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5965 - mse: 0.0259 - mae: 0.0334 - val_loss: 44.4064 - val_mse: 0.1582 - val_mae: 0.1598\n",
      "Epoch 331/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5939 - mse: 0.0265 - mae: 0.0339 - val_loss: 44.4055 - val_mse: 0.1587 - val_mae: 0.1603\n",
      "Epoch 332/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5885 - mse: 0.0266 - mae: 0.0339 - val_loss: 44.4044 - val_mse: 0.1590 - val_mae: 0.1605\n",
      "Epoch 333/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.5880 - mse: 0.0260 - mae: 0.0332 - val_loss: 44.4049 - val_mse: 0.1585 - val_mae: 0.1600\n",
      "Epoch 334/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5851 - mse: 0.0266 - mae: 0.0337 - val_loss: 44.4039 - val_mse: 0.1584 - val_mae: 0.1599\n",
      "Epoch 335/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5816 - mse: 0.0261 - mae: 0.0331 - val_loss: 44.4035 - val_mse: 0.1587 - val_mae: 0.1602\n",
      "Epoch 336/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5793 - mse: 0.0264 - mae: 0.0334 - val_loss: 44.4029 - val_mse: 0.1590 - val_mae: 0.1605\n",
      "Epoch 337/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5782 - mse: 0.0264 - mae: 0.0333 - val_loss: 44.4025 - val_mse: 0.1584 - val_mae: 0.1598\n",
      "Epoch 338/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.5740 - mse: 0.0264 - mae: 0.0331 - val_loss: 44.4020 - val_mse: 0.1585 - val_mae: 0.1599\n",
      "Epoch 339/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.5725 - mse: 0.0263 - mae: 0.0330 - val_loss: 44.4012 - val_mse: 0.1592 - val_mae: 0.1606\n",
      "Epoch 340/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5677 - mse: 0.0263 - mae: 0.0329 - val_loss: 44.4014 - val_mse: 0.1582 - val_mae: 0.1596\n",
      "Epoch 341/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5696 - mse: 0.0261 - mae: 0.0327 - val_loss: 44.4005 - val_mse: 0.1591 - val_mae: 0.1605\n",
      "Epoch 342/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5628 - mse: 0.0268 - mae: 0.0332 - val_loss: 44.3999 - val_mse: 0.1585 - val_mae: 0.1598\n",
      "Epoch 343/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5625 - mse: 0.0264 - mae: 0.0328 - val_loss: 44.4002 - val_mse: 0.1585 - val_mae: 0.1598\n",
      "Epoch 344/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5586 - mse: 0.0265 - mae: 0.0328 - val_loss: 44.3990 - val_mse: 0.1590 - val_mae: 0.1603\n",
      "Epoch 345/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5586 - mse: 0.0263 - mae: 0.0325 - val_loss: 44.3988 - val_mse: 0.1585 - val_mae: 0.1598\n",
      "Epoch 346/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5537 - mse: 0.0262 - mae: 0.0323 - val_loss: 44.3987 - val_mse: 0.1589 - val_mae: 0.1602\n",
      "Epoch 347/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5544 - mse: 0.0266 - mae: 0.0327 - val_loss: 44.3981 - val_mse: 0.1582 - val_mae: 0.1595\n",
      "Epoch 348/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5493 - mse: 0.0262 - mae: 0.0321 - val_loss: 44.3977 - val_mse: 0.1588 - val_mae: 0.1600\n",
      "Epoch 349/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.5484 - mse: 0.0265 - mae: 0.0325 - val_loss: 44.3972 - val_mse: 0.1584 - val_mae: 0.1597\n",
      "Epoch 350/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5460 - mse: 0.0267 - mae: 0.0326 - val_loss: 44.3968 - val_mse: 0.1587 - val_mae: 0.1599\n",
      "Epoch 351/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5452 - mse: 0.0263 - mae: 0.0321 - val_loss: 44.3964 - val_mse: 0.1587 - val_mae: 0.1599\n",
      "Epoch 352/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5427 - mse: 0.0262 - mae: 0.0320 - val_loss: 44.3960 - val_mse: 0.1593 - val_mae: 0.1605\n",
      "Epoch 353/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 9ms/step - loss: 44.5394 - mse: 0.0262 - mae: 0.0319 - val_loss: 44.3957 - val_mse: 0.1585 - val_mae: 0.1597\n",
      "Epoch 354/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.5385 - mse: 0.0267 - mae: 0.0324 - val_loss: 44.3953 - val_mse: 0.1587 - val_mae: 0.1599\n",
      "Epoch 355/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5382 - mse: 0.0258 - mae: 0.0314 - val_loss: 44.3949 - val_mse: 0.1583 - val_mae: 0.1595\n",
      "Epoch 356/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5326 - mse: 0.0268 - mae: 0.0323 - val_loss: 44.3943 - val_mse: 0.1591 - val_mae: 0.1603\n",
      "Epoch 357/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5323 - mse: 0.0264 - mae: 0.0318 - val_loss: 44.3944 - val_mse: 0.1582 - val_mae: 0.1594\n",
      "Epoch 358/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5295 - mse: 0.0264 - mae: 0.0317 - val_loss: 44.3938 - val_mse: 0.1587 - val_mae: 0.1598\n",
      "Epoch 359/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.5308 - mse: 0.0260 - mae: 0.0314 - val_loss: 44.3935 - val_mse: 0.1587 - val_mae: 0.1599\n",
      "Epoch 360/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5244 - mse: 0.0267 - mae: 0.0319 - val_loss: 44.3929 - val_mse: 0.1591 - val_mae: 0.1602\n",
      "Epoch 361/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5247 - mse: 0.0265 - mae: 0.0317 - val_loss: 44.3930 - val_mse: 0.1581 - val_mae: 0.1592\n",
      "Epoch 362/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.5252 - mse: 0.0261 - mae: 0.0313 - val_loss: 44.3922 - val_mse: 0.1593 - val_mae: 0.1604\n",
      "Epoch 363/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.5193 - mse: 0.0270 - mae: 0.0320 - val_loss: 44.3923 - val_mse: 0.1581 - val_mae: 0.1592\n",
      "Epoch 364/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5204 - mse: 0.0263 - mae: 0.0313 - val_loss: 44.3917 - val_mse: 0.1593 - val_mae: 0.1604\n",
      "Epoch 365/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5165 - mse: 0.0262 - mae: 0.0311 - val_loss: 44.3916 - val_mse: 0.1583 - val_mae: 0.1594\n",
      "Epoch 366/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5155 - mse: 0.0268 - mae: 0.0318 - val_loss: 44.3911 - val_mse: 0.1584 - val_mae: 0.1595\n",
      "Epoch 367/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5148 - mse: 0.0260 - mae: 0.0309 - val_loss: 44.3906 - val_mse: 0.1593 - val_mae: 0.1603\n",
      "Epoch 368/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5139 - mse: 0.0264 - mae: 0.0313 - val_loss: 44.3907 - val_mse: 0.1586 - val_mae: 0.1596\n",
      "Epoch 369/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5098 - mse: 0.0264 - mae: 0.0311 - val_loss: 44.3902 - val_mse: 0.1584 - val_mae: 0.1594\n",
      "Epoch 370/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5097 - mse: 0.0267 - mae: 0.0314 - val_loss: 44.3897 - val_mse: 0.1592 - val_mae: 0.1602\n",
      "Epoch 371/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.5094 - mse: 0.0258 - mae: 0.0305 - val_loss: 44.3898 - val_mse: 0.1581 - val_mae: 0.1591\n",
      "Epoch 372/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.5042 - mse: 0.0267 - mae: 0.0312 - val_loss: 44.3891 - val_mse: 0.1593 - val_mae: 0.1602\n",
      "Epoch 373/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5049 - mse: 0.0267 - mae: 0.0313 - val_loss: 44.3892 - val_mse: 0.1586 - val_mae: 0.1596\n",
      "Epoch 374/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5028 - mse: 0.0261 - mae: 0.0307 - val_loss: 44.3887 - val_mse: 0.1583 - val_mae: 0.1592\n",
      "Epoch 375/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.5015 - mse: 0.0265 - mae: 0.0310 - val_loss: 44.3885 - val_mse: 0.1590 - val_mae: 0.1599\n",
      "Epoch 376/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.5002 - mse: 0.0263 - mae: 0.0307 - val_loss: 44.3881 - val_mse: 0.1589 - val_mae: 0.1598\n",
      "Epoch 377/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4985 - mse: 0.0266 - mae: 0.0309 - val_loss: 44.3879 - val_mse: 0.1584 - val_mae: 0.1593\n",
      "Epoch 378/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4983 - mse: 0.0265 - mae: 0.0309 - val_loss: 44.3876 - val_mse: 0.1592 - val_mae: 0.1601\n",
      "Epoch 379/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4952 - mse: 0.0264 - mae: 0.0306 - val_loss: 44.3874 - val_mse: 0.1581 - val_mae: 0.1590\n",
      "Epoch 380/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4947 - mse: 0.0263 - mae: 0.0306 - val_loss: 44.3871 - val_mse: 0.1592 - val_mae: 0.1601\n",
      "Epoch 381/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4921 - mse: 0.0267 - mae: 0.0309 - val_loss: 44.3869 - val_mse: 0.1584 - val_mae: 0.1592\n",
      "Epoch 382/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4922 - mse: 0.0263 - mae: 0.0305 - val_loss: 44.3865 - val_mse: 0.1586 - val_mae: 0.1595\n",
      "Epoch 383/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4891 - mse: 0.0263 - mae: 0.0303 - val_loss: 44.3861 - val_mse: 0.1591 - val_mae: 0.1600\n",
      "Epoch 384/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4905 - mse: 0.0261 - mae: 0.0302 - val_loss: 44.3863 - val_mse: 0.1585 - val_mae: 0.1594\n",
      "Epoch 385/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.4864 - mse: 0.0269 - mae: 0.0309 - val_loss: 44.3858 - val_mse: 0.1586 - val_mae: 0.1595\n",
      "Epoch 386/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4864 - mse: 0.0265 - mae: 0.0305 - val_loss: 44.3855 - val_mse: 0.1590 - val_mae: 0.1599\n",
      "Epoch 387/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4841 - mse: 0.0265 - mae: 0.0305 - val_loss: 44.3853 - val_mse: 0.1584 - val_mae: 0.1593\n",
      "Epoch 388/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4833 - mse: 0.0262 - mae: 0.0300 - val_loss: 44.3851 - val_mse: 0.1586 - val_mae: 0.1595\n",
      "Epoch 389/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4819 - mse: 0.0268 - mae: 0.0306 - val_loss: 44.3848 - val_mse: 0.1591 - val_mae: 0.1599\n",
      "Epoch 390/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4813 - mse: 0.0261 - mae: 0.0300 - val_loss: 44.3846 - val_mse: 0.1583 - val_mae: 0.1591\n",
      "Epoch 391/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4795 - mse: 0.0267 - mae: 0.0305 - val_loss: 44.3843 - val_mse: 0.1594 - val_mae: 0.1602\n",
      "Epoch 392/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4789 - mse: 0.0261 - mae: 0.0299 - val_loss: 44.3842 - val_mse: 0.1583 - val_mae: 0.1591\n",
      "Epoch 393/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4777 - mse: 0.0266 - mae: 0.0303 - val_loss: 44.3837 - val_mse: 0.1590 - val_mae: 0.1598\n",
      "Epoch 394/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4762 - mse: 0.0264 - mae: 0.0301 - val_loss: 44.3839 - val_mse: 0.1589 - val_mae: 0.1597\n",
      "Epoch 395/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4756 - mse: 0.0263 - mae: 0.0300 - val_loss: 44.3835 - val_mse: 0.1582 - val_mae: 0.1590\n",
      "Epoch 396/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4736 - mse: 0.0264 - mae: 0.0300 - val_loss: 44.3830 - val_mse: 0.1591 - val_mae: 0.1598\n",
      "Epoch 397/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.4727 - mse: 0.0264 - mae: 0.0300 - val_loss: 44.3832 - val_mse: 0.1584 - val_mae: 0.1592\n",
      "Epoch 398/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4709 - mse: 0.0263 - mae: 0.0298 - val_loss: 44.3828 - val_mse: 0.1587 - val_mae: 0.1595\n",
      "Epoch 399/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4713 - mse: 0.0265 - mae: 0.0300 - val_loss: 44.3826 - val_mse: 0.1589 - val_mae: 0.1596\n",
      "Epoch 400/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4687 - mse: 0.0267 - mae: 0.0301 - val_loss: 44.3823 - val_mse: 0.1589 - val_mae: 0.1597\n",
      "Epoch 401/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4685 - mse: 0.0263 - mae: 0.0297 - val_loss: 44.3822 - val_mse: 0.1587 - val_mae: 0.1595\n",
      "Epoch 402/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4664 - mse: 0.0267 - mae: 0.0301 - val_loss: 44.3819 - val_mse: 0.1589 - val_mae: 0.1596\n",
      "Epoch 403/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4664 - mse: 0.0261 - mae: 0.0294 - val_loss: 44.3819 - val_mse: 0.1586 - val_mae: 0.1593\n",
      "Epoch 404/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4651 - mse: 0.0264 - mae: 0.0297 - val_loss: 44.3816 - val_mse: 0.1583 - val_mae: 0.1590\n",
      "Epoch 405/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4640 - mse: 0.0264 - mae: 0.0297 - val_loss: 44.3814 - val_mse: 0.1587 - val_mae: 0.1594\n",
      "Epoch 406/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4644 - mse: 0.0262 - mae: 0.0295 - val_loss: 44.3812 - val_mse: 0.1587 - val_mae: 0.1594\n",
      "Epoch 407/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4620 - mse: 0.0264 - mae: 0.0297 - val_loss: 44.3810 - val_mse: 0.1592 - val_mae: 0.1599\n",
      "Epoch 408/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4596 - mse: 0.0267 - mae: 0.0298 - val_loss: 44.3808 - val_mse: 0.1589 - val_mae: 0.1596\n",
      "Epoch 409/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4600 - mse: 0.0265 - mae: 0.0297 - val_loss: 44.3807 - val_mse: 0.1582 - val_mae: 0.1589\n",
      "Epoch 410/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4590 - mse: 0.0265 - mae: 0.0296 - val_loss: 44.3805 - val_mse: 0.1587 - val_mae: 0.1594\n",
      "Epoch 411/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4586 - mse: 0.0265 - mae: 0.0296 - val_loss: 44.3801 - val_mse: 0.1591 - val_mae: 0.1597\n",
      "Epoch 412/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4578 - mse: 0.0260 - mae: 0.0291 - val_loss: 44.3803 - val_mse: 0.1586 - val_mae: 0.1592\n",
      "Epoch 413/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4554 - mse: 0.0269 - mae: 0.0299 - val_loss: 44.3798 - val_mse: 0.1591 - val_mae: 0.1598\n",
      "Epoch 414/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4554 - mse: 0.0265 - mae: 0.0295 - val_loss: 44.3796 - val_mse: 0.1587 - val_mae: 0.1593\n",
      "Epoch 415/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4543 - mse: 0.0263 - mae: 0.0293 - val_loss: 44.3797 - val_mse: 0.1583 - val_mae: 0.1589\n",
      "Epoch 416/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4539 - mse: 0.0261 - mae: 0.0291 - val_loss: 44.3794 - val_mse: 0.1587 - val_mae: 0.1594\n",
      "Epoch 417/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4512 - mse: 0.0268 - mae: 0.0297 - val_loss: 44.3792 - val_mse: 0.1591 - val_mae: 0.1597\n",
      "Epoch 418/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4523 - mse: 0.0264 - mae: 0.0293 - val_loss: 44.3791 - val_mse: 0.1584 - val_mae: 0.1590\n",
      "Epoch 419/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4505 - mse: 0.0265 - mae: 0.0294 - val_loss: 44.3789 - val_mse: 0.1589 - val_mae: 0.1595\n",
      "Epoch 420/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4505 - mse: 0.0260 - mae: 0.0289 - val_loss: 44.3787 - val_mse: 0.1585 - val_mae: 0.1591\n",
      "Epoch 421/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4478 - mse: 0.0268 - mae: 0.0295 - val_loss: 44.3785 - val_mse: 0.1592 - val_mae: 0.1598\n",
      "Epoch 422/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4481 - mse: 0.0265 - mae: 0.0293 - val_loss: 44.3784 - val_mse: 0.1583 - val_mae: 0.1589\n",
      "Epoch 423/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4473 - mse: 0.0263 - mae: 0.0290 - val_loss: 44.3782 - val_mse: 0.1592 - val_mae: 0.1598\n",
      "Epoch 424/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4464 - mse: 0.0266 - mae: 0.0293 - val_loss: 44.3781 - val_mse: 0.1589 - val_mae: 0.1595\n",
      "Epoch 425/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4468 - mse: 0.0260 - mae: 0.0288 - val_loss: 44.3778 - val_mse: 0.1587 - val_mae: 0.1593\n",
      "Epoch 426/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.4437 - mse: 0.0268 - mae: 0.0294 - val_loss: 44.3779 - val_mse: 0.1583 - val_mae: 0.1589\n",
      "Epoch 427/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4440 - mse: 0.0264 - mae: 0.0290 - val_loss: 44.3777 - val_mse: 0.1589 - val_mae: 0.1594\n",
      "Epoch 428/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.4437 - mse: 0.0266 - mae: 0.0293 - val_loss: 44.3774 - val_mse: 0.1587 - val_mae: 0.1592\n",
      "Epoch 429/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4417 - mse: 0.0267 - mae: 0.0293 - val_loss: 44.3773 - val_mse: 0.1588 - val_mae: 0.1593\n",
      "Epoch 430/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4426 - mse: 0.0261 - mae: 0.0287 - val_loss: 44.3772 - val_mse: 0.1586 - val_mae: 0.1592\n",
      "Epoch 431/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4409 - mse: 0.0266 - mae: 0.0291 - val_loss: 44.3770 - val_mse: 0.1588 - val_mae: 0.1593\n",
      "Epoch 432/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4395 - mse: 0.0262 - mae: 0.0287 - val_loss: 44.3769 - val_mse: 0.1590 - val_mae: 0.1595\n",
      "Epoch 433/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4398 - mse: 0.0266 - mae: 0.0291 - val_loss: 44.3767 - val_mse: 0.1588 - val_mae: 0.1593\n",
      "Epoch 434/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4389 - mse: 0.0264 - mae: 0.0288 - val_loss: 44.3764 - val_mse: 0.1589 - val_mae: 0.1595\n",
      "Epoch 435/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4384 - mse: 0.0261 - mae: 0.0286 - val_loss: 44.3766 - val_mse: 0.1584 - val_mae: 0.1589\n",
      "Epoch 436/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4365 - mse: 0.0269 - mae: 0.0293 - val_loss: 44.3762 - val_mse: 0.1591 - val_mae: 0.1596\n",
      "Epoch 437/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.4366 - mse: 0.0265 - mae: 0.0289 - val_loss: 44.3762 - val_mse: 0.1588 - val_mae: 0.1593\n",
      "Epoch 438/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4357 - mse: 0.0265 - mae: 0.0288 - val_loss: 44.3762 - val_mse: 0.1585 - val_mae: 0.1590\n",
      "Epoch 439/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4351 - mse: 0.0265 - mae: 0.0288 - val_loss: 44.3759 - val_mse: 0.1587 - val_mae: 0.1592\n",
      "Epoch 440/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4346 - mse: 0.0264 - mae: 0.0287 - val_loss: 44.3758 - val_mse: 0.1591 - val_mae: 0.1596\n",
      "Epoch 441/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4336 - mse: 0.0266 - mae: 0.0289 - val_loss: 44.3757 - val_mse: 0.1584 - val_mae: 0.1589\n",
      "Epoch 442/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4328 - mse: 0.0266 - mae: 0.0289 - val_loss: 44.3755 - val_mse: 0.1591 - val_mae: 0.1596\n",
      "Epoch 443/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.4325 - mse: 0.0263 - mae: 0.0286 - val_loss: 44.3754 - val_mse: 0.1588 - val_mae: 0.1592\n",
      "Epoch 444/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4314 - mse: 0.0264 - mae: 0.0287 - val_loss: 44.3753 - val_mse: 0.1588 - val_mae: 0.1592\n",
      "Epoch 445/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4311 - mse: 0.0263 - mae: 0.0285 - val_loss: 44.3751 - val_mse: 0.1589 - val_mae: 0.1594\n",
      "Epoch 446/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4309 - mse: 0.0265 - mae: 0.0288 - val_loss: 44.3751 - val_mse: 0.1583 - val_mae: 0.1588\n",
      "Epoch 447/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4298 - mse: 0.0266 - mae: 0.0288 - val_loss: 44.3749 - val_mse: 0.1588 - val_mae: 0.1593\n",
      "Epoch 448/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4286 - mse: 0.0264 - mae: 0.0285 - val_loss: 44.3748 - val_mse: 0.1587 - val_mae: 0.1592\n",
      "Epoch 449/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4285 - mse: 0.0264 - mae: 0.0285 - val_loss: 44.3747 - val_mse: 0.1587 - val_mae: 0.1591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4284 - mse: 0.0265 - mae: 0.0286 - val_loss: 44.3744 - val_mse: 0.1592 - val_mae: 0.1597\n",
      "Epoch 451/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4273 - mse: 0.0266 - mae: 0.0287 - val_loss: 44.3746 - val_mse: 0.1584 - val_mae: 0.1589\n",
      "Epoch 452/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4270 - mse: 0.0260 - mae: 0.0281 - val_loss: 44.3743 - val_mse: 0.1588 - val_mae: 0.1592\n",
      "Epoch 453/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4252 - mse: 0.0268 - mae: 0.0288 - val_loss: 44.3741 - val_mse: 0.1591 - val_mae: 0.1595\n",
      "Epoch 454/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4264 - mse: 0.0261 - mae: 0.0282 - val_loss: 44.3742 - val_mse: 0.1585 - val_mae: 0.1589\n",
      "Epoch 455/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4245 - mse: 0.0269 - mae: 0.0290 - val_loss: 44.3740 - val_mse: 0.1591 - val_mae: 0.1595\n",
      "Epoch 456/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4243 - mse: 0.0263 - mae: 0.0283 - val_loss: 44.3739 - val_mse: 0.1589 - val_mae: 0.1594\n",
      "Epoch 457/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.4233 - mse: 0.0265 - mae: 0.0284 - val_loss: 44.3738 - val_mse: 0.1588 - val_mae: 0.1592\n",
      "Epoch 458/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.4237 - mse: 0.0266 - mae: 0.0286 - val_loss: 44.3736 - val_mse: 0.1586 - val_mae: 0.1590\n",
      "Epoch 459/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4219 - mse: 0.0267 - mae: 0.0286 - val_loss: 44.3735 - val_mse: 0.1589 - val_mae: 0.1593\n",
      "Epoch 460/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4227 - mse: 0.0261 - mae: 0.0281 - val_loss: 44.3734 - val_mse: 0.1588 - val_mae: 0.1592\n",
      "Epoch 461/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.4213 - mse: 0.0266 - mae: 0.0285 - val_loss: 44.3734 - val_mse: 0.1583 - val_mae: 0.1587\n",
      "Epoch 462/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4207 - mse: 0.0264 - mae: 0.0283 - val_loss: 44.3732 - val_mse: 0.1588 - val_mae: 0.1593\n",
      "Epoch 463/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4206 - mse: 0.0267 - mae: 0.0286 - val_loss: 44.3731 - val_mse: 0.1586 - val_mae: 0.1590\n",
      "Epoch 464/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4200 - mse: 0.0263 - mae: 0.0282 - val_loss: 44.3730 - val_mse: 0.1593 - val_mae: 0.1597\n",
      "Epoch 465/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.4195 - mse: 0.0265 - mae: 0.0283 - val_loss: 44.3730 - val_mse: 0.1583 - val_mae: 0.1587\n",
      "Epoch 466/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4193 - mse: 0.0260 - mae: 0.0279 - val_loss: 44.3728 - val_mse: 0.1588 - val_mae: 0.1592\n",
      "Epoch 467/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4174 - mse: 0.0272 - mae: 0.0290 - val_loss: 44.3727 - val_mse: 0.1587 - val_mae: 0.1591\n",
      "Epoch 468/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4180 - mse: 0.0261 - mae: 0.0279 - val_loss: 44.3726 - val_mse: 0.1593 - val_mae: 0.1597\n",
      "Epoch 469/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.4173 - mse: 0.0265 - mae: 0.0283 - val_loss: 44.3725 - val_mse: 0.1588 - val_mae: 0.1592\n",
      "Epoch 470/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.4173 - mse: 0.0265 - mae: 0.0283 - val_loss: 44.3724 - val_mse: 0.1581 - val_mae: 0.1585\n",
      "Epoch 471/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4159 - mse: 0.0265 - mae: 0.0283 - val_loss: 44.3723 - val_mse: 0.1589 - val_mae: 0.1593\n",
      "Epoch 472/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4161 - mse: 0.0265 - mae: 0.0282 - val_loss: 44.3722 - val_mse: 0.1586 - val_mae: 0.1590\n",
      "Epoch 473/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4151 - mse: 0.0264 - mae: 0.0281 - val_loss: 44.3721 - val_mse: 0.1589 - val_mae: 0.1593\n",
      "Epoch 474/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4152 - mse: 0.0266 - mae: 0.0283 - val_loss: 44.3720 - val_mse: 0.1593 - val_mae: 0.1597\n",
      "Epoch 475/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.4145 - mse: 0.0265 - mae: 0.0282 - val_loss: 44.3720 - val_mse: 0.1581 - val_mae: 0.1585\n",
      "Epoch 476/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4136 - mse: 0.0264 - mae: 0.0281 - val_loss: 44.3718 - val_mse: 0.1588 - val_mae: 0.1592\n",
      "Epoch 477/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4135 - mse: 0.0263 - mae: 0.0280 - val_loss: 44.3718 - val_mse: 0.1589 - val_mae: 0.1592\n",
      "Epoch 478/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4130 - mse: 0.0266 - mae: 0.0283 - val_loss: 44.3717 - val_mse: 0.1588 - val_mae: 0.1591\n",
      "Epoch 479/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4130 - mse: 0.0264 - mae: 0.0281 - val_loss: 44.3716 - val_mse: 0.1588 - val_mae: 0.1591\n",
      "Epoch 480/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4116 - mse: 0.0268 - mae: 0.0284 - val_loss: 44.3714 - val_mse: 0.1593 - val_mae: 0.1596\n",
      "Epoch 481/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4125 - mse: 0.0258 - mae: 0.0274 - val_loss: 44.3715 - val_mse: 0.1588 - val_mae: 0.1592\n",
      "Epoch 482/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4107 - mse: 0.0271 - mae: 0.0287 - val_loss: 44.3713 - val_mse: 0.1582 - val_mae: 0.1585\n",
      "Epoch 483/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4107 - mse: 0.0262 - mae: 0.0278 - val_loss: 44.3713 - val_mse: 0.1589 - val_mae: 0.1593\n",
      "Epoch 484/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4104 - mse: 0.0265 - mae: 0.0280 - val_loss: 44.3711 - val_mse: 0.1590 - val_mae: 0.1594\n",
      "Epoch 485/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.4103 - mse: 0.0265 - mae: 0.0280 - val_loss: 44.3712 - val_mse: 0.1590 - val_mae: 0.1593\n",
      "Epoch 486/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4090 - mse: 0.0268 - mae: 0.0284 - val_loss: 44.3710 - val_mse: 0.1583 - val_mae: 0.1586\n",
      "Epoch 487/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.4095 - mse: 0.0262 - mae: 0.0277 - val_loss: 44.3709 - val_mse: 0.1591 - val_mae: 0.1594\n",
      "Epoch 488/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4085 - mse: 0.0265 - mae: 0.0280 - val_loss: 44.3708 - val_mse: 0.1589 - val_mae: 0.1592\n",
      "Epoch 489/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4083 - mse: 0.0263 - mae: 0.0278 - val_loss: 44.3708 - val_mse: 0.1588 - val_mae: 0.1592\n",
      "Epoch 490/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4085 - mse: 0.0262 - mae: 0.0277 - val_loss: 44.3707 - val_mse: 0.1582 - val_mae: 0.1585\n",
      "Epoch 491/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4071 - mse: 0.0269 - mae: 0.0284 - val_loss: 44.3706 - val_mse: 0.1589 - val_mae: 0.1592\n",
      "Epoch 492/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4075 - mse: 0.0260 - mae: 0.0275 - val_loss: 44.3705 - val_mse: 0.1587 - val_mae: 0.1590\n",
      "Epoch 493/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4061 - mse: 0.0269 - mae: 0.0283 - val_loss: 44.3705 - val_mse: 0.1590 - val_mae: 0.1593\n",
      "Epoch 494/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4065 - mse: 0.0265 - mae: 0.0279 - val_loss: 44.3704 - val_mse: 0.1591 - val_mae: 0.1594\n",
      "Epoch 495/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4060 - mse: 0.0265 - mae: 0.0280 - val_loss: 44.3702 - val_mse: 0.1588 - val_mae: 0.1591\n",
      "Epoch 496/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4052 - mse: 0.0264 - mae: 0.0278 - val_loss: 44.3703 - val_mse: 0.1590 - val_mae: 0.1593\n",
      "Epoch 497/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4054 - mse: 0.0265 - mae: 0.0279 - val_loss: 44.3702 - val_mse: 0.1582 - val_mae: 0.1585\n",
      "Epoch 498/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4049 - mse: 0.0264 - mae: 0.0278 - val_loss: 44.3701 - val_mse: 0.1589 - val_mae: 0.1592\n",
      "Epoch 499/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4043 - mse: 0.0266 - mae: 0.0279 - val_loss: 44.3700 - val_mse: 0.1588 - val_mae: 0.1591\n",
      "Epoch 500/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4040 - mse: 0.0266 - mae: 0.0280 - val_loss: 44.3700 - val_mse: 0.1587 - val_mae: 0.1590\n",
      "Epoch 501/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4036 - mse: 0.0262 - mae: 0.0276 - val_loss: 44.3699 - val_mse: 0.1588 - val_mae: 0.1591\n",
      "Epoch 502/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.4036 - mse: 0.0265 - mae: 0.0278 - val_loss: 44.3698 - val_mse: 0.1588 - val_mae: 0.1591\n",
      "Epoch 503/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4026 - mse: 0.0264 - mae: 0.0277 - val_loss: 44.3697 - val_mse: 0.1589 - val_mae: 0.1591\n",
      "Epoch 504/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4026 - mse: 0.0266 - mae: 0.0279 - val_loss: 44.3696 - val_mse: 0.1591 - val_mae: 0.1593\n",
      "Epoch 505/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4023 - mse: 0.0264 - mae: 0.0277 - val_loss: 44.3697 - val_mse: 0.1590 - val_mae: 0.1593\n",
      "Epoch 506/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4019 - mse: 0.0266 - mae: 0.0279 - val_loss: 44.3695 - val_mse: 0.1588 - val_mae: 0.1591\n",
      "Epoch 507/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4016 - mse: 0.0265 - mae: 0.0278 - val_loss: 44.3695 - val_mse: 0.1582 - val_mae: 0.1585\n",
      "Epoch 508/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4015 - mse: 0.0265 - mae: 0.0278 - val_loss: 44.3694 - val_mse: 0.1589 - val_mae: 0.1591\n",
      "Epoch 509/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4006 - mse: 0.0264 - mae: 0.0277 - val_loss: 44.3693 - val_mse: 0.1587 - val_mae: 0.1590\n",
      "Epoch 510/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4006 - mse: 0.0266 - mae: 0.0279 - val_loss: 44.3693 - val_mse: 0.1588 - val_mae: 0.1591\n",
      "Epoch 511/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.4001 - mse: 0.0268 - mae: 0.0280 - val_loss: 44.3692 - val_mse: 0.1588 - val_mae: 0.1591\n",
      "Epoch 512/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.4003 - mse: 0.0261 - mae: 0.0274 - val_loss: 44.3692 - val_mse: 0.1587 - val_mae: 0.1589\n",
      "Epoch 513/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3992 - mse: 0.0268 - mae: 0.0281 - val_loss: 44.3690 - val_mse: 0.1592 - val_mae: 0.1595\n",
      "Epoch 514/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3995 - mse: 0.0264 - mae: 0.0276 - val_loss: 44.3691 - val_mse: 0.1583 - val_mae: 0.1586\n",
      "Epoch 515/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3991 - mse: 0.0263 - mae: 0.0275 - val_loss: 44.3690 - val_mse: 0.1591 - val_mae: 0.1593\n",
      "Epoch 516/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3985 - mse: 0.0267 - mae: 0.0278 - val_loss: 44.3689 - val_mse: 0.1588 - val_mae: 0.1590\n",
      "Epoch 517/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3985 - mse: 0.0262 - mae: 0.0274 - val_loss: 44.3688 - val_mse: 0.1586 - val_mae: 0.1589\n",
      "Epoch 518/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3980 - mse: 0.0265 - mae: 0.0277 - val_loss: 44.3688 - val_mse: 0.1588 - val_mae: 0.1590\n",
      "Epoch 519/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3976 - mse: 0.0266 - mae: 0.0277 - val_loss: 44.3687 - val_mse: 0.1593 - val_mae: 0.1595\n",
      "Epoch 520/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3972 - mse: 0.0264 - mae: 0.0275 - val_loss: 44.3687 - val_mse: 0.1585 - val_mae: 0.1587\n",
      "Epoch 521/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3970 - mse: 0.0268 - mae: 0.0280 - val_loss: 44.3685 - val_mse: 0.1591 - val_mae: 0.1594\n",
      "Epoch 522/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3971 - mse: 0.0262 - mae: 0.0274 - val_loss: 44.3686 - val_mse: 0.1582 - val_mae: 0.1585\n",
      "Epoch 523/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3964 - mse: 0.0267 - mae: 0.0278 - val_loss: 44.3685 - val_mse: 0.1590 - val_mae: 0.1592\n",
      "Epoch 524/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3961 - mse: 0.0263 - mae: 0.0274 - val_loss: 44.3684 - val_mse: 0.1586 - val_mae: 0.1589\n",
      "Epoch 525/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3964 - mse: 0.0261 - mae: 0.0272 - val_loss: 44.3684 - val_mse: 0.1589 - val_mae: 0.1591\n",
      "Epoch 526/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3952 - mse: 0.0268 - mae: 0.0279 - val_loss: 44.3683 - val_mse: 0.1587 - val_mae: 0.1589\n",
      "Epoch 527/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3954 - mse: 0.0265 - mae: 0.0276 - val_loss: 44.3682 - val_mse: 0.1593 - val_mae: 0.1595\n",
      "Epoch 528/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3951 - mse: 0.0265 - mae: 0.0276 - val_loss: 44.3682 - val_mse: 0.1583 - val_mae: 0.1586\n",
      "Epoch 529/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3950 - mse: 0.0266 - mae: 0.0277 - val_loss: 44.3681 - val_mse: 0.1594 - val_mae: 0.1596\n",
      "Epoch 530/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3946 - mse: 0.0265 - mae: 0.0275 - val_loss: 44.3682 - val_mse: 0.1585 - val_mae: 0.1587\n",
      "Epoch 531/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3941 - mse: 0.0263 - mae: 0.0274 - val_loss: 44.3680 - val_mse: 0.1590 - val_mae: 0.1592\n",
      "Epoch 532/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3942 - mse: 0.0267 - mae: 0.0277 - val_loss: 44.3681 - val_mse: 0.1584 - val_mae: 0.1586\n",
      "Epoch 533/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3936 - mse: 0.0265 - mae: 0.0275 - val_loss: 44.3680 - val_mse: 0.1589 - val_mae: 0.1592\n",
      "Epoch 534/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3939 - mse: 0.0261 - mae: 0.0271 - val_loss: 44.3679 - val_mse: 0.1586 - val_mae: 0.1589\n",
      "Epoch 535/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3932 - mse: 0.0265 - mae: 0.0275 - val_loss: 44.3679 - val_mse: 0.1589 - val_mae: 0.1591\n",
      "Epoch 536/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3926 - mse: 0.0271 - mae: 0.0281 - val_loss: 44.3678 - val_mse: 0.1593 - val_mae: 0.1595\n",
      "Epoch 537/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3927 - mse: 0.0265 - mae: 0.0275 - val_loss: 44.3678 - val_mse: 0.1587 - val_mae: 0.1589\n",
      "Epoch 538/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3922 - mse: 0.0266 - mae: 0.0276 - val_loss: 44.3677 - val_mse: 0.1585 - val_mae: 0.1587\n",
      "Epoch 539/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3925 - mse: 0.0261 - mae: 0.0271 - val_loss: 44.3676 - val_mse: 0.1588 - val_mae: 0.1590\n",
      "Epoch 540/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3919 - mse: 0.0266 - mae: 0.0276 - val_loss: 44.3676 - val_mse: 0.1593 - val_mae: 0.1595\n",
      "Epoch 541/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3917 - mse: 0.0265 - mae: 0.0275 - val_loss: 44.3675 - val_mse: 0.1586 - val_mae: 0.1588\n",
      "Epoch 542/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3915 - mse: 0.0265 - mae: 0.0275 - val_loss: 44.3675 - val_mse: 0.1584 - val_mae: 0.1586\n",
      "Epoch 543/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3912 - mse: 0.0264 - mae: 0.0273 - val_loss: 44.3675 - val_mse: 0.1590 - val_mae: 0.1592\n",
      "Epoch 544/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3910 - mse: 0.0265 - mae: 0.0274 - val_loss: 44.3674 - val_mse: 0.1586 - val_mae: 0.1588\n",
      "Epoch 545/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3907 - mse: 0.0266 - mae: 0.0275 - val_loss: 44.3673 - val_mse: 0.1594 - val_mae: 0.1596\n",
      "Epoch 546/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3905 - mse: 0.0264 - mae: 0.0273 - val_loss: 44.3673 - val_mse: 0.1582 - val_mae: 0.1584\n",
      "Epoch 547/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3899 - mse: 0.0269 - mae: 0.0278 - val_loss: 44.3673 - val_mse: 0.1592 - val_mae: 0.1594\n",
      "Epoch 548/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3902 - mse: 0.0264 - mae: 0.0273 - val_loss: 44.3673 - val_mse: 0.1586 - val_mae: 0.1588\n",
      "Epoch 549/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3898 - mse: 0.0265 - mae: 0.0274 - val_loss: 44.3671 - val_mse: 0.1592 - val_mae: 0.1594\n",
      "Epoch 550/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3896 - mse: 0.0263 - mae: 0.0272 - val_loss: 44.3671 - val_mse: 0.1588 - val_mae: 0.1590\n",
      "Epoch 551/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3894 - mse: 0.0265 - mae: 0.0274 - val_loss: 44.3671 - val_mse: 0.1586 - val_mae: 0.1588\n",
      "Epoch 552/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3891 - mse: 0.0263 - mae: 0.0272 - val_loss: 44.3671 - val_mse: 0.1586 - val_mae: 0.1588\n",
      "Epoch 553/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3888 - mse: 0.0266 - mae: 0.0275 - val_loss: 44.3670 - val_mse: 0.1590 - val_mae: 0.1592\n",
      "Epoch 554/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3887 - mse: 0.0264 - mae: 0.0273 - val_loss: 44.3669 - val_mse: 0.1588 - val_mae: 0.1590\n",
      "Epoch 555/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3883 - mse: 0.0268 - mae: 0.0276 - val_loss: 44.3670 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 556/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3885 - mse: 0.0259 - mae: 0.0267 - val_loss: 44.3669 - val_mse: 0.1589 - val_mae: 0.1591\n",
      "Epoch 557/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3876 - mse: 0.0272 - mae: 0.0280 - val_loss: 44.3668 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 558/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3879 - mse: 0.0261 - mae: 0.0270 - val_loss: 44.3668 - val_mse: 0.1589 - val_mae: 0.1591\n",
      "Epoch 559/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3877 - mse: 0.0268 - mae: 0.0276 - val_loss: 44.3668 - val_mse: 0.1589 - val_mae: 0.1591\n",
      "Epoch 560/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3875 - mse: 0.0264 - mae: 0.0272 - val_loss: 44.3666 - val_mse: 0.1591 - val_mae: 0.1593\n",
      "Epoch 561/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3870 - mse: 0.0263 - mae: 0.0272 - val_loss: 44.3667 - val_mse: 0.1584 - val_mae: 0.1586\n",
      "Epoch 562/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3872 - mse: 0.0266 - mae: 0.0275 - val_loss: 44.3666 - val_mse: 0.1586 - val_mae: 0.1588\n",
      "Epoch 563/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3865 - mse: 0.0267 - mae: 0.0275 - val_loss: 44.3665 - val_mse: 0.1592 - val_mae: 0.1594\n",
      "Epoch 564/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3869 - mse: 0.0261 - mae: 0.0269 - val_loss: 44.3666 - val_mse: 0.1586 - val_mae: 0.1588\n",
      "Epoch 565/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3864 - mse: 0.0266 - mae: 0.0274 - val_loss: 44.3665 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 566/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3860 - mse: 0.0264 - mae: 0.0272 - val_loss: 44.3664 - val_mse: 0.1592 - val_mae: 0.1594\n",
      "Epoch 567/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3861 - mse: 0.0267 - mae: 0.0275 - val_loss: 44.3665 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 568/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3859 - mse: 0.0263 - mae: 0.0271 - val_loss: 44.3664 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 569/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3854 - mse: 0.0268 - mae: 0.0275 - val_loss: 44.3664 - val_mse: 0.1584 - val_mae: 0.1586\n",
      "Epoch 570/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3856 - mse: 0.0262 - mae: 0.0270 - val_loss: 44.3663 - val_mse: 0.1591 - val_mae: 0.1593\n",
      "Epoch 571/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3851 - mse: 0.0264 - mae: 0.0272 - val_loss: 44.3663 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 572/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3850 - mse: 0.0266 - mae: 0.0273 - val_loss: 44.3662 - val_mse: 0.1593 - val_mae: 0.1595\n",
      "Epoch 573/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3848 - mse: 0.0268 - mae: 0.0275 - val_loss: 44.3663 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 574/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3849 - mse: 0.0262 - mae: 0.0270 - val_loss: 44.3661 - val_mse: 0.1587 - val_mae: 0.1589\n",
      "Epoch 575/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3845 - mse: 0.0265 - mae: 0.0273 - val_loss: 44.3661 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 576/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3842 - mse: 0.0264 - mae: 0.0272 - val_loss: 44.3661 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 577/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3841 - mse: 0.0265 - mae: 0.0273 - val_loss: 44.3660 - val_mse: 0.1591 - val_mae: 0.1593\n",
      "Epoch 578/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3838 - mse: 0.0266 - mae: 0.0273 - val_loss: 44.3661 - val_mse: 0.1590 - val_mae: 0.1592\n",
      "Epoch 579/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3837 - mse: 0.0262 - mae: 0.0269 - val_loss: 44.3660 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 580/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3836 - mse: 0.0265 - mae: 0.0272 - val_loss: 44.3660 - val_mse: 0.1588 - val_mae: 0.1590\n",
      "Epoch 581/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3835 - mse: 0.0268 - mae: 0.0275 - val_loss: 44.3659 - val_mse: 0.1587 - val_mae: 0.1589\n",
      "Epoch 582/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3831 - mse: 0.0266 - mae: 0.0273 - val_loss: 44.3659 - val_mse: 0.1588 - val_mae: 0.1590\n",
      "Epoch 583/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3833 - mse: 0.0261 - mae: 0.0268 - val_loss: 44.3659 - val_mse: 0.1588 - val_mae: 0.1590\n",
      "Epoch 584/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3829 - mse: 0.0265 - mae: 0.0272 - val_loss: 44.3658 - val_mse: 0.1591 - val_mae: 0.1592\n",
      "Epoch 585/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3827 - mse: 0.0266 - mae: 0.0273 - val_loss: 44.3658 - val_mse: 0.1590 - val_mae: 0.1591\n",
      "Epoch 586/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3824 - mse: 0.0263 - mae: 0.0269 - val_loss: 44.3658 - val_mse: 0.1584 - val_mae: 0.1585\n",
      "Epoch 587/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3826 - mse: 0.0267 - mae: 0.0274 - val_loss: 44.3657 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 588/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3821 - mse: 0.0266 - mae: 0.0273 - val_loss: 44.3657 - val_mse: 0.1588 - val_mae: 0.1590\n",
      "Epoch 589/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3822 - mse: 0.0262 - mae: 0.0269 - val_loss: 44.3657 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 590/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3820 - mse: 0.0262 - mae: 0.0268 - val_loss: 44.3656 - val_mse: 0.1583 - val_mae: 0.1585\n",
      "Epoch 591/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3816 - mse: 0.0269 - mae: 0.0276 - val_loss: 44.3656 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 592/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3816 - mse: 0.0264 - mae: 0.0270 - val_loss: 44.3656 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 593/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3812 - mse: 0.0269 - mae: 0.0275 - val_loss: 44.3655 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 594/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3814 - mse: 0.0261 - mae: 0.0268 - val_loss: 44.3655 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 595/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3813 - mse: 0.0266 - mae: 0.0272 - val_loss: 44.3654 - val_mse: 0.1591 - val_mae: 0.1593\n",
      "Epoch 596/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3809 - mse: 0.0264 - mae: 0.0270 - val_loss: 44.3655 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 597/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3808 - mse: 0.0264 - mae: 0.0270 - val_loss: 44.3654 - val_mse: 0.1590 - val_mae: 0.1591\n",
      "Epoch 598/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3808 - mse: 0.0267 - mae: 0.0273 - val_loss: 44.3654 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 599/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3805 - mse: 0.0265 - mae: 0.0271 - val_loss: 44.3654 - val_mse: 0.1586 - val_mae: 0.1588\n",
      "Epoch 600/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3804 - mse: 0.0265 - mae: 0.0271 - val_loss: 44.3653 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 601/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3802 - mse: 0.0267 - mae: 0.0273 - val_loss: 44.3653 - val_mse: 0.1590 - val_mae: 0.1591\n",
      "Epoch 602/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3802 - mse: 0.0264 - mae: 0.0270 - val_loss: 44.3653 - val_mse: 0.1586 - val_mae: 0.1588\n",
      "Epoch 603/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3799 - mse: 0.0265 - mae: 0.0270 - val_loss: 44.3652 - val_mse: 0.1592 - val_mae: 0.1594\n",
      "Epoch 604/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3796 - mse: 0.0268 - mae: 0.0274 - val_loss: 44.3653 - val_mse: 0.1586 - val_mae: 0.1588\n",
      "Epoch 605/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3798 - mse: 0.0262 - mae: 0.0268 - val_loss: 44.3652 - val_mse: 0.1586 - val_mae: 0.1588\n",
      "Epoch 606/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3796 - mse: 0.0265 - mae: 0.0271 - val_loss: 44.3651 - val_mse: 0.1587 - val_mae: 0.1589\n",
      "Epoch 607/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3794 - mse: 0.0265 - mae: 0.0271 - val_loss: 44.3651 - val_mse: 0.1592 - val_mae: 0.1594\n",
      "Epoch 608/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3791 - mse: 0.0264 - mae: 0.0269 - val_loss: 44.3651 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 609/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3792 - mse: 0.0266 - mae: 0.0272 - val_loss: 44.3651 - val_mse: 0.1590 - val_mae: 0.1591\n",
      "Epoch 610/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3790 - mse: 0.0265 - mae: 0.0271 - val_loss: 44.3650 - val_mse: 0.1583 - val_mae: 0.1585\n",
      "Epoch 611/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3788 - mse: 0.0265 - mae: 0.0270 - val_loss: 44.3650 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 612/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3787 - mse: 0.0265 - mae: 0.0271 - val_loss: 44.3650 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 613/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3785 - mse: 0.0263 - mae: 0.0269 - val_loss: 44.3649 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 614/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3785 - mse: 0.0265 - mae: 0.0270 - val_loss: 44.3650 - val_mse: 0.1585 - val_mae: 0.1587\n",
      "Epoch 615/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3784 - mse: 0.0268 - mae: 0.0274 - val_loss: 44.3649 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 616/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3782 - mse: 0.0263 - mae: 0.0269 - val_loss: 44.3648 - val_mse: 0.1590 - val_mae: 0.1591\n",
      "Epoch 617/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3780 - mse: 0.0263 - mae: 0.0269 - val_loss: 44.3649 - val_mse: 0.1585 - val_mae: 0.1587\n",
      "Epoch 618/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3779 - mse: 0.0265 - mae: 0.0270 - val_loss: 44.3648 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 619/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3780 - mse: 0.0267 - mae: 0.0272 - val_loss: 44.3648 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 620/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3776 - mse: 0.0264 - mae: 0.0269 - val_loss: 44.3648 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 621/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3776 - mse: 0.0264 - mae: 0.0269 - val_loss: 44.3648 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 622/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3776 - mse: 0.0266 - mae: 0.0271 - val_loss: 44.3647 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 623/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3773 - mse: 0.0265 - mae: 0.0270 - val_loss: 44.3647 - val_mse: 0.1590 - val_mae: 0.1591\n",
      "Epoch 624/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3770 - mse: 0.0269 - mae: 0.0274 - val_loss: 44.3647 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 625/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3772 - mse: 0.0264 - mae: 0.0269 - val_loss: 44.3647 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 626/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3769 - mse: 0.0263 - mae: 0.0268 - val_loss: 44.3646 - val_mse: 0.1582 - val_mae: 0.1583\n",
      "Epoch 627/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3769 - mse: 0.0265 - mae: 0.0270 - val_loss: 44.3646 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 628/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3768 - mse: 0.0264 - mae: 0.0269 - val_loss: 44.3646 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 629/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3766 - mse: 0.0265 - mae: 0.0270 - val_loss: 44.3646 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 630/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3765 - mse: 0.0266 - mae: 0.0271 - val_loss: 44.3646 - val_mse: 0.1584 - val_mae: 0.1585\n",
      "Epoch 631/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3763 - mse: 0.0265 - mae: 0.0270 - val_loss: 44.3645 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 632/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3764 - mse: 0.0264 - mae: 0.0269 - val_loss: 44.3645 - val_mse: 0.1584 - val_mae: 0.1585\n",
      "Epoch 633/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3761 - mse: 0.0266 - mae: 0.0270 - val_loss: 44.3644 - val_mse: 0.1591 - val_mae: 0.1592\n",
      "Epoch 634/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3761 - mse: 0.0265 - mae: 0.0270 - val_loss: 44.3645 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 635/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3759 - mse: 0.0268 - mae: 0.0273 - val_loss: 44.3644 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 636/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3760 - mse: 0.0262 - mae: 0.0267 - val_loss: 44.3644 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 637/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3759 - mse: 0.0261 - mae: 0.0265 - val_loss: 44.3644 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 638/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3756 - mse: 0.0270 - mae: 0.0274 - val_loss: 44.3644 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 639/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3754 - mse: 0.0267 - mae: 0.0272 - val_loss: 44.3644 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 640/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3755 - mse: 0.0261 - mae: 0.0265 - val_loss: 44.3643 - val_mse: 0.1591 - val_mae: 0.1592\n",
      "Epoch 641/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3755 - mse: 0.0262 - mae: 0.0267 - val_loss: 44.3643 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 642/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3750 - mse: 0.0268 - mae: 0.0272 - val_loss: 44.3643 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 643/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3753 - mse: 0.0262 - mae: 0.0267 - val_loss: 44.3643 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 644/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3749 - mse: 0.0269 - mae: 0.0274 - val_loss: 44.3643 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 645/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3749 - mse: 0.0265 - mae: 0.0269 - val_loss: 44.3642 - val_mse: 0.1584 - val_mae: 0.1585\n",
      "Epoch 646/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3748 - mse: 0.0267 - mae: 0.0271 - val_loss: 44.3642 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 647/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3747 - mse: 0.0263 - mae: 0.0267 - val_loss: 44.3642 - val_mse: 0.1590 - val_mae: 0.1591\n",
      "Epoch 648/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3746 - mse: 0.0264 - mae: 0.0269 - val_loss: 44.3642 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 649/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3746 - mse: 0.0266 - mae: 0.0270 - val_loss: 44.3642 - val_mse: 0.1582 - val_mae: 0.1583\n",
      "Epoch 650/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3744 - mse: 0.0265 - mae: 0.0269 - val_loss: 44.3641 - val_mse: 0.1594 - val_mae: 0.1595\n",
      "Epoch 651/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3744 - mse: 0.0266 - mae: 0.0270 - val_loss: 44.3641 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 652/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3741 - mse: 0.0263 - mae: 0.0267 - val_loss: 44.3641 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 653/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3741 - mse: 0.0266 - mae: 0.0270 - val_loss: 44.3640 - val_mse: 0.1591 - val_mae: 0.1592\n",
      "Epoch 654/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3742 - mse: 0.0262 - mae: 0.0266 - val_loss: 44.3641 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 655/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3739 - mse: 0.0269 - mae: 0.0273 - val_loss: 44.3640 - val_mse: 0.1591 - val_mae: 0.1592\n",
      "Epoch 656/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3738 - mse: 0.0264 - mae: 0.0268 - val_loss: 44.3640 - val_mse: 0.1584 - val_mae: 0.1585\n",
      "Epoch 657/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3737 - mse: 0.0269 - mae: 0.0273 - val_loss: 44.3640 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 658/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3737 - mse: 0.0262 - mae: 0.0266 - val_loss: 44.3640 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 659/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3736 - mse: 0.0265 - mae: 0.0269 - val_loss: 44.3640 - val_mse: 0.1584 - val_mae: 0.1585\n",
      "Epoch 660/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3735 - mse: 0.0264 - mae: 0.0268 - val_loss: 44.3640 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 661/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3734 - mse: 0.0265 - mae: 0.0269 - val_loss: 44.3639 - val_mse: 0.1594 - val_mae: 0.1595\n",
      "Epoch 662/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3734 - mse: 0.0268 - mae: 0.0272 - val_loss: 44.3639 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 663/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3732 - mse: 0.0263 - mae: 0.0267 - val_loss: 44.3639 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 664/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3733 - mse: 0.0261 - mae: 0.0265 - val_loss: 44.3639 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 665/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3729 - mse: 0.0272 - mae: 0.0276 - val_loss: 44.3639 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 666/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3730 - mse: 0.0261 - mae: 0.0264 - val_loss: 44.3638 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 667/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3729 - mse: 0.0269 - mae: 0.0273 - val_loss: 44.3638 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 668/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3730 - mse: 0.0261 - mae: 0.0265 - val_loss: 44.3638 - val_mse: 0.1582 - val_mae: 0.1583\n",
      "Epoch 669/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3727 - mse: 0.0265 - mae: 0.0269 - val_loss: 44.3638 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 670/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3727 - mse: 0.0265 - mae: 0.0269 - val_loss: 44.3638 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 671/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3726 - mse: 0.0268 - mae: 0.0271 - val_loss: 44.3638 - val_mse: 0.1590 - val_mae: 0.1591\n",
      "Epoch 672/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3725 - mse: 0.0262 - mae: 0.0266 - val_loss: 44.3637 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 673/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3724 - mse: 0.0265 - mae: 0.0269 - val_loss: 44.3637 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 674/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3724 - mse: 0.0266 - mae: 0.0270 - val_loss: 44.3637 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 675/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3722 - mse: 0.0268 - mae: 0.0271 - val_loss: 44.3637 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 676/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3723 - mse: 0.0262 - mae: 0.0266 - val_loss: 44.3637 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 677/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3720 - mse: 0.0268 - mae: 0.0271 - val_loss: 44.3637 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 678/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3721 - mse: 0.0262 - mae: 0.0266 - val_loss: 44.3636 - val_mse: 0.1590 - val_mae: 0.1591\n",
      "Epoch 679/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3720 - mse: 0.0266 - mae: 0.0269 - val_loss: 44.3636 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 680/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3719 - mse: 0.0265 - mae: 0.0268 - val_loss: 44.3636 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 681/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3717 - mse: 0.0263 - mae: 0.0267 - val_loss: 44.3636 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 682/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3718 - mse: 0.0267 - mae: 0.0270 - val_loss: 44.3636 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 683/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3716 - mse: 0.0265 - mae: 0.0268 - val_loss: 44.3636 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 684/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3715 - mse: 0.0268 - mae: 0.0271 - val_loss: 44.3635 - val_mse: 0.1591 - val_mae: 0.1592\n",
      "Epoch 685/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3717 - mse: 0.0258 - mae: 0.0261 - val_loss: 44.3636 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 686/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3713 - mse: 0.0272 - mae: 0.0275 - val_loss: 44.3635 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 687/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3714 - mse: 0.0265 - mae: 0.0268 - val_loss: 44.3635 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 688/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3714 - mse: 0.0261 - mae: 0.0265 - val_loss: 44.3635 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 689/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3711 - mse: 0.0265 - mae: 0.0268 - val_loss: 44.3635 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 690/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3712 - mse: 0.0266 - mae: 0.0269 - val_loss: 44.3635 - val_mse: 0.1586 - val_mae: 0.1587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 691/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3710 - mse: 0.0268 - mae: 0.0271 - val_loss: 44.3634 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 692/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3712 - mse: 0.0258 - mae: 0.0261 - val_loss: 44.3635 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 693/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3708 - mse: 0.0268 - mae: 0.0271 - val_loss: 44.3634 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 694/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3709 - mse: 0.0267 - mae: 0.0270 - val_loss: 44.3634 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 695/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3708 - mse: 0.0267 - mae: 0.0270 - val_loss: 44.3634 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 696/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3707 - mse: 0.0262 - mae: 0.0265 - val_loss: 44.3634 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 697/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3707 - mse: 0.0267 - mae: 0.0270 - val_loss: 44.3634 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 698/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3706 - mse: 0.0267 - mae: 0.0270 - val_loss: 44.3634 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 699/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3706 - mse: 0.0263 - mae: 0.0266 - val_loss: 44.3634 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 700/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3705 - mse: 0.0265 - mae: 0.0268 - val_loss: 44.3633 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 701/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3704 - mse: 0.0265 - mae: 0.0268 - val_loss: 44.3633 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 702/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3703 - mse: 0.0264 - mae: 0.0266 - val_loss: 44.3633 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 703/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3704 - mse: 0.0262 - mae: 0.0265 - val_loss: 44.3633 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 704/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3701 - mse: 0.0272 - mae: 0.0275 - val_loss: 44.3633 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 705/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3702 - mse: 0.0261 - mae: 0.0263 - val_loss: 44.3633 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 706/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3701 - mse: 0.0268 - mae: 0.0271 - val_loss: 44.3633 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 707/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3701 - mse: 0.0263 - mae: 0.0266 - val_loss: 44.3632 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 708/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3699 - mse: 0.0264 - mae: 0.0267 - val_loss: 44.3632 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 709/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3700 - mse: 0.0265 - mae: 0.0268 - val_loss: 44.3632 - val_mse: 0.1591 - val_mae: 0.1592\n",
      "Epoch 710/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3699 - mse: 0.0262 - mae: 0.0264 - val_loss: 44.3632 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 711/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3697 - mse: 0.0269 - mae: 0.0272 - val_loss: 44.3632 - val_mse: 0.1594 - val_mae: 0.1595\n",
      "Epoch 712/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3697 - mse: 0.0267 - mae: 0.0269 - val_loss: 44.3632 - val_mse: 0.1582 - val_mae: 0.1583\n",
      "Epoch 713/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3696 - mse: 0.0266 - mae: 0.0269 - val_loss: 44.3632 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 714/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3697 - mse: 0.0262 - mae: 0.0265 - val_loss: 44.3632 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 715/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3696 - mse: 0.0265 - mae: 0.0268 - val_loss: 44.3632 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 716/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3695 - mse: 0.0264 - mae: 0.0267 - val_loss: 44.3631 - val_mse: 0.1582 - val_mae: 0.1583\n",
      "Epoch 717/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3694 - mse: 0.0269 - mae: 0.0271 - val_loss: 44.3631 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 718/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3695 - mse: 0.0258 - mae: 0.0261 - val_loss: 44.3631 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 719/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3693 - mse: 0.0268 - mae: 0.0271 - val_loss: 44.3631 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 720/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3693 - mse: 0.0266 - mae: 0.0269 - val_loss: 44.3631 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 721/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3692 - mse: 0.0265 - mae: 0.0267 - val_loss: 44.3631 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 722/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3693 - mse: 0.0261 - mae: 0.0263 - val_loss: 44.3631 - val_mse: 0.1590 - val_mae: 0.1591\n",
      "Epoch 723/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3691 - mse: 0.0269 - mae: 0.0272 - val_loss: 44.3631 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 724/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3691 - mse: 0.0265 - mae: 0.0268 - val_loss: 44.3631 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 725/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3689 - mse: 0.0268 - mae: 0.0270 - val_loss: 44.3630 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 726/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3690 - mse: 0.0261 - mae: 0.0264 - val_loss: 44.3630 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 727/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3689 - mse: 0.0265 - mae: 0.0267 - val_loss: 44.3630 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 728/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3688 - mse: 0.0269 - mae: 0.0271 - val_loss: 44.3630 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 729/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3689 - mse: 0.0262 - mae: 0.0265 - val_loss: 44.3630 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 730/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3687 - mse: 0.0263 - mae: 0.0266 - val_loss: 44.3630 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 731/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3688 - mse: 0.0267 - mae: 0.0270 - val_loss: 44.3630 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 732/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3686 - mse: 0.0265 - mae: 0.0267 - val_loss: 44.3630 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 733/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3686 - mse: 0.0266 - mae: 0.0269 - val_loss: 44.3630 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 734/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3685 - mse: 0.0262 - mae: 0.0264 - val_loss: 44.3629 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 735/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3686 - mse: 0.0267 - mae: 0.0270 - val_loss: 44.3629 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 736/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3684 - mse: 0.0264 - mae: 0.0266 - val_loss: 44.3629 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 737/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3683 - mse: 0.0269 - mae: 0.0271 - val_loss: 44.3629 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 738/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3684 - mse: 0.0262 - mae: 0.0264 - val_loss: 44.3629 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 739/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3683 - mse: 0.0265 - mae: 0.0267 - val_loss: 44.3629 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 740/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3682 - mse: 0.0268 - mae: 0.0270 - val_loss: 44.3629 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 741/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3683 - mse: 0.0262 - mae: 0.0265 - val_loss: 44.3629 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 742/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3681 - mse: 0.0264 - mae: 0.0266 - val_loss: 44.3629 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 743/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3681 - mse: 0.0266 - mae: 0.0268 - val_loss: 44.3629 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 744/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3681 - mse: 0.0264 - mae: 0.0266 - val_loss: 44.3628 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 745/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3680 - mse: 0.0265 - mae: 0.0267 - val_loss: 44.3628 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 746/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3680 - mse: 0.0265 - mae: 0.0267 - val_loss: 44.3628 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 747/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3679 - mse: 0.0267 - mae: 0.0269 - val_loss: 44.3628 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 748/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3679 - mse: 0.0265 - mae: 0.0267 - val_loss: 44.3628 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 749/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3678 - mse: 0.0266 - mae: 0.0268 - val_loss: 44.3628 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 750/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3678 - mse: 0.0264 - mae: 0.0266 - val_loss: 44.3628 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 751/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3678 - mse: 0.0262 - mae: 0.0264 - val_loss: 44.3628 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 752/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3677 - mse: 0.0265 - mae: 0.0267 - val_loss: 44.3628 - val_mse: 0.1582 - val_mae: 0.1583\n",
      "Epoch 753/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3676 - mse: 0.0269 - mae: 0.0270 - val_loss: 44.3628 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 754/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3676 - mse: 0.0268 - mae: 0.0270 - val_loss: 44.3628 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 755/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3676 - mse: 0.0263 - mae: 0.0265 - val_loss: 44.3628 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 756/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3675 - mse: 0.0265 - mae: 0.0267 - val_loss: 44.3627 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 757/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3675 - mse: 0.0264 - mae: 0.0266 - val_loss: 44.3627 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 758/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3675 - mse: 0.0266 - mae: 0.0268 - val_loss: 44.3627 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 759/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3673 - mse: 0.0268 - mae: 0.0270 - val_loss: 44.3627 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 760/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3674 - mse: 0.0262 - mae: 0.0264 - val_loss: 44.3627 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 761/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3673 - mse: 0.0268 - mae: 0.0270 - val_loss: 44.3627 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 762/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3673 - mse: 0.0264 - mae: 0.0266 - val_loss: 44.3627 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 763/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3673 - mse: 0.0262 - mae: 0.0264 - val_loss: 44.3627 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 764/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3671 - mse: 0.0269 - mae: 0.0271 - val_loss: 44.3627 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 765/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3672 - mse: 0.0262 - mae: 0.0264 - val_loss: 44.3627 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 766/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3671 - mse: 0.0267 - mae: 0.0269 - val_loss: 44.3626 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 767/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3671 - mse: 0.0262 - mae: 0.0264 - val_loss: 44.3627 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 768/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3671 - mse: 0.0266 - mae: 0.0268 - val_loss: 44.3626 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 769/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3671 - mse: 0.0264 - mae: 0.0266 - val_loss: 44.3626 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 770/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3670 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3626 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 771/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3670 - mse: 0.0260 - mae: 0.0262 - val_loss: 44.3626 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 772/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3668 - mse: 0.0268 - mae: 0.0270 - val_loss: 44.3626 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 773/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3669 - mse: 0.0267 - mae: 0.0269 - val_loss: 44.3626 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 774/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3668 - mse: 0.0265 - mae: 0.0267 - val_loss: 44.3626 - val_mse: 0.1582 - val_mae: 0.1583\n",
      "Epoch 775/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3668 - mse: 0.0268 - mae: 0.0270 - val_loss: 44.3626 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 776/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3668 - mse: 0.0258 - mae: 0.0260 - val_loss: 44.3626 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 777/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3667 - mse: 0.0269 - mae: 0.0271 - val_loss: 44.3626 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 778/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3667 - mse: 0.0264 - mae: 0.0266 - val_loss: 44.3626 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 779/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3667 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3626 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 780/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3666 - mse: 0.0270 - mae: 0.0272 - val_loss: 44.3626 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 781/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3666 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3625 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 782/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3665 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3625 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 783/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3665 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3625 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 784/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3665 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3625 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 785/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3664 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3625 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 786/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3664 - mse: 0.0264 - mae: 0.0266 - val_loss: 44.3625 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 787/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3663 - mse: 0.0269 - mae: 0.0270 - val_loss: 44.3625 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 788/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3664 - mse: 0.0258 - mae: 0.0260 - val_loss: 44.3625 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 789/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3663 - mse: 0.0271 - mae: 0.0273 - val_loss: 44.3625 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 790/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3663 - mse: 0.0265 - mae: 0.0267 - val_loss: 44.3625 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 791/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3662 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3625 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 792/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3662 - mse: 0.0269 - mae: 0.0271 - val_loss: 44.3625 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 793/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3662 - mse: 0.0261 - mae: 0.0263 - val_loss: 44.3625 - val_mse: 0.1582 - val_mae: 0.1583\n",
      "Epoch 794/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3661 - mse: 0.0264 - mae: 0.0266 - val_loss: 44.3625 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 795/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3661 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3624 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 796/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3661 - mse: 0.0265 - mae: 0.0267 - val_loss: 44.3624 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 797/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3660 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3624 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 798/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3660 - mse: 0.0267 - mae: 0.0269 - val_loss: 44.3624 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 799/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3660 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3624 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 800/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3660 - mse: 0.0262 - mae: 0.0264 - val_loss: 44.3624 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 801/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3659 - mse: 0.0270 - mae: 0.0271 - val_loss: 44.3624 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 802/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3659 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3624 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 803/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3659 - mse: 0.0266 - mae: 0.0268 - val_loss: 44.3624 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 804/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3658 - mse: 0.0264 - mae: 0.0266 - val_loss: 44.3624 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 805/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3658 - mse: 0.0265 - mae: 0.0267 - val_loss: 44.3624 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 806/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3657 - mse: 0.0269 - mae: 0.0270 - val_loss: 44.3624 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 807/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3658 - mse: 0.0262 - mae: 0.0264 - val_loss: 44.3624 - val_mse: 0.1592 - val_mae: 0.1593\n",
      "Epoch 808/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3657 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3624 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 809/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3656 - mse: 0.0272 - mae: 0.0274 - val_loss: 44.3624 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 810/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3657 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3624 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 811/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3656 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3623 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 812/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3656 - mse: 0.0264 - mae: 0.0266 - val_loss: 44.3623 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 813/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3656 - mse: 0.0268 - mae: 0.0269 - val_loss: 44.3623 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 814/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3655 - mse: 0.0262 - mae: 0.0264 - val_loss: 44.3623 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 815/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3655 - mse: 0.0264 - mae: 0.0266 - val_loss: 44.3623 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 816/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3655 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3623 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 817/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3655 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3623 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 818/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3654 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3623 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 819/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3654 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3623 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 820/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3654 - mse: 0.0268 - mae: 0.0269 - val_loss: 44.3623 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 821/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3654 - mse: 0.0262 - mae: 0.0264 - val_loss: 44.3623 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 822/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3653 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3623 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 823/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3653 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3623 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 824/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3653 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3623 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 825/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3652 - mse: 0.0268 - mae: 0.0269 - val_loss: 44.3623 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 826/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3652 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3623 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 827/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3653 - mse: 0.0262 - mae: 0.0264 - val_loss: 44.3622 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 828/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3651 - mse: 0.0268 - mae: 0.0269 - val_loss: 44.3623 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 829/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3652 - mse: 0.0269 - mae: 0.0270 - val_loss: 44.3623 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 830/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3651 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3622 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 831/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3651 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3622 - val_mse: 0.1593 - val_mae: 0.1594\n",
      "Epoch 832/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3651 - mse: 0.0268 - mae: 0.0269 - val_loss: 44.3622 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 833/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3650 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3622 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 834/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3651 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3622 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 835/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3650 - mse: 0.0260 - mae: 0.0261 - val_loss: 44.3622 - val_mse: 0.1589 - val_mae: 0.1590\n",
      "Epoch 836/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3649 - mse: 0.0268 - mae: 0.0269 - val_loss: 44.3622 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 837/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3650 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3622 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 838/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3649 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3622 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 839/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3649 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3622 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 840/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3649 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3622 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 841/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3649 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3622 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 842/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3648 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3622 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 843/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3648 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3622 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 844/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3648 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3622 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 845/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3648 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3622 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 846/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3647 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3622 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 847/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3648 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3622 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 848/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3647 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3622 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 849/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3647 - mse: 0.0270 - mae: 0.0271 - val_loss: 44.3621 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 850/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3647 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3621 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 851/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3647 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3621 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 852/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3646 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3621 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 853/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3646 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3621 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 854/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3646 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3621 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 855/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3646 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3621 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 856/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3645 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3621 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 857/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3645 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3621 - val_mse: 0.1591 - val_mae: 0.1592\n",
      "Epoch 858/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3645 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3621 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 859/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3645 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3621 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 860/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3645 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3621 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 861/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3644 - mse: 0.0269 - mae: 0.0270 - val_loss: 44.3621 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 862/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3644 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3621 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 863/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3644 - mse: 0.0268 - mae: 0.0269 - val_loss: 44.3621 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 864/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3644 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3621 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 865/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3643 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3621 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 866/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3643 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3621 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 867/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3643 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3621 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 868/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3643 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3621 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 869/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3643 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3621 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 870/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3643 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3621 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 871/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3642 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3621 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 872/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3642 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3621 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 873/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3642 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3620 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 874/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3642 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3620 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 875/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3641 - mse: 0.0268 - mae: 0.0269 - val_loss: 44.3620 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 876/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3642 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3620 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 877/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3641 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3620 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 878/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.3641 - mse: 0.0268 - mae: 0.0269 - val_loss: 44.3620 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 879/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3641 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3620 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 880/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3641 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3620 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 881/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3641 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3620 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 882/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3640 - mse: 0.0268 - mae: 0.0269 - val_loss: 44.3620 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 883/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3640 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3620 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 884/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3640 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3620 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 885/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3640 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3620 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 886/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3640 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3620 - val_mse: 0.1584 - val_mae: 0.1585\n",
      "Epoch 887/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3640 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3620 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 888/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3640 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3620 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 889/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3639 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3620 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 890/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3639 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3620 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 891/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3639 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3620 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 892/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3639 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3620 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 893/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3639 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3620 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 894/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3638 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3620 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 895/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3639 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3620 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 896/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3638 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3620 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 897/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3638 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3620 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 898/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3638 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3620 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 899/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3638 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3620 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 900/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3638 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3620 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 901/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3637 - mse: 0.0268 - mae: 0.0269 - val_loss: 44.3619 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 902/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3637 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3619 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 903/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3637 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3619 - val_mse: 0.1584 - val_mae: 0.1585\n",
      "Epoch 904/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3637 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3619 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 905/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3637 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3619 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 906/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3637 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3619 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 907/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3637 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3619 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 908/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3636 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3619 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 909/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3636 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3619 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 910/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3636 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3619 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 911/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3636 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3619 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 912/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3636 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3619 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 913/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3636 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3619 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 914/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3636 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3619 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 915/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3635 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3619 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 916/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3636 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3619 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 917/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3635 - mse: 0.0270 - mae: 0.0271 - val_loss: 44.3619 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 918/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3635 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3619 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 919/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3635 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3619 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 920/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3635 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3619 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 921/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3635 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3619 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 922/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3635 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3619 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 923/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3634 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3619 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 924/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3634 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3619 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 925/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3634 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3619 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 926/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3634 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3619 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 927/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3634 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3619 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 928/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3633 - mse: 0.0272 - mae: 0.0273 - val_loss: 44.3619 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 929/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3634 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3619 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 930/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3633 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3619 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 931/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3633 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3619 - val_mse: 0.1588 - val_mae: 0.1589\n",
      "Epoch 932/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3633 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3619 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 933/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3633 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3619 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 934/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3633 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3619 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 935/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3633 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3618 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 936/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3633 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3619 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 937/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3633 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3619 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 938/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3633 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3618 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 939/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3632 - mse: 0.0260 - mae: 0.0261 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 940/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3632 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3618 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 941/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3632 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3618 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 942/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3632 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 943/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3632 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3618 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 944/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3632 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3618 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 945/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3632 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3618 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 946/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3632 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3618 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 947/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3631 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3618 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 948/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3631 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3618 - val_mse: 0.1594 - val_mae: 0.1595\n",
      "Epoch 949/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3631 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 950/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3631 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3618 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 951/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3631 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 952/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3631 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3618 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 953/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3631 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3618 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 954/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3631 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3618 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 955/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3631 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 956/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3631 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3618 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 957/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3630 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 958/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3630 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 959/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3630 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3618 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 960/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3630 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3618 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 961/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3630 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3618 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 962/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3630 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 963/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3630 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3618 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 964/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3630 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3618 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 965/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3629 - mse: 0.0271 - mae: 0.0272 - val_loss: 44.3618 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 966/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3630 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 967/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3629 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3618 - val_mse: 0.1587 - val_mae: 0.1588\n",
      "Epoch 968/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3629 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3618 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 969/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3629 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3618 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 970/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3629 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3618 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 971/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3629 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3618 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 972/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3629 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3618 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 973/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3629 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3618 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 974/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3629 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3618 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 975/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3629 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 976/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3629 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3618 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 977/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3628 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3618 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 978/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3628 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3618 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 979/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3628 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3618 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 980/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3628 - mse: 0.0271 - mae: 0.0272 - val_loss: 44.3618 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 981/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3628 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3618 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 982/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3628 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3617 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 983/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3628 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3618 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 984/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3628 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3617 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 985/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3628 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3617 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 986/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3628 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3617 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 987/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3628 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3617 - val_mse: 0.1584 - val_mae: 0.1585\n",
      "Epoch 988/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3627 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3617 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 989/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3627 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 990/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3627 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 991/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3627 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3617 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 992/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3627 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3617 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 993/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3627 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3617 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 994/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3627 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3617 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 995/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3627 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3617 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 996/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3627 - mse: 0.0269 - mae: 0.0270 - val_loss: 44.3617 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 997/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3627 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 998/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3627 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3617 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 999/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3627 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3617 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1000/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3627 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3617 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1001/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3626 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3617 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1002/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3626 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3617 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1003/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3626 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3617 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1004/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3626 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1005/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3626 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3617 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1006/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3626 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3617 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1007/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3626 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3617 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1008/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3626 - mse: 0.0262 - mae: 0.0262 - val_loss: 44.3617 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1009/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3626 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3617 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1010/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3626 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3617 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1011/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3626 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3617 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1012/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3626 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3617 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1013/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3626 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3617 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1014/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3626 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3617 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 1015/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3625 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3617 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1016/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3625 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3617 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1017/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3625 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3617 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 1018/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3625 - mse: 0.0269 - mae: 0.0270 - val_loss: 44.3617 - val_mse: 0.1586 - val_mae: 0.1587\n",
      "Epoch 1019/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3625 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3617 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1020/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3625 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3617 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1021/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3625 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3617 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1022/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3625 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1023/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3625 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3617 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1024/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3625 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3617 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1025/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3625 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3617 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1026/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3625 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3617 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1027/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3625 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3617 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1028/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3625 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3617 - val_mse: 0.1584 - val_mae: 0.1584\n",
      "Epoch 1029/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3624 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3617 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1030/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3625 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3617 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1031/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3624 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3617 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 1032/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3624 - mse: 0.0271 - mae: 0.0272 - val_loss: 44.3617 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1033/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3624 - mse: 0.0263 - mae: 0.0263 - val_loss: 44.3617 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1034/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3624 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1035/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3624 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3617 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1036/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3624 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3617 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1037/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3624 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3617 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1038/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3624 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3617 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1039/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3624 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3617 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1040/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3624 - mse: 0.0267 - mae: 0.0268 - val_loss: 44.3617 - val_mse: 0.1583 - val_mae: 0.1583\n",
      "Epoch 1041/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3624 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3617 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1042/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3624 - mse: 0.0265 - mae: 0.0266 - val_loss: 44.3617 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1043/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3624 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3617 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1044/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3624 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3617 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1045/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3624 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1046/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3623 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1047/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3623 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3617 - val_mse: 0.1585 - val_mae: 0.1586\n",
      "Epoch 1048/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3623 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3616 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1049/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3623 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1050/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3623 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1051/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3623 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1052/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3623 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1593 - val_mae: 0.1593\n",
      "Epoch 1053/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3623 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1583 - val_mae: 0.1584\n",
      "Epoch 1054/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3623 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3616 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1055/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3623 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1056/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3623 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1057/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3623 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3616 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1058/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3623 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1582 - val_mae: 0.1582\n",
      "Epoch 1059/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3623 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1060/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3623 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1061/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3623 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3616 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1062/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3623 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1594 - val_mae: 0.1594\n",
      "Epoch 1063/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3622 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1064/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3623 - mse: 0.0264 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1065/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3622 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1066/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3622 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1591 - val_mae: 0.1591\n",
      "Epoch 1067/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3622 - mse: 0.0261 - mae: 0.0261 - val_loss: 44.3616 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1068/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3622 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3616 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1069/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3622 - mse: 0.0270 - mae: 0.0270 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1070/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3622 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3616 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1071/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3622 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1072/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3622 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3616 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1073/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3622 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3616 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1074/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3622 - mse: 0.0260 - mae: 0.0260 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1075/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3622 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1076/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3622 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1077/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3622 - mse: 0.0265 - mae: 0.0265 - val_loss: 44.3616 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1078/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3622 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1079/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3622 - mse: 0.0268 - mae: 0.0268 - val_loss: 44.3616 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1080/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 44.3622 - mse: 0.0261 - mae: 0.0262 - val_loss: 44.3616 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1081/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3622 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1082/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3622 - mse: 0.0263 - mae: 0.0264 - val_loss: 44.3616 - val_mse: 0.1589 - val_mae: 0.1589\n",
      "Epoch 1083/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3622 - mse: 0.0267 - mae: 0.0267 - val_loss: 44.3616 - val_mse: 0.1590 - val_mae: 0.1590\n",
      "Epoch 1084/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3621 - mse: 0.0264 - mae: 0.0264 - val_loss: 44.3616 - val_mse: 0.1592 - val_mae: 0.1592\n",
      "Epoch 1085/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 44.3621 - mse: 0.0269 - mae: 0.0269 - val_loss: 44.3616 - val_mse: 0.1586 - val_mae: 0.1586\n",
      "Epoch 1086/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3622 - mse: 0.0262 - mae: 0.0263 - val_loss: 44.3616 - val_mse: 0.1588 - val_mae: 0.1588\n",
      "Epoch 1087/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3621 - mse: 0.0266 - mae: 0.0266 - val_loss: 44.3616 - val_mse: 0.1585 - val_mae: 0.1585\n",
      "Epoch 1088/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 44.3621 - mse: 0.0266 - mae: 0.0267 - val_loss: 44.3616 - val_mse: 0.1587 - val_mae: 0.1587\n",
      "Epoch 1089/2000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 44.3622 - mse: 0.0225 - mae: 0.0225"
     ]
    }
   ],
   "source": [
    "t = Trainer(testnetBernoulli,\n",
    "                    NLL,\n",
    "                    (train,test),\n",
    "                    batch_size = 1,\n",
    "                    optimizer=optimizer,\n",
    "                    dimension = dimension,\n",
    "                    channels = channels,\n",
    "                    metrics = [\"mse\",\"mae\"])\n",
    "\n",
    "print(\"len train,val\",len(train),len(test))\n",
    "t.fit(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "history = t.history\n",
    "def plotHistory():\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history['mse'])\n",
    "    plt.plot(history['val_mse'])\n",
    "    plt.title('Model MSE')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "plotHistory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
