{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs: 1\n",
      "Num GPUs Available: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from Utils.loadset import getDataSet\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import os\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "print(\"Num GPUs:\", len(physical_devices)) \n",
    "\n",
    "from trainer import Trainer\n",
    "try:\n",
    "    from Utils.connection_cfg import *\n",
    "except Exception as e:\n",
    "    PSWD = None\n",
    "    USRN = None\n",
    "    \n",
    "from Utils.Data import dataWrapper\n",
    "\n",
    "from tensorflow.keras.backend import int_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = (64,64)\n",
    "channels = 5\n",
    "optimizer = Adam( lr = 1e-5 )\n",
    "tfd = tfp.distributions\n",
    "def NLL(y_true, y_hat):\n",
    "    return -y_hat.log_prob(y_true)\n",
    "                           \n",
    "def zeroInflatedPoisson(output):\n",
    "        rate = tf.math.exp(output[0,:,:,0]) #A \n",
    "        s = tf.math.sigmoid(output[0,:,:,1])\n",
    "        components = [tfd.Deterministic(loc=tf.zeros_like(rate)), #E\n",
    "         tfd.Poisson(rate=rate) #F \n",
    "         ]\n",
    "        mixture = tfd.Mixture(\n",
    "              cat=tfd.Categorical(probs=tf.stack([1-s, s],axis=-1)),#D\n",
    "              components=components)\n",
    "        return mixture\n",
    "\n",
    "def lstmLayer(inp,filters = [20,20]):\n",
    "\n",
    "    shape_inp = int_shape(inp)\n",
    "\n",
    "\n",
    "    lstm_shape = Reshape((shape_inp[-1],shape_inp[1],shape_inp[2],1))(inp)\n",
    "    \n",
    "\n",
    "    lstm_conv = ConvLSTM2D(filters=filters[0], kernel_size=(3, 3), activation='relu',\n",
    "                       padding='same', return_sequences=True,data_format='channels_last')(lstm_shape)\n",
    "    \n",
    "    lstm_conv = BatchNormalization() (lstm_conv)\n",
    "\n",
    "    for i in filters[1:-1]:\n",
    "        lstm_conv = ConvLSTM2D(filters=i, kernel_size=(3, 3), activation='relu',\n",
    "                       padding='same', return_sequences=True,data_format='channels_last')(lstm_conv)\n",
    "        lstm_conv = BatchNormalization() (lstm_conv)\n",
    "\n",
    "    lstm_conv = ConvLSTM2D(filters=filters[-1], kernel_size=(3, 3), activation='relu',\n",
    "                       padding='same', return_sequences=False,data_format='channels_last')(lstm_conv)\n",
    "    lstm_conv = BatchNormalization() (lstm_conv)\n",
    "\n",
    "    return lstm_conv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def testnet_LSTM_Meets_Unet_Upconv_Poisson(input_shape,\n",
    "                    n_predictions=1,\n",
    "                    simpleclassification=None,\n",
    "                    flatten_output=False,\n",
    "                    activation_hidden=\"relu\",\n",
    "                    activation_output=\"relu\"):\n",
    "\n",
    "\n",
    "    def zeroInflatedPoisson(output):\n",
    "        rate = tf.math.exp(output[0,:,:,0]) #A \n",
    "        s = tf.math.sigmoid(output[0,:,:,1])\n",
    "        components = [tfd.Deterministic(loc=tf.zeros_like(rate)), #E\n",
    "         tfd.Poisson(rate=rate) #F \n",
    "         ]\n",
    "        mixture = tfd.Mixture(\n",
    "              cat=tfd.Categorical(probs=tf.stack([1-s, s],axis=-1)),#D\n",
    "              components=components)\n",
    "        return mixture\n",
    "\n",
    "    def poss(output):\n",
    "        rate = tf.math.exp(output)\n",
    "        return tfp.layers.IndependentPoisson(rate)\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "\n",
    "    conv01 = Conv2D(10, kernel_size=(3, 3), padding=\"same\")(inputs)       \n",
    "    conv01 = Activation(activation_hidden)(conv01)\n",
    "    conv01 = BatchNormalization() (conv01)\n",
    "    conv01_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv01)            \n",
    "    \n",
    "\n",
    "    conv02 = Conv2D(20, kernel_size=(3, 3), padding=\"same\")(conv01_pool)  \n",
    "    conv02 = Activation(activation_hidden)(conv02)\n",
    "    conv02 = BatchNormalization() (conv02)\n",
    "    conv02_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv02)            \n",
    "    \n",
    "    conv03 = Conv2D(20, kernel_size=(3, 3), padding=\"same\")(conv02_pool)  \n",
    "    conv03 = Activation(activation_hidden)(conv03)\n",
    "    conv03 = BatchNormalization() (conv03)\n",
    "    conv03_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv03)            \n",
    "    \n",
    "\n",
    "    lstm_conv3 = lstmLayer(conv03,filters = [20,20,20])\n",
    "    lstm_conv3 = BatchNormalization() (lstm_conv3)\n",
    "    conv03 = concatenate([conv03, lstm_conv3], axis=3)\n",
    "\n",
    "    conv04 = Conv2D(20, kernel_size=(3, 3), padding=\"same\")(conv03_pool)  \n",
    "    conv04 = Activation(activation_hidden)(conv04)\n",
    "    conv04 = BatchNormalization() (conv04)\n",
    "    conv04_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv04)            \n",
    "    \n",
    "\n",
    "    lstm_conv4 = lstmLayer(conv04,filters = [20,20,20,20])\n",
    "    lstm_conv4 = BatchNormalization() (lstm_conv4)\n",
    "\n",
    "    conv04 = concatenate([conv04, lstm_conv4], axis=3)\n",
    "\n",
    "    ### UPSAMPLING:\n",
    "    up04 = Conv2DTranspose(20,(3, 3),strides=(2,2),padding=\"same\")(conv04_pool)    \n",
    "    up04 = BatchNormalization() (up04)\n",
    "    up04 = concatenate([conv04, up04], axis=3)  \n",
    "    up04 = Conv2D(20, kernel_size=(3, 3), padding=\"same\")(up04)  \n",
    "    \n",
    "\n",
    "    up03 = Conv2DTranspose(20,(3, 3),strides=(2,2),padding=\"same\")(up04)           \n",
    "    up03 = BatchNormalization() (up03)\n",
    "    up03 = concatenate([conv03, up03], axis=3)  \n",
    "    up03 = Conv2D(20, kernel_size=(3, 3), padding=\"same\")(up03)  \n",
    "    \n",
    "\n",
    "    up02 = Conv2DTranspose(20,(3, 3),strides=(2,2),padding=\"same\")(up03)           \n",
    "    up02 = BatchNormalization() (up02)\n",
    "    up02 = concatenate([conv02, up02], axis=3)  \n",
    "    up02 = Conv2D(20, kernel_size=(3, 3), padding=\"same\")(up02)  \n",
    "    \n",
    "\n",
    "    up01 = Conv2DTranspose(20,(3, 3),strides=(2,2),padding=\"same\")(up02)           \n",
    "    up01 = BatchNormalization() (up01)\n",
    "    up01 = concatenate([conv01, up01], axis=3)  \n",
    "    up01 = Conv2D(20, kernel_size=(3, 3), padding=\"same\")(up01)  \n",
    "    \n",
    "    output = Conv2D(64, (1, 1), activation=tf.exp)(up01) \n",
    "    \n",
    "    \n",
    "    #output = tfp.layers.DistributionLambda(zeroInflatedPoisson)(output)\n",
    "    output = tfp.layers.DistributionLambda(tfp.distributions.Poisson)(output)\n",
    "    #output = tfp.layers.DistributionLambda(poss)(output)\n",
    "    #output = tfp.layers.IndependentPoisson()(output)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "def testnet_LSTM_Meets_Unet_Upconv_Poisson(input_shape,\n",
    "                    n_predictions=1,\n",
    "                    simpleclassification=None,\n",
    "                    flatten_output=False,\n",
    "                    activation_hidden=\"relu\",\n",
    "                    activation_output=\"relu\"):\n",
    "\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "\n",
    "    conv01 = Conv2D(64, kernel_size=(3, 3), padding=\"same\")(inputs)       \n",
    "    conv01 = Activation(activation_hidden)(conv01)\n",
    "    conv01 = BatchNormalization() (conv01)\n",
    "    conv01_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv01)            \n",
    "\n",
    "\n",
    "    conv02 = Conv2D(256, kernel_size=(3, 3), padding=\"same\")(conv01_pool)  \n",
    "    conv02 = Activation(activation_hidden)(conv02)\n",
    "    conv02 = BatchNormalization() (conv02)\n",
    "    conv02_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv02)            \n",
    "\n",
    "    conv03 = Conv2D(512, kernel_size=(3, 3), padding=\"same\")(conv02_pool)  \n",
    "    conv03 = Activation(activation_hidden)(conv03)\n",
    "    conv03 = BatchNormalization() (conv03)\n",
    "    conv03_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv03)            \n",
    "\n",
    "\n",
    "    #lstm_conv3 = lstmLayer(conv03,filters = [20,20])\n",
    "    lstm_conv3 = conv03\n",
    "    lstm_conv3 = BatchNormalization() (lstm_conv3)\n",
    "    conv03 = concatenate([conv03, lstm_conv3], axis=3)\n",
    "\n",
    "    conv04 = Conv2D(1024, kernel_size=(3, 3), padding=\"same\")(conv03_pool)  \n",
    "    conv04 = Activation(activation_hidden)(conv04)\n",
    "    conv04 = BatchNormalization() (conv04)\n",
    "    conv04_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv04)            \n",
    "\n",
    "\n",
    "    lstm_conv4 = conv04\n",
    "    #lstm_conv4 = lstmLayer(conv04,filters = [20,20,20,20])\n",
    "    lstm_conv4 = BatchNormalization() (lstm_conv4)\n",
    "\n",
    "    conv04 = concatenate([conv04, lstm_conv4], axis=3)\n",
    "\n",
    "    ### UPSAMPLING:\n",
    "    up04 = Conv2DTranspose(512,(3, 3),strides=(2,2),padding=\"same\")(conv04_pool)    \n",
    "    up04 = BatchNormalization() (up04)\n",
    "    up04 = concatenate([conv04, up04], axis=3)  \n",
    "    up04 = Conv2D(512, kernel_size=(3, 3), padding=\"same\")(up04)  \n",
    "\n",
    "\n",
    "    up03 = Conv2DTranspose(20,(3, 3),strides=(2,2),padding=\"same\")(up04)           \n",
    "    up03 = BatchNormalization() (up03)\n",
    "    up03 = concatenate([conv03, up03], axis=3)  \n",
    "    up03 = Conv2D(256, kernel_size=(3, 3), padding=\"same\")(up03)  \n",
    "\n",
    "\n",
    "    up02 = Conv2DTranspose(20,(3, 3),strides=(2,2),padding=\"same\")(up03)           \n",
    "    up02 = BatchNormalization() (up02)\n",
    "    up02 = concatenate([conv02, up02], axis=3)  \n",
    "    up02 = Conv2D(128, kernel_size=(3, 3), padding=\"same\")(up02)  \n",
    "\n",
    "\n",
    "    up01 = Conv2DTranspose(20,(3, 3),strides=(2,2),padding=\"same\")(up02)           \n",
    "    up01 = BatchNormalization() (up01)\n",
    "    up01 = concatenate([conv01, up01], axis=3)  \n",
    "    up01 = Conv2D(64, kernel_size=(3, 3), padding=\"same\")(up01)  \n",
    "\n",
    "    output = Conv2D(1, (1, 1), activation=tf.exp)(up01) \n",
    "    \n",
    "    #output = tfp.layers.IndependentPoisson(1)(output)\n",
    "    output = tfp.layers.DistributionLambda(zeroInflatedPoisson)(output)\n",
    "\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    return model\n",
    "\"\"\"\n",
    "\n",
    "def provideData(flatten=False,dimension=dimension,batch_size=10,transform=None,preTransformation=None):\n",
    "\n",
    "    getDataSet(DatasetFolder,year=[2017],username=USRN,pswd=PSWD)\n",
    "    train,test = dataWrapper(PathToData,\n",
    "                            dimension=dimension,\n",
    "                            channels=channels,\n",
    "                            batch_size=batch_size,\n",
    "                            overwritecsv=True,\n",
    "                            flatten=flatten,\n",
    "                            onlyUseYears=[2017],\n",
    "                            transform=transform,\n",
    "                            preTransformation=preTransformation)\n",
    "    \n",
    "    return train,test\n",
    "DatasetFolder = \"./Data/RAW\"\n",
    "PathToData = os.path.join(DatasetFolder,\"MonthPNGData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mFound Year \u001b[0m:  2017 => won't download this year again... please check for consistency\n",
      "\u001b[32mFinished Loading Dataset\n",
      " \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dimension = (64,64)\n",
    "channels = 5\n",
    "optimizer = Adam( lr = 1e-5 )\n",
    "tfd = tfp.distributions\n",
    "def NLL(y_true, y_hat):\n",
    "    return -y_hat.log_prob(y_true)\n",
    "\n",
    "train, test = provideData(flatten=False,dimension=dimension,batch_size=1,transform=None,preTransformation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Load file failed]  ./model_data/testnet_LSTM_Meets_Unet_Upconv_Poisson_function/testnet_LSTM_Meets_Unet_Upconv_Poisson_function64x64x5.h5\n",
      "[Load file failed]  ./model_data/testnet_LSTM_Meets_Unet_Upconv_Poisson_function/testnet_LSTM_Meets_Unet_Upconv_Poisson_function64x64x5history.json\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 64, 5)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 10)   460         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 10)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 10)   40          activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 10)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 20)   1820        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 20)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 20)   80          activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 20)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 20)   3620        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 16, 16, 20)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 20)   80          activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 20)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 20)     3620        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 8, 8, 20)     0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8, 8, 20)     80          activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 20, 8, 8, 1)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_3 (ConvLSTM2D)     (None, 20, 8, 8, 20) 15200       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 20, 8, 8, 20) 80          conv_lst_m2d_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_4 (ConvLSTM2D)     (None, 20, 8, 8, 20) 28880       batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 20, 8, 8, 20) 80          conv_lst_m2d_4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_5 (ConvLSTM2D)     (None, 20, 8, 8, 20) 28880       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 20, 16, 16, 1 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 20, 8, 8, 20) 80          conv_lst_m2d_5[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d (ConvLSTM2D)       (None, 20, 16, 16, 2 15200       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_6 (ConvLSTM2D)     (None, 8, 8, 20)     28880       batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 20, 16, 16, 2 80          conv_lst_m2d[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 20)     80          conv_lst_m2d_6[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 20)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)     (None, 20, 16, 16, 2 28880       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 20)     80          batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 8, 8, 20)     3620        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 20, 16, 16, 2 80          conv_lst_m2d_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 40)     0           batch_normalization_7[0][0]      \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 20)     80          conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)     (None, 16, 16, 20)   28880       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 60)     0           concatenate_1[0][0]              \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 20)   80          conv_lst_m2d_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 8, 8, 20)     10820       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 20)   80          batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 20)   3620        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16, 16, 40)   0           batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 20)   80          conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16, 16, 60)   0           concatenate[0][0]                \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 20)   10820       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 20)   3620        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 20)   80          conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 40)   0           batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 20)   7220        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 64, 20)   3620        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 64, 20)   80          conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 64, 64, 30)   0           batch_normalization[0][0]        \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 20)   5420        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 64)   1344        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "distribution_lambda (Distributi ((None, 64, 64, 64), 0           conv2d_8[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 235,744\n",
      "Trainable params: 235,084\n",
      "Non-trainable params: 660\n",
      "__________________________________________________________________________________________________\n",
      "len train,val 10 10\n"
     ]
    }
   ],
   "source": [
    "t_0 = Trainer(testnet_LSTM_Meets_Unet_Upconv_Poisson,\n",
    "                    NLL,\n",
    "                    (train,test),\n",
    "                    batch_size = 1,\n",
    "                    optimizer=optimizer,\n",
    "                    dimension = dimension,\n",
    "                    channels = channels,\n",
    "                    metrics = [\"mse\",\"mae\"])\n",
    "\n",
    "print(\"len train,val\",len(train),len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 10 steps, validate for 10 steps\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 18s 2s/step - loss: 1.4278 - mse: 21.1909 - mae: 1.3337 - val_loss: 11.4935 - val_mse: 182.2261 - val_mae: 4.5412\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 1.4136 - mse: 16.1237 - mae: 1.3222 - val_loss: 10.6583 - val_mse: 160.3905 - val_mae: 4.3161\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 3s 337ms/step - loss: 1.4078 - mse: 11.8709 - mae: 1.3132 - val_loss: 11.0938 - val_mse: 171.4762 - val_mae: 4.4332\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 3s 337ms/step - loss: 1.3968 - mse: 11.3257 - mae: 1.3053 - val_loss: 11.4109 - val_mse: 179.4420 - val_mae: 4.5189\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 3s 346ms/step - loss: 1.3923 - mse: 9.0486 - mae: 1.2969 - val_loss: 11.0874 - val_mse: 171.4421 - val_mae: 4.4307\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 1.3839 - mse: 8.7136 - mae: 1.2905 - val_loss: 11.0760 - val_mse: 171.2639 - val_mae: 4.4285\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 3s 333ms/step - loss: 1.3803 - mse: 7.7657 - mae: 1.2863 - val_loss: 10.6822 - val_mse: 160.9222 - val_mae: 4.3231\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 1.3707 - mse: 7.2034 - mae: 1.2790 - val_loss: 11.0211 - val_mse: 169.2550 - val_mae: 4.4162\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 3s 334ms/step - loss: 1.3716 - mse: 6.9835 - mae: 1.2758 - val_loss: 11.4950 - val_mse: 182.4279 - val_mae: 4.5375\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 1.3634 - mse: 6.1600 - mae: 1.2709 - val_loss: 10.6952 - val_mse: 161.1884 - val_mae: 4.3289\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 1.3573 - mse: 6.0381 - mae: 1.2652 - val_loss: 11.4389 - val_mse: 180.0675 - val_mae: 4.5283\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 1.3556 - mse: 5.9925 - mae: 1.2646 - val_loss: 10.6467 - val_mse: 160.1203 - val_mae: 4.3131\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 1.3502 - mse: 5.7709 - mae: 1.2598 - val_loss: 11.4808 - val_mse: 180.9238 - val_mae: 4.5406\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 3s 337ms/step - loss: 1.3449 - mse: 5.3023 - mae: 1.2545 - val_loss: 10.6540 - val_mse: 159.7711 - val_mae: 4.3166\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 1.3431 - mse: 5.3732 - mae: 1.2524 - val_loss: 11.0937 - val_mse: 171.6822 - val_mae: 4.4319\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 3s 348ms/step - loss: 1.3381 - mse: 5.1360 - mae: 1.2474 - val_loss: 11.0600 - val_mse: 170.5168 - val_mae: 4.4248\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 1.3370 - mse: 5.0834 - mae: 1.2442 - val_loss: 11.0918 - val_mse: 170.8345 - val_mae: 4.4333\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 1.3305 - mse: 4.9882 - mae: 1.2415 - val_loss: 11.1029 - val_mse: 171.1508 - val_mae: 4.4355\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 1.3278 - mse: 4.7994 - mae: 1.2363 - val_loss: 11.4340 - val_mse: 179.3655 - val_mae: 4.5251\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 1.3237 - mse: 4.6304 - mae: 1.2345 - val_loss: 11.1184 - val_mse: 171.6528 - val_mae: 4.4372\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 1.3205 - mse: 4.6417 - mae: 1.2317 - val_loss: 10.7055 - val_mse: 160.5637 - val_mae: 4.3265\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 1.3188 - mse: 4.6292 - mae: 1.2294 - val_loss: 11.4458 - val_mse: 179.2118 - val_mae: 4.5246\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 1.3121 - mse: 4.4417 - mae: 1.2242 - val_loss: 11.1315 - val_mse: 171.4706 - val_mae: 4.4369\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 1.3096 - mse: 4.4363 - mae: 1.2218 - val_loss: 10.6766 - val_mse: 158.8548 - val_mae: 4.3154\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 1.3114 - mse: 4.3791 - mae: 1.2212 - val_loss: 11.1666 - val_mse: 172.2529 - val_mae: 4.4427\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 1.3026 - mse: 4.2843 - mae: 1.2150 - val_loss: 11.0829 - val_mse: 168.8880 - val_mae: 4.4161\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 1.3003 - mse: 4.2134 - mae: 1.2124 - val_loss: 11.1536 - val_mse: 170.5597 - val_mae: 4.4356\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 3s 341ms/step - loss: 1.2950 - mse: 4.1690 - mae: 1.2084 - val_loss: 11.1075 - val_mse: 168.9674 - val_mae: 4.4165\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 3s 345ms/step - loss: 1.2988 - mse: 4.1581 - mae: 1.2083 - val_loss: 11.1800 - val_mse: 170.5716 - val_mae: 4.4339\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 1.2899 - mse: 4.0613 - mae: 1.2026 - val_loss: 11.1022 - val_mse: 167.0834 - val_mae: 4.4085\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 3s 338ms/step - loss: 1.2840 - mse: 3.9833 - mae: 1.1986 - val_loss: 11.1703 - val_mse: 168.8877 - val_mae: 4.4207\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 3s 334ms/step - loss: 1.2879 - mse: 4.0226 - mae: 1.1976 - val_loss: 11.1854 - val_mse: 168.5231 - val_mae: 4.4179\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 1.2805 - mse: 3.9418 - mae: 1.1946 - val_loss: 11.6178 - val_mse: 178.9393 - val_mae: 4.5257\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 1.2778 - mse: 3.8993 - mae: 1.1909 - val_loss: 11.2343 - val_mse: 168.3089 - val_mae: 4.4130\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 3s 344ms/step - loss: 1.2713 - mse: 3.8024 - mae: 1.1863 - val_loss: 11.2462 - val_mse: 166.8137 - val_mae: 4.4106\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 3s 345ms/step - loss: 1.2712 - mse: 3.8161 - mae: 1.1853 - val_loss: 10.8899 - val_mse: 156.8522 - val_mae: 4.3057\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 3s 347ms/step - loss: 1.2687 - mse: 3.7811 - mae: 1.1817 - val_loss: 11.2682 - val_mse: 165.5078 - val_mae: 4.3970\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 1.2640 - mse: 3.7201 - mae: 1.1797 - val_loss: 11.7532 - val_mse: 176.0782 - val_mae: 4.5216\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 1.2622 - mse: 3.7139 - mae: 1.1759 - val_loss: 11.0339 - val_mse: 158.7920 - val_mae: 4.3244\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 1.2594 - mse: 3.6540 - mae: 1.1728 - val_loss: 11.7911 - val_mse: 178.3976 - val_mae: 4.5283\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 3s 338ms/step - loss: 1.2551 - mse: 3.6331 - mae: 1.1697 - val_loss: 11.5604 - val_mse: 180.1636 - val_mae: 4.4758\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 3s 338ms/step - loss: 1.2531 - mse: 3.6290 - mae: 1.1678 - val_loss: 11.5901 - val_mse: 199.6938 - val_mae: 4.5124\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 3s 338ms/step - loss: 1.2490 - mse: 3.5681 - mae: 1.1641 - val_loss: 11.4181 - val_mse: 275.2830 - val_mae: 4.5414\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 1.2463 - mse: 3.5368 - mae: 1.1621 - val_loss: 12.3249 - val_mse: 329.9511 - val_mae: 4.8065\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 3s 338ms/step - loss: 1.2426 - mse: 3.5187 - mae: 1.1591 - val_loss: 11.9304 - val_mse: 782.5467 - val_mae: 4.9489\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 1.2363 - mse: 3.4498 - mae: 1.1546 - val_loss: 13.0079 - val_mse: 5673.6982 - val_mae: 5.6708\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 3s 350ms/step - loss: 1.2397 - mse: 3.4830 - mae: 1.1549 - val_loss: 32.3690 - val_mse: 198531504.0000 - val_mae: 24.9297\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 1.2337 - mse: 3.4365 - mae: 1.1506 - val_loss: 141.5592 - val_mse: 3619882240.0000 - val_mae: 133.9679\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 1.2311 - mse: 3.4104 - mae: 1.1482 - val_loss: 7073.1893 - val_mse: 5493013086208.0000 - val_mae: 7065.4570\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 1.2288 - mse: 3.4060 - mae: 1.1456 - val_loss: 51296415.0096 - val_mse: 6774902842192025354240.0000 - val_mae: 51296408.0000\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 1.2271 - mse: 3.3758 - mae: 1.1439 - val_loss: 9803177155847.4961 - val_mse: inf - val_mae: 9803176869888.0000\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 3s 338ms/step - loss: 1.2199 - mse: 3.3082 - mae: 1.1399 - val_loss: 920995523353384.6250 - val_mse: inf - val_mae: 920995405758464.0000\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 3s 337ms/step - loss: 1.2214 - mse: 3.3492 - mae: 1.1387 - val_loss: 1303229709083526656.0000 - val_mse: inf - val_mae: 1303229829365104640.0000\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 1.2192 - mse: 3.3076 - mae: 1.1368 - val_loss: 151728150927016622372683776.0000 - val_mse: inf - val_mae: 151728140908331730242371584.0000\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 1.2103 - mse: 3.2410 - mae: 1.1322 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 3s 346ms/step - loss: 1.2157 - mse: 3.3107 - mae: 1.1338 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 3s 344ms/step - loss: 1.2089 - mse: 3.2262 - mae: 1.1297 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 1.2095 - mse: 3.2592 - mae: 1.1284 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 1.2053 - mse: 3.2215 - mae: 1.1261 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 1.2007 - mse: 3.1893 - mae: 1.1230 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 1.2003 - mse: 3.1764 - mae: 1.1216 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 1.1998 - mse: 3.1833 - mae: 1.1203 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 3s 341ms/step - loss: 1.2008 - mse: 3.2016 - mae: 1.1202 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 3s 348ms/step - loss: 1.1902 - mse: 3.1017 - mae: 1.1147 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 1.1948 - mse: 3.1560 - mae: 1.1160 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 3s 344ms/step - loss: 1.1899 - mse: 3.1253 - mae: 1.1116 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 3s 344ms/step - loss: 1.1914 - mse: 3.1434 - mae: 1.1120 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 1.1869 - mse: 3.0880 - mae: 1.1098 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 1.1876 - mse: 3.1179 - mae: 1.1085 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 1.1817 - mse: 3.0642 - mae: 1.1069 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 1.1822 - mse: 3.0905 - mae: 1.1066 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 3s 348ms/step - loss: 1.1814 - mse: 3.0718 - mae: 1.1043 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 3s 341ms/step - loss: 1.1788 - mse: 3.0557 - mae: 1.1030 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 3s 345ms/step - loss: 1.1771 - mse: 3.0651 - mae: 1.1026 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 3s 337ms/step - loss: 1.1758 - mse: 3.0309 - mae: 1.1014 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 1.1716 - mse: 3.0101 - mae: 1.0967 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 1.1748 - mse: 3.0396 - mae: 1.0984 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 3s 345ms/step - loss: 1.1744 - mse: 3.0562 - mae: 1.0980 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 3s 337ms/step - loss: 1.1691 - mse: 3.0002 - mae: 1.0942 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 1.1702 - mse: 3.0159 - mae: 1.0946 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 3s 334ms/step - loss: 1.1677 - mse: 3.0046 - mae: 1.0940 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 1.1647 - mse: 2.9766 - mae: 1.0934 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 1.1642 - mse: 2.9745 - mae: 1.0903 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 1.1623 - mse: 2.9700 - mae: 1.0893 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 3s 341ms/step - loss: 1.1658 - mse: 3.0024 - mae: 1.0907 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 1.1597 - mse: 2.9646 - mae: 1.0883 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 3s 341ms/step - loss: 1.1645 - mse: 3.0032 - mae: 1.0895 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 1.1568 - mse: 2.9310 - mae: 1.0860 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 3s 337ms/step - loss: 1.1568 - mse: 2.9473 - mae: 1.0857 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 3s 347ms/step - loss: 1.1576 - mse: 2.9561 - mae: 1.0849 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 1.1590 - mse: 2.9788 - mae: 1.0851 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 1.1531 - mse: 2.9174 - mae: 1.0829 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 3s 337ms/step - loss: 1.1575 - mse: 2.9711 - mae: 1.0857 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 3s 341ms/step - loss: 1.1533 - mse: 2.9463 - mae: 1.0824 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 1.1521 - mse: 2.9108 - mae: 1.0802 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 1.1526 - mse: 2.9471 - mae: 1.0806 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 1.1519 - mse: 2.9298 - mae: 1.0805 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 346ms/step - loss: 1.1502 - mse: 2.9257 - mae: 1.0794 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 3s 344ms/step - loss: 1.1485 - mse: 2.9045 - mae: 1.0781 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 3s 334ms/step - loss: 1.1493 - mse: 2.9309 - mae: 1.0789 - val_loss: nan - val_mse: nan - val_mae: nan\n"
     ]
    }
   ],
   "source": [
    "t_0.fit(100)\n",
    "model_0 = t_0.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "history_0 = t_0.history\n",
    "def plotHistory(history):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history['mse'][:48])\n",
    "    plt.plot(history['val_mse'][:48])\n",
    "    plt.title('Model MSE')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history['loss'][:48])\n",
    "    plt.plot(history['val_loss'][:48])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "plotHistory(history_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testnet_LSTM_Meets_Unet_Upconv_Poisson_changed_CHANNEL(input_shape,\n",
    "                    n_predictions=1,\n",
    "                    simpleclassification=None,\n",
    "                    flatten_output=False,\n",
    "                    activation_hidden=\"relu\",\n",
    "                    activation_output=\"relu\"):\n",
    "\n",
    "\n",
    "    def zeroInflatedPoisson(output):\n",
    "        rate = tf.math.exp(output[0,:,:,0]) #A \n",
    "        s = tf.math.sigmoid(output[0,:,:,1])\n",
    "        components = [tfd.Deterministic(loc=tf.zeros_like(rate)), #E\n",
    "         tfd.Poisson(rate=rate) #F \n",
    "         ]\n",
    "        mixture = tfd.Mixture(\n",
    "              cat=tfd.Categorical(probs=tf.stack([1-s, s],axis=-1)),#D\n",
    "              components=components)\n",
    "        return mixture\n",
    "\n",
    "    def poss(output):\n",
    "        rate = tf.math.exp(output)\n",
    "        return tfp.layers.IndependentPoisson(rate)\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "\n",
    "    conv01 = Conv2D(10, kernel_size=(3, 3), padding=\"same\")(inputs)       \n",
    "    conv01 = Activation(activation_hidden)(conv01)\n",
    "    conv01 = BatchNormalization() (conv01)\n",
    "    conv01_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv01)            \n",
    "    \n",
    "\n",
    "    conv02 = Conv2D(20, kernel_size=(3, 3), padding=\"same\")(conv01_pool)  \n",
    "    conv02 = Activation(activation_hidden)(conv02)\n",
    "    conv02 = BatchNormalization() (conv02)\n",
    "    conv02_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv02)            \n",
    "    \n",
    "    conv03 = Conv2D(20, kernel_size=(3, 3), padding=\"same\")(conv02_pool)  \n",
    "    conv03 = Activation(activation_hidden)(conv03)\n",
    "    conv03 = BatchNormalization() (conv03)\n",
    "    conv03_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv03)            \n",
    "    \n",
    "\n",
    "    lstm_conv3 = lstmLayer(conv03,filters = [20,20,20])\n",
    "    lstm_conv3 = BatchNormalization() (lstm_conv3)\n",
    "    conv03 = concatenate([conv03, lstm_conv3], axis=3)\n",
    "\n",
    "    conv04 = Conv2D(20, kernel_size=(3, 3), padding=\"same\")(conv03_pool)  \n",
    "    conv04 = Activation(activation_hidden)(conv04)\n",
    "    conv04 = BatchNormalization() (conv04)\n",
    "    conv04_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv04)            \n",
    "    \n",
    "\n",
    "    lstm_conv4 = lstmLayer(conv04,filters = [20,20,20,20])\n",
    "    lstm_conv4 = BatchNormalization() (lstm_conv4)\n",
    "\n",
    "    conv04 = concatenate([conv04, lstm_conv4], axis=3)\n",
    "\n",
    "    ### UPSAMPLING:\n",
    "    up04 = Conv2DTranspose(20,(3, 3),strides=(2,2),padding=\"same\")(conv04_pool)    \n",
    "    up04 = BatchNormalization() (up04)\n",
    "    up04 = concatenate([conv04, up04], axis=3)  \n",
    "    up04 = Conv2D(20, kernel_size=(3, 3), padding=\"same\")(up04)  \n",
    "    \n",
    "\n",
    "    up03 = Conv2DTranspose(20,(3, 3),strides=(2,2),padding=\"same\")(up04)           \n",
    "    up03 = BatchNormalization() (up03)\n",
    "    up03 = concatenate([conv03, up03], axis=3)  \n",
    "    up03 = Conv2D(20, kernel_size=(3, 3), padding=\"same\")(up03)  \n",
    "    \n",
    "\n",
    "    up02 = Conv2DTranspose(20,(3, 3),strides=(2,2),padding=\"same\")(up03)           \n",
    "    up02 = BatchNormalization() (up02)\n",
    "    up02 = concatenate([conv02, up02], axis=3)  \n",
    "    up02 = Conv2D(20, kernel_size=(3, 3), padding=\"same\")(up02)  \n",
    "    \n",
    "\n",
    "    up01 = Conv2DTranspose(20,(3, 3),strides=(2,2),padding=\"same\")(up02)           \n",
    "    up01 = BatchNormalization() (up01)\n",
    "    up01 = concatenate([conv01, up01], axis=3)  \n",
    "    up01 = Conv2D(20, kernel_size=(3, 3), padding=\"same\")(up01)  \n",
    "    \n",
    "    output = Conv2D(1, (1, 1), activation=tf.exp)(up01) \n",
    "    \n",
    "    \n",
    "    #output = tfp.layers.DistributionLambda(zeroInflatedPoisson)(output)\n",
    "    output = tfp.layers.DistributionLambda(tfp.distributions.Poisson)(output)\n",
    "    #output = tfp.layers.DistributionLambda(poss)(output)\n",
    "    #output = tfp.layers.IndependentPoisson()(output)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Load file failed]  ./model_data/testnet_LSTM_Meets_Unet_Upconv_Poisson_changed_CHANNEL_function/testnet_LSTM_Meets_Unet_Upconv_Poisson_changed_CHANNEL_function64x64x5.h5\n",
      "[Load file failed]  ./model_data/testnet_LSTM_Meets_Unet_Upconv_Poisson_changed_CHANNEL_function/testnet_LSTM_Meets_Unet_Upconv_Poisson_changed_CHANNEL_function64x64x5history.json\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 64, 64, 5)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 10)   460         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 10)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64, 64, 10)   40          activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 10)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 20)   1820        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 20)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 20)   80          activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 20)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 20)   3620        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 20)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 20)   80          activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 8, 8, 20)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 20)     3620        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 8, 8, 20)     0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 8, 8, 20)     80          activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 20, 8, 8, 1)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_10 (ConvLSTM2D)    (None, 20, 8, 8, 20) 15200       reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 20, 8, 8, 20) 80          conv_lst_m2d_10[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_11 (ConvLSTM2D)    (None, 20, 8, 8, 20) 28880       batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 20, 8, 8, 20) 80          conv_lst_m2d_11[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_12 (ConvLSTM2D)    (None, 20, 8, 8, 20) 28880       batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 20, 16, 16, 1 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 20, 8, 8, 20) 80          conv_lst_m2d_12[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_7 (ConvLSTM2D)     (None, 20, 16, 16, 2 15200       reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_13 (ConvLSTM2D)    (None, 8, 8, 20)     28880       batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 20, 16, 16, 2 80          conv_lst_m2d_7[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 20)     80          conv_lst_m2d_13[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 4, 4, 20)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_8 (ConvLSTM2D)     (None, 20, 16, 16, 2 28880       batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 20)     80          batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 8, 8, 20)     3620        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 20, 16, 16, 2 80          conv_lst_m2d_8[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 8, 8, 40)     0           batch_normalization_24[0][0]     \n",
      "                                                                 batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 20)     80          conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_9 (ConvLSTM2D)     (None, 16, 16, 20)   28880       batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 8, 8, 60)     0           concatenate_7[0][0]              \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 20)   80          conv_lst_m2d_9[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 20)     10820       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 20)   80          batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 16, 16, 20)   3620        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 16, 16, 40)   0           batch_normalization_19[0][0]     \n",
      "                                                                 batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 20)   80          conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 16, 16, 60)   0           concatenate_6[0][0]              \n",
      "                                                                 batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 20)   10820       concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 32, 32, 20)   3620        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 32, 32, 20)   80          conv2d_transpose_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 40)   0           batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 20)   7220        concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 64, 64, 20)   3620        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 64, 64, 20)   80          conv2d_transpose_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 64, 64, 30)   0           batch_normalization_17[0][0]     \n",
      "                                                                 batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 20)   5420        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 1)    21          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "distribution_lambda_1 (Distribu ((None, 64, 64, 1),  0           conv2d_17[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 234,421\n",
      "Trainable params: 233,761\n",
      "Non-trainable params: 660\n",
      "__________________________________________________________________________________________________\n",
      "len train,val 10 10\n"
     ]
    }
   ],
   "source": [
    "t_1 = Trainer(testnet_LSTM_Meets_Unet_Upconv_Poisson_changed_CHANNEL,\n",
    "                    NLL,\n",
    "                    (train,test),\n",
    "                    batch_size = 1,\n",
    "                    optimizer=optimizer,\n",
    "                    dimension = dimension,\n",
    "                    channels = channels,\n",
    "                    metrics = [\"mse\",\"mae\"])\n",
    "\n",
    "print(\"len train,val\",len(train),len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 10 steps, validate for 10 steps\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - 17s 2s/step - loss: 2.7420 - mse: 3634.3413 - mae: 2.6048 - val_loss: 10.6227 - val_mse: 161.3957 - val_mae: 4.3247\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - 3s 333ms/step - loss: 2.1355 - mse: 43.3292 - mae: 1.9754 - val_loss: 11.0444 - val_mse: 170.7875 - val_mae: 4.4104\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 2.0112 - mse: 20.8725 - mae: 1.8445 - val_loss: 11.0379 - val_mse: 169.8374 - val_mae: 4.4048\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - 3s 345ms/step - loss: 1.9181 - mse: 14.4605 - mae: 1.7549 - val_loss: 11.1167 - val_mse: 170.9756 - val_mae: 4.4120\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 1.8844 - mse: 13.4356 - mae: 1.7311 - val_loss: 11.0983 - val_mse: 169.9632 - val_mae: 4.4080\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 1.8307 - mse: 10.9863 - mae: 1.6823 - val_loss: 11.5533 - val_mse: 182.3736 - val_mae: 4.5179\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 1.7925 - mse: 10.2453 - mae: 1.6450 - val_loss: 11.1386 - val_mse: 170.6805 - val_mae: 4.4103\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 1.7575 - mse: 9.7143 - mae: 1.6129 - val_loss: 10.7717 - val_mse: 161.3557 - val_mae: 4.2996\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - 3s 334ms/step - loss: 1.7308 - mse: 9.2834 - mae: 1.5913 - val_loss: 11.5124 - val_mse: 179.6084 - val_mae: 4.4972\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 1.6999 - mse: 8.7084 - mae: 1.5672 - val_loss: 11.1654 - val_mse: 171.7100 - val_mae: 4.4019\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - 3s 334ms/step - loss: 1.6679 - mse: 8.1052 - mae: 1.5333 - val_loss: 10.7414 - val_mse: 159.2073 - val_mae: 4.2866\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - 3s 342ms/step - loss: 1.6544 - mse: 7.9465 - mae: 1.5209 - val_loss: 11.1730 - val_mse: 171.0624 - val_mae: 4.4039\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 1.6323 - mse: 7.9239 - mae: 1.5255 - val_loss: 11.2299 - val_mse: 172.4311 - val_mae: 4.4096\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 1.6118 - mse: 7.6792 - mae: 1.5004 - val_loss: 11.1486 - val_mse: 170.0801 - val_mae: 4.3854\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - 3s 334ms/step - loss: 1.5913 - mse: 7.2906 - mae: 1.4797 - val_loss: 11.2097 - val_mse: 171.2644 - val_mae: 4.4013\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 1.5642 - mse: 6.9518 - mae: 1.4598 - val_loss: 11.5863 - val_mse: 180.0811 - val_mae: 4.5038\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 1.5545 - mse: 6.8722 - mae: 1.4466 - val_loss: 10.8290 - val_mse: 161.2460 - val_mae: 4.2852\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 1.5442 - mse: 6.6594 - mae: 1.4454 - val_loss: 11.2744 - val_mse: 172.3966 - val_mae: 4.4199\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 1.5228 - mse: 6.6802 - mae: 1.4302 - val_loss: 11.2039 - val_mse: 169.6485 - val_mae: 4.3728\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - 3s 338ms/step - loss: 1.5078 - mse: 6.2892 - mae: 1.4053 - val_loss: 11.6282 - val_mse: 180.2204 - val_mae: 4.4947\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 1.4920 - mse: 6.1461 - mae: 1.3974 - val_loss: 11.2618 - val_mse: 170.7963 - val_mae: 4.3957\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 1.4831 - mse: 6.0876 - mae: 1.3865 - val_loss: 11.2737 - val_mse: 170.6696 - val_mae: 4.3892\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - 3s 333ms/step - loss: 1.4674 - mse: 6.1635 - mae: 1.3886 - val_loss: 10.8919 - val_mse: 160.4474 - val_mae: 4.2838\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 1.4502 - mse: 5.8513 - mae: 1.3674 - val_loss: 11.3059 - val_mse: 171.3749 - val_mae: 4.3880\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - 3s 333ms/step - loss: 1.4463 - mse: 5.6632 - mae: 1.3509 - val_loss: 11.3062 - val_mse: 169.8338 - val_mae: 4.3846\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - 3s 337ms/step - loss: 1.4353 - mse: 5.8063 - mae: 1.3518 - val_loss: 11.7534 - val_mse: 181.7995 - val_mae: 4.4992\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - 3s 333ms/step - loss: 1.4165 - mse: 5.5093 - mae: 1.3412 - val_loss: 11.3108 - val_mse: 169.9297 - val_mae: 4.3764\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 1.4160 - mse: 5.5759 - mae: 1.3455 - val_loss: 10.9699 - val_mse: 160.3549 - val_mae: 4.2768\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 1.4020 - mse: 5.5474 - mae: 1.3205 - val_loss: 11.4044 - val_mse: 170.8661 - val_mae: 4.3855\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 1.3899 - mse: 5.4963 - mae: 1.3155 - val_loss: 11.3832 - val_mse: 170.3916 - val_mae: 4.3747\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 1.3820 - mse: 5.2969 - mae: 1.3096 - val_loss: 11.3936 - val_mse: 169.2917 - val_mae: 4.3672\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 1.3734 - mse: 5.1493 - mae: 1.2973 - val_loss: 11.4279 - val_mse: 170.0658 - val_mae: 4.3632\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 1.3608 - mse: 5.0983 - mae: 1.3002 - val_loss: 11.4272 - val_mse: 168.6787 - val_mae: 4.3586\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 1.3585 - mse: 5.1096 - mae: 1.2892 - val_loss: 11.4515 - val_mse: 168.5955 - val_mae: 4.3626\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 1.3448 - mse: 5.1348 - mae: 1.2890 - val_loss: 11.4377 - val_mse: 167.4150 - val_mae: 4.3402\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 1.3398 - mse: 4.9381 - mae: 1.2705 - val_loss: 11.4848 - val_mse: 166.5569 - val_mae: 4.3389\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 1.3255 - mse: 4.8888 - mae: 1.2714 - val_loss: 11.9224 - val_mse: 177.8995 - val_mae: 4.4574\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 1.3256 - mse: 4.7583 - mae: 1.2501 - val_loss: 11.5078 - val_mse: 166.2776 - val_mae: 4.3356\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 1.3183 - mse: 4.7793 - mae: 1.2545 - val_loss: 11.1312 - val_mse: 156.2443 - val_mae: 4.2289\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 1.3092 - mse: 4.6687 - mae: 1.2427 - val_loss: 11.5553 - val_mse: 167.9731 - val_mae: 4.3448\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 1.3006 - mse: 4.6118 - mae: 1.2400 - val_loss: 11.9130 - val_mse: 174.4495 - val_mae: 4.4418\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 1.2896 - mse: 4.5417 - mae: 1.2371 - val_loss: 11.2827 - val_mse: 175.5370 - val_mae: 4.3050\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 1.2899 - mse: 4.6423 - mae: 1.2418 - val_loss: 11.6475 - val_mse: 190.3723 - val_mae: 4.4097\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 1.2825 - mse: 4.4969 - mae: 1.2371 - val_loss: 11.7463 - val_mse: 251.1600 - val_mae: 4.5031\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 1.2751 - mse: 4.4809 - mae: 1.2219 - val_loss: 11.9886 - val_mse: 396.0392 - val_mae: 4.6855\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - 3s 323ms/step - loss: 1.2666 - mse: 4.2970 - mae: 1.2101 - val_loss: 12.2100 - val_mse: 767.5696 - val_mae: 4.8996\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 1.2636 - mse: 4.3485 - mae: 1.2136 - val_loss: 12.8382 - val_mse: 1929.6725 - val_mae: 5.4225\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 1.2554 - mse: 4.3481 - mae: 1.2095 - val_loss: 13.6664 - val_mse: 5813.3584 - val_mae: 6.1701\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 1.2513 - mse: 4.2433 - mae: 1.2012 - val_loss: 18.4354 - val_mse: 122104.8125 - val_mae: 10.6605\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 1.2416 - mse: 4.1955 - mae: 1.1985 - val_loss: 58.3670 - val_mse: 10184197.0000 - val_mae: 50.9546\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - 3s 348ms/step - loss: 1.2415 - mse: 4.2056 - mae: 1.1889 - val_loss: 326.0223 - val_mse: 1072749056.0000 - val_mae: 318.3076\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - 3s 349ms/step - loss: 1.2357 - mse: 4.2369 - mae: 1.1920 - val_loss: 23955017.6308 - val_mse: 11355026015949684736.0000 - val_mae: 23955034.0000\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 1.2255 - mse: 4.0883 - mae: 1.1887 - val_loss: 6478499368.0959 - val_mse: 1654446106105715382812672.0000 - val_mae: 6478499328.0000\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 1.2260 - mse: 4.1024 - mae: 1.1808 - val_loss: 34660954377612.5000 - val_mse: 32976737590366723302207801786368.0000 - val_mae: 34660952309760.0000\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 1.2152 - mse: 3.9773 - mae: 1.1697 - val_loss: 255789985445091.1875 - val_mse: 1225673910406121084445286251626496.0000 - val_mae: 255789964984320.0000\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 1.2090 - mse: 3.9730 - mae: 1.1709 - val_loss: 1809792319188274096099033088.0000 - val_mse: inf - val_mae: 1809792352197333347876208640.0000\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 1.2120 - mse: 4.0523 - mae: 1.1633 - val_loss: 168961658960101187180822528.0000 - val_mse: inf - val_mae: 168961661071057478358138880.0000\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 1.2026 - mse: 3.8840 - mae: 1.1575 - val_loss: nan - val_mse: inf - val_mae: 22268456098599815224894685184.0000\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 1.1993 - mse: 3.8209 - mae: 1.1515 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - 3s 338ms/step - loss: 1.1931 - mse: 3.8936 - mae: 1.1533 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 1.1884 - mse: 3.8452 - mae: 1.1450 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 1.1817 - mse: 3.8641 - mae: 1.1512 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 1.1794 - mse: 3.7919 - mae: 1.1445 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 1.1763 - mse: 3.7195 - mae: 1.1362 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 1.1696 - mse: 3.6612 - mae: 1.1309 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 1.1641 - mse: 3.6749 - mae: 1.1257 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 1.1644 - mse: 3.6505 - mae: 1.1277 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 1.1585 - mse: 3.6661 - mae: 1.1247 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 1.1534 - mse: 3.6199 - mae: 1.1177 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 1.1489 - mse: 3.5632 - mae: 1.1096 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 1.1490 - mse: 3.5936 - mae: 1.1151 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - 3s 333ms/step - loss: 1.1400 - mse: 3.5175 - mae: 1.1104 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 1.1387 - mse: 3.6197 - mae: 1.1103 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 1.1303 - mse: 3.3588 - mae: 1.0928 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 1.1322 - mse: 3.4155 - mae: 1.0939 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 1.1291 - mse: 3.4482 - mae: 1.0857 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 1.1250 - mse: 3.4651 - mae: 1.0925 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 1.1196 - mse: 3.3568 - mae: 1.0800 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 1.1151 - mse: 3.4032 - mae: 1.0847 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 1.1132 - mse: 3.3398 - mae: 1.0868 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 1.1038 - mse: 3.3101 - mae: 1.0797 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 1.1107 - mse: 3.3402 - mae: 1.0831 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 1.1021 - mse: 3.3753 - mae: 1.0760 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 1.0987 - mse: 3.2222 - mae: 1.0705 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 1.0941 - mse: 3.2897 - mae: 1.0704 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 1.0936 - mse: 3.2016 - mae: 1.0620 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 1.0870 - mse: 3.2171 - mae: 1.0514 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 1.0856 - mse: 3.2273 - mae: 1.0551 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 1.0839 - mse: 3.1490 - mae: 1.0491 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 1.0761 - mse: 3.1229 - mae: 1.0523 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 1.0759 - mse: 3.1357 - mae: 1.0503 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 1.0742 - mse: 3.1447 - mae: 1.0385 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 1.0696 - mse: 3.1118 - mae: 1.0475 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 1.0652 - mse: 3.0157 - mae: 1.0350 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 1.0666 - mse: 3.0941 - mae: 1.0401 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 1.0569 - mse: 3.0447 - mae: 1.0334 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 97/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 330ms/step - loss: 1.0594 - mse: 3.1466 - mae: 1.0395 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 1.0545 - mse: 3.0539 - mae: 1.0347 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 1.0515 - mse: 2.9551 - mae: 1.0195 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 1.0486 - mse: 3.0249 - mae: 1.0341 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 1.0462 - mse: 2.9490 - mae: 1.0205 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 1.0421 - mse: 2.9756 - mae: 1.0211 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 1.0416 - mse: 2.9844 - mae: 1.0128 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 1.0348 - mse: 2.9701 - mae: 1.0174 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 1.0361 - mse: 2.9703 - mae: 1.0165 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - 3s 334ms/step - loss: 1.0301 - mse: 2.9259 - mae: 1.0061 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 1.0285 - mse: 2.8473 - mae: 1.0022 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - 3s 335ms/step - loss: 1.0258 - mse: 2.9862 - mae: 1.0165 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 1.0213 - mse: 2.8975 - mae: 1.0102 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 1.0222 - mse: 2.9430 - mae: 1.0042 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 1.0160 - mse: 2.8164 - mae: 0.9974 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 1.0148 - mse: 2.8295 - mae: 0.9968 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - 3s 336ms/step - loss: 1.0128 - mse: 2.7950 - mae: 0.9907 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 1.0069 - mse: 2.8500 - mae: 0.9971 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 1.0115 - mse: 2.7912 - mae: 0.9885 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 1.0008 - mse: 2.7732 - mae: 0.9900 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 1.0034 - mse: 2.8040 - mae: 0.9887 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.9988 - mse: 2.7937 - mae: 0.9814 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.9971 - mse: 2.6969 - mae: 0.9681 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - 3s 334ms/step - loss: 0.9916 - mse: 2.6799 - mae: 0.9749 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.9921 - mse: 2.7405 - mae: 0.9742 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.9883 - mse: 2.6815 - mae: 0.9656 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.9856 - mse: 2.6874 - mae: 0.9618 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.9813 - mse: 2.5985 - mae: 0.9604 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.9792 - mse: 2.6490 - mae: 0.9552 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.9805 - mse: 2.7204 - mae: 0.9660 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.9767 - mse: 2.7034 - mae: 0.9714 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.9695 - mse: 2.6210 - mae: 0.9515 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.9721 - mse: 2.6667 - mae: 0.9556 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.9706 - mse: 2.6076 - mae: 0.9510 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.9643 - mse: 2.5742 - mae: 0.9461 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.9636 - mse: 2.5733 - mae: 0.9413 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.9612 - mse: 2.6358 - mae: 0.9608 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.9568 - mse: 2.5377 - mae: 0.9398 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.9561 - mse: 2.5950 - mae: 0.9468 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.9512 - mse: 2.5771 - mae: 0.9417 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.9533 - mse: 2.5588 - mae: 0.9356 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - 3s 329ms/step - loss: 0.9482 - mse: 2.5099 - mae: 0.9318 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.9433 - mse: 2.5255 - mae: 0.9342 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.9441 - mse: 2.4891 - mae: 0.9260 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.9416 - mse: 2.4899 - mae: 0.9177 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.9372 - mse: 2.4670 - mae: 0.9225 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.9392 - mse: 2.5174 - mae: 0.9263 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.9338 - mse: 2.4294 - mae: 0.9168 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.9302 - mse: 2.3863 - mae: 0.9107 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.9271 - mse: 2.4429 - mae: 0.9152 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - 3s 333ms/step - loss: 0.9286 - mse: 2.4347 - mae: 0.9111 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - 3s 328ms/step - loss: 0.9237 - mse: 2.3973 - mae: 0.9127 - val_loss: nan - val_mse: nan - val_mae: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/150\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.9205 - mse: 2.3966 - mae: 0.9130 - val_loss: nan - val_mse: nan - val_mae: nan\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.9207 - mse: 2.3559 - mae: 0.8971 - val_loss: nan - val_mse: nan - val_mae: nan\n"
     ]
    }
   ],
   "source": [
    "t_1.fit(150)\n",
    "model_1 = t_1.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "history_1 = t_1.history\n",
    "\n",
    "plotHistory(history_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
