{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZrwVQsM9TiUw"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "CpDUTVKYTowI"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ltPJCG6pAUoc"
   },
   "source": [
    "# TFP Probabilistic Layers: Variational Auto Encoder\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Probabilistic_Layers_VAE.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Probabilistic_Layers_VAE.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRVR-tGTR31S"
   },
   "source": [
    "In this example we show how to fit a Variational Autoencoder using TFP's \"probabilistic layers.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uiR4-VOt9NFX"
   },
   "source": [
    "### Dependencies & Prerequisites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cg5t0lWXGY0z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: tensorflow 2.0.0 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-probability 0.8.0 has requirement cloudpickle==1.1.1, but you'll have cloudpickle 1.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-probability 0.8.0 has requirement gast<0.3,>=0.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-gpu 2.0.0 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
      "Installation of `tf-nightly` complete.\n"
     ]
    }
   ],
   "source": [
    "#@title Install { display-mode: \"form\" }\n",
    "TF_Installation = 'TF Nightly' #@param ['TF Nightly', 'TF Stable', 'System']\n",
    "\n",
    "if TF_Installation == 'TF Nightly':\n",
    "  !pip install -q --upgrade tf-nightly\n",
    "  print('Installation of `tf-nightly` complete.')\n",
    "elif TF_Installation == 'TF Stable':\n",
    "  !pip install -q --upgrade tensorflow\n",
    "  print('Installation of `tensorflow` complete.')\n",
    "elif TF_Installation == 'System':\n",
    "  pass\n",
    "else:\n",
    "  raise ValueError('Selection Error: Please select a valid '\n",
    "                   'installation option.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling tf-nightly-2.2.0.dev20200405:\n",
      "  Would remove:\n",
      "    /home/simon/anaconda3/envs/tensorflow-gpu/bin/estimator_ckpt_converter\n",
      "    /home/simon/anaconda3/envs/tensorflow-gpu/bin/saved_model_cli\n",
      "    /home/simon/anaconda3/envs/tensorflow-gpu/bin/tf_upgrade_v2\n",
      "    /home/simon/anaconda3/envs/tensorflow-gpu/bin/tflite_convert\n",
      "    /home/simon/anaconda3/envs/tensorflow-gpu/bin/toco\n",
      "    /home/simon/anaconda3/envs/tensorflow-gpu/bin/toco_from_protos\n",
      "    /home/simon/anaconda3/envs/tensorflow-gpu/lib/python3.7/site-packages/tensorflow/*\n",
      "    /home/simon/anaconda3/envs/tensorflow-gpu/lib/python3.7/site-packages/tf_nightly-2.2.0.dev20200405.dist-info/*\n",
      "Proceed (y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9clSiUTiT3G1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: spyder 3.3.6 requires pyqt5<5.13; python_version >= \"3\", which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: spyder 3.3.6 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-probability 0.8.0 has requirement cloudpickle==1.1.1, but you'll have cloudpickle 1.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-probability 0.8.0 has requirement gast<0.3,>=0.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
      "Installation of `tfp-nightly` complete.\n"
     ]
    }
   ],
   "source": [
    "#@title Install { display-mode: \"form\" }\n",
    "TFP_Installation = \"Nightly\" #@param [\"Nightly\", \"Stable\", \"System\"]\n",
    "\n",
    "if TFP_Installation == \"Nightly\":\n",
    "  !pip install -q tfp-nightly\n",
    "  print(\"Installation of `tfp-nightly` complete.\")\n",
    "elif TFP_Installation == \"Stable\":\n",
    "  !pip install -q --upgrade tensorflow-probability\n",
    "  print(\"Installation of `tensorflow-probability` complete.\")\n",
    "elif TFP_Installation == \"System\":\n",
    "  pass\n",
    "else:\n",
    "  raise ValueError(\"Selection Error: Please select a valid \"\n",
    "                   \"installation option.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZ0MdF1j8WJf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/f1/172770d86e8cd3b531b73ccb2ba5cf285ea78937ab857bd958a77ed247e3/tensorflow_datasets-2.1.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1MB 3.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt in /home/simon/anaconda3/envs/tensorflow-gpu/lib/python3.7/site-packages (from tensorflow_datasets) (1.11.2)\n",
      "Requirement already satisfied: six in /home/simon/anaconda3/envs/tensorflow-gpu/lib/python3.7/site-packages (from tensorflow_datasets) (1.13.0)\n",
      "Requirement already satisfied: absl-py in /home/simon/anaconda3/envs/tensorflow-gpu/lib/python3.7/site-packages (from tensorflow_datasets) (0.9.0)\n",
      "Collecting promise (from tensorflow_datasets)\n",
      "  Downloading https://files.pythonhosted.org/packages/cf/9c/fb5d48abfe5d791cd496e4242ebcf87a4bb2e0c3dcd6e0ae68c11426a528/promise-2.3.tar.gz\n",
      "Collecting dill (from tensorflow_datasets)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 9.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: future in /home/simon/anaconda3/envs/tensorflow-gpu/lib/python3.7/site-packages (from tensorflow_datasets) (0.17.1)\n",
      "Requirement already satisfied: termcolor in /home/simon/anaconda3/envs/tensorflow-gpu/lib/python3.7/site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied: numpy in /home/simon/anaconda3/envs/tensorflow-gpu/lib/python3.7/site-packages (from tensorflow_datasets) (1.17.4)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /home/simon/anaconda3/envs/tensorflow-gpu/lib/python3.7/site-packages (from tensorflow_datasets) (19.1.0)\n",
      "Collecting tensorflow-metadata (from tensorflow_datasets)\n",
      "  Downloading https://files.pythonhosted.org/packages/3c/aa/c4c3c9339fbe9d46edd390789d7033b4fa89e9f566d5723576dfdd3ed18e/tensorflow_metadata-0.21.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm in /home/simon/anaconda3/envs/tensorflow-gpu/lib/python3.7/site-packages (from tensorflow_datasets) (4.32.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/simon/anaconda3/envs/tensorflow-gpu/lib/python3.7/site-packages (from tensorflow_datasets) (3.11.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/simon/anaconda3/envs/tensorflow-gpu/lib/python3.7/site-packages (from tensorflow_datasets) (2.22.0)\n",
      "Collecting googleapis-common-protos (from tensorflow-metadata->tensorflow_datasets)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/46/168fd780f594a4d61122f7f3dc0561686084319ad73b4febbf02ae8b32cf/googleapis-common-protos-1.51.0.tar.gz\n",
      "Requirement already satisfied: setuptools in /home/simon/anaconda3/envs/tensorflow-gpu/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow_datasets) (42.0.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/simon/anaconda3/envs/tensorflow-gpu/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/simon/anaconda3/envs/tensorflow-gpu/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/simon/anaconda3/envs/tensorflow-gpu/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.25.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/simon/anaconda3/envs/tensorflow-gpu/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (2019.11.28)\n",
      "Building wheels for collected packages: promise, dill, googleapis-common-protos\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/simon/.cache/pip/wheels/19/49/34/c3c1e78bcb954c49e5ec0d31784fe63d14d427f316b12fbde9\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/simon/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n",
      "  Building wheel for googleapis-common-protos (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/simon/.cache/pip/wheels/2c/f9/7f/6eb87e636072bf467e25348bbeb96849333e6a080dca78f706\n",
      "Successfully built promise dill googleapis-common-protos\n",
      "Installing collected packages: promise, dill, googleapis-common-protos, tensorflow-metadata, tensorflow-datasets\n",
      "Successfully installed dill-0.3.1.1 googleapis-common-protos-1.51.0 promise-2.3 tensorflow-datasets-2.1.0 tensorflow-metadata-0.21.1\n"
     ]
    }
   ],
   "source": [
    "#@title Import { display-mode: \"form\" }\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "tfpl = tfp.layers\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7nnwjUdVoWN2"
   },
   "source": [
    "### Make things Fast!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2CK9RaDcoYPG"
   },
   "source": [
    "Before we dive in, let's make sure we're using a GPU for this demo.  \n",
    "\n",
    "To do this, select \"Runtime\" -> \"Change runtime type\" -> \"Hardware accelerator\" -> \"GPU\".\n",
    "\n",
    "The following snippet will verify that we have access to a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qP_4Xr8vpA42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: GPU device not found.\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
    "  print('WARNING: GPU device not found.')\n",
    "else:\n",
    "  print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FJRBc_S0ppfE"
   },
   "source": [
    "Note: if for some reason you cannot access a GPU, this colab will still work. (Training will just take longer.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N8Shtn_e99XC"
   },
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "daPl6ycN9cD3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset mnist/3.0.0 (download: 11.06 MiB, generated: Unknown size, total: 11.06 MiB) to /home/simon/tensorflow_datasets/mnist/3.0.0...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
      "local data directory. If you'd instead prefer to read directly from our public\n",
      "GCS bucket (recommended if you're running on GCP), you can instead set\n",
      "data_dir=gs://tfds-data/datasets.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b45f5e8f924ce0b5cc2bd188a7f8fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Dl Completed...', max=4, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1mDataset mnist downloaded and prepared to /home/simon/tensorflow_datasets/mnist/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "datasets, datasets_info = tfds.load(name='mnist',\n",
    "                                    with_info=True,\n",
    "                                    as_supervised=False)\n",
    "\n",
    "def _preprocess(sample):\n",
    "  image = tf.cast(sample['image'], tf.float32) / 255.  # Scale to unit interval.\n",
    "  image = image < tf.random.uniform(tf.shape(image))   # Randomly binarize.\n",
    "  return image, image\n",
    "\n",
    "train_dataset = (datasets['train']\n",
    "                 .map(_preprocess)\n",
    "                 .batch(256)\n",
    "                 .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "                 .shuffle(int(10e3)))\n",
    "eval_dataset = (datasets['test']\n",
    "                .map(_preprocess)\n",
    "                .batch(256)\n",
    "                .prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZPKblOe58Hql"
   },
   "source": [
    "Note that _preprocess() above returns `image, image` rather than just `image` because Keras is set up for discriminative models with an (example, label) input format, i.e. $p_\\theta(y|x)$. Since the goal of the VAE is to recover the input x from x itself (i.e. $p_\\theta(x|x)$), the data pair is (example, example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CI-VFyp8-BIa"
   },
   "source": [
    "### VAE Code Golf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MKgRI5eoS2rx"
   },
   "source": [
    "#### Specify model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rd3Voa64_Gtv"
   },
   "outputs": [],
   "source": [
    "input_shape = datasets_info.features['image'].shape\n",
    "encoded_size = 16\n",
    "base_depth = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9d7Jbm66FN_u"
   },
   "outputs": [],
   "source": [
    "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(encoded_size), scale=1),\n",
    "                        reinterpreted_batch_ndims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eRHjRtAL-e33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/simon/anaconda3/envs/tensorflow-gpu/lib/python3.7/site-packages/tensorflow/python/ops/linalg/linear_operator_lower_triangular.py:158: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not pass `graph_parents`.  They will  no longer be used.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/simon/anaconda3/envs/tensorflow-gpu/lib/python3.7/site-packages/tensorflow/python/ops/linalg/linear_operator_lower_triangular.py:158: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not pass `graph_parents`.  They will  no longer be used.\n"
     ]
    }
   ],
   "source": [
    "encoder = tfk.Sequential([\n",
    "    tfkl.InputLayer(input_shape=input_shape),\n",
    "    tfkl.Lambda(lambda x: tf.cast(x, tf.float32) - 0.5),\n",
    "    tfkl.Conv2D(base_depth, 5, strides=1,\n",
    "                padding='same', activation=tf.nn.leaky_relu),\n",
    "    tfkl.Conv2D(base_depth, 5, strides=2,\n",
    "                padding='same', activation=tf.nn.leaky_relu),\n",
    "    tfkl.Conv2D(2 * base_depth, 5, strides=1,\n",
    "                padding='same', activation=tf.nn.leaky_relu),\n",
    "    tfkl.Conv2D(2 * base_depth, 5, strides=2,\n",
    "                padding='same', activation=tf.nn.leaky_relu),\n",
    "    tfkl.Conv2D(4 * encoded_size, 7, strides=1,\n",
    "                padding='valid', activation=tf.nn.leaky_relu),\n",
    "    tfkl.Flatten(),\n",
    "    tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(encoded_size),\n",
    "               activation=None),\n",
    "    tfpl.MultivariateNormalTriL(\n",
    "        encoded_size,\n",
    "        activity_regularizer=tfpl.KLDivergenceRegularizer(prior)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "baP--pt6-ewK"
   },
   "outputs": [],
   "source": [
    "decoder = tfk.Sequential([\n",
    "    tfkl.InputLayer(input_shape=[encoded_size]),\n",
    "    tfkl.Reshape([1, 1, encoded_size]),\n",
    "    tfkl.Conv2DTranspose(2 * base_depth, 7, strides=1,\n",
    "                         padding='valid', activation=tf.nn.leaky_relu),\n",
    "    tfkl.Conv2DTranspose(2 * base_depth, 5, strides=1,\n",
    "                         padding='same', activation=tf.nn.leaky_relu),\n",
    "    tfkl.Conv2DTranspose(2 * base_depth, 5, strides=2,\n",
    "                         padding='same', activation=tf.nn.leaky_relu),\n",
    "    tfkl.Conv2DTranspose(base_depth, 5, strides=1,\n",
    "                         padding='same', activation=tf.nn.leaky_relu),\n",
    "    tfkl.Conv2DTranspose(base_depth, 5, strides=2,\n",
    "                         padding='same', activation=tf.nn.leaky_relu),\n",
    "    tfkl.Conv2DTranspose(base_depth, 5, strides=1,\n",
    "                         padding='same', activation=tf.nn.leaky_relu),\n",
    "    tfkl.Conv2D(filters=1, kernel_size=5, strides=1,\n",
    "                padding='same', activation=None),\n",
    "    tfkl.Flatten(),\n",
    "    tfpl.IndependentBernoulli(input_shape, tfd.Bernoulli.logits),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7itugvZVLyWL"
   },
   "outputs": [],
   "source": [
    "vae = tfk.Model(inputs=encoder.inputs,\n",
    "                outputs=decoder(encoder.outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        25632     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 64)          102464    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 1, 64)          200768    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 152)               9880      \n",
      "_________________________________________________________________\n",
      "multivariate_normal_tri_l (M ((None, 16), (None, 16))  0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 28, 28, 1)         358465    \n",
      "=================================================================\n",
      "Total params: 749,305\n",
      "Trainable params: 749,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ckYuzfILkVb"
   },
   "source": [
    "#### Do inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "height": 590
    },
    "colab_type": "code",
    "id": "e7f1u-Ya-axQ",
    "outputId": "e989c831-6075-4ebd-b628-b9f80e820a90"
   },
   "outputs": [],
   "source": [
    "negloglik = lambda x, rv_x: -rv_x.log_prob(x)\n",
    "\n",
    "vae.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3),\n",
    "            loss=negloglik)\n",
    "\n",
    "_ = vae.fit(train_dataset,\n",
    "            epochs=15,\n",
    "            validation_data=eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hC4rNz9t_zpo"
   },
   "source": [
    "### Look Ma, No ~~Hands~~Tensors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ZqfOYMP_2p_"
   },
   "outputs": [],
   "source": [
    "# We'll just examine ten random digits.\n",
    "x = next(iter(eval_dataset))[0][:10]\n",
    "xhat = vae(x)\n",
    "assert isinstance(xhat, tfd.Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "MM7wW4S2OrBt"
   },
   "outputs": [],
   "source": [
    "#@title Image Plot Util\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_imgs(x, y=None):\n",
    "  if not isinstance(x, (np.ndarray, np.generic)):\n",
    "    x = np.array(x)\n",
    "  plt.ioff()\n",
    "  n = x.shape[0]\n",
    "  fig, axs = plt.subplots(1, n, figsize=(n, 1))\n",
    "  if y is not None:\n",
    "    fig.suptitle(np.argmax(y, axis=1))\n",
    "  for i in xrange(n):\n",
    "    axs.flat[i].imshow(x[i].squeeze(), interpolation='none', cmap='gray')\n",
    "    axs.flat[i].axis('off')\n",
    "  plt.show()\n",
    "  plt.close()\n",
    "  plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "height": 428
    },
    "colab_type": "code",
    "id": "ow7rfh6YLLx1",
    "outputId": "29c2f6a9-f53b-43bc-9d09-155a699d9be7"
   },
   "outputs": [],
   "source": [
    "print('Originals:')\n",
    "display_imgs(x)\n",
    "\n",
    "print('Decoded Random Samples:')\n",
    "display_imgs(xhat.sample())\n",
    "\n",
    "print('Decoded Modes:')\n",
    "display_imgs(xhat.mode())\n",
    "\n",
    "print('Decoded Means:')\n",
    "display_imgs(xhat.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C3_5HPUCQpYO"
   },
   "outputs": [],
   "source": [
    "# Now, let's generate ten never-before-seen digits.\n",
    "z = prior.sample(10)\n",
    "xtilde = decoder(z)\n",
    "assert isinstance(xtilde, tfd.Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "height": 325
    },
    "colab_type": "code",
    "id": "_jMPwz8r9pYX",
    "outputId": "19f46823-9fa5-434b-a4f7-e9ffd4f250ab"
   },
   "outputs": [],
   "source": [
    "print('Randomly Generated Samples:')\n",
    "display_imgs(xtilde.sample())\n",
    "\n",
    "print('Randomly Generated Modes:')\n",
    "display_imgs(xtilde.mode())\n",
    "\n",
    "print('Randomly Generated Means:')\n",
    "display_imgs(xtilde.mean())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Probabilistic_Layers_VAE.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
