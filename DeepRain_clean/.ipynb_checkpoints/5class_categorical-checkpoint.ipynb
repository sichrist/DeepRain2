{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from Models.Loss import NLL\n",
    "from Models.Distributions import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from Utils.Dataset import getData\n",
    "from Utils.transform import cutOut,LinBin,Normalize,NormalizePerImage\n",
    "from tensorflow.keras.callbacks import *\n",
    "from Models.Utils import *\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs:\", len(physical_devices))\n",
    "gpu = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_class_categorical(input_shape,\n",
    "                          activation_hidden=\"relu\"):\n",
    "\n",
    "\n",
    "    inputs = Input(shape=input_shape) \n",
    "\n",
    "    conv01 = Conv2D(20, kernel_size=(3, 3), padding=\"same\")(inputs)       # 10 x 64x64\n",
    "    conv01 = Activation(activation_hidden)(conv01)\n",
    "    conv01_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv01)            # 10 x 32x32\n",
    "\n",
    "\n",
    "    conv02 = Conv2D(25, kernel_size=(3, 3), padding=\"same\")(conv01_pool)  # 20 x 32x32\n",
    "    conv02 = Activation(activation_hidden)(conv02)\n",
    "    conv02_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv02)            # 20 x 16x16\n",
    "\n",
    "\n",
    "    conv03 = Conv2D(25, kernel_size=(3, 3), padding=\"same\")(conv02_pool)  # 20 x 16x16\n",
    "    conv03 = Activation(activation_hidden)(conv03)\n",
    "    conv03_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv03)            # 20 x 8x8\n",
    "\n",
    "\n",
    "    conv04 = Conv2D(25, kernel_size=(3, 3), padding=\"same\")(conv03_pool)  # 20 x 8x8\n",
    "    conv04 = Activation(activation_hidden)(conv04)\n",
    "    conv04_pool = MaxPooling2D((2, 2), strides=(2, 2))(conv04)            # 20 x 4x4\n",
    "\n",
    "\n",
    "    ### UPSAMPLING:\n",
    "    up04 = UpSampling2D((2, 2))(conv04_pool)    # 20 x 8x8\n",
    "    up04 = concatenate([conv04, up04], axis=3)  # 20+20 x 8x8\n",
    "\n",
    "\n",
    "    up03 = UpSampling2D((2, 2))(up04)           # 40 x 16x16\n",
    "    up03 = concatenate([conv03, up03], axis=3)  # 20+40 x 16x16\n",
    "\n",
    "\n",
    "    up02 = UpSampling2D((2, 2))(up03)           # 60 x 32x32\n",
    "    up02 = concatenate([conv02, up02], axis=3)  # 20+60 x 32x32\n",
    "\n",
    "    \n",
    "    up01 = UpSampling2D((2, 2))(up02)           # 80 x 64x64\n",
    "    up01 = concatenate([conv01, up01], axis=3)  # 10+80 x 64x64\n",
    "\n",
    "    \n",
    "    layer = Conv2D(1, (7, 7), activation=\"relu\")(up01)  # 1 x 64x64\n",
    "\n",
    "\n",
    "    prob = Flatten()(layer)\n",
    "    \n",
    "    prob      = Dense(256)(prob)\n",
    "    \n",
    "\n",
    "    prob = Dense(50*50*5,activation=\"linear\")(prob)\n",
    "    \n",
    "    prob = tf.keras.layers.Reshape((50,50,1,5))(prob)\n",
    "\n",
    "    \n",
    "    prob = tf.math.softmax(prob,axis=-1)\n",
    "    #prob = prob)\n",
    "    #input_dist= tf.concat([cat,count,prob],axis=-1)\n",
    "    \n",
    "    output_dist = tfp.layers.DistributionLambda(\n",
    "        name=\"DistributionLayer\",\n",
    "        make_distribution_fn=lambda t: tfp.distributions.Independent(\n",
    "        tfd.Categorical(logits=tf.math.log(t[...,:,:,:]))\n",
    "        ,name=\"categorical\",reinterpreted_batch_ndims=0 ))\n",
    "    \n",
    "    #output_dist = tfp.layers.DistributionLambda(tfd.Categorical,name=\"categorical\"))\n",
    "    \n",
    "    \n",
    "\n",
    "    output = output_dist(prob)\n",
    "    #output = tf.math.softmax(prob,axis=-1)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "DIMENSION = (64,64)\n",
    "CHANNELS = 5\n",
    "MODELPATH = \"./Models_weights\"\n",
    "MODELNAME = \"five_class_categorical\"\n",
    "\n",
    "\n",
    "\n",
    "def getModel():\n",
    "    modelpath = MODELPATH\n",
    "    modelname = MODELNAME\n",
    "\n",
    "    \n",
    "    if not os.path.exists(modelpath):\n",
    "            os.mkdir(modelpath)\n",
    "\n",
    "    modelpath = os.path.join(modelpath,modelname)\n",
    "\n",
    "    if not os.path.exists(modelpath):\n",
    "        os.mkdir(modelpath)\n",
    "\n",
    "    \n",
    "    input_shape = (*DIMENSION,CHANNELS)\n",
    "\n",
    "    model = five_class_categorical(\n",
    "                input_shape=input_shape\n",
    "                )\n",
    "\n",
    "    y_transform = [cutOut([7,57,7,57]),LinBin(56)]\n",
    "    x_transform = [Normalize(0.007742631458799244, 0.015872015890555563)]\n",
    "    #x_transform = [NormalizePerImage()]\n",
    "\n",
    "    \n",
    "    train,test = getData(BATCH_SIZE,\n",
    "                         DIMENSION,CHANNELS,\n",
    "                         timeToPred=10,\n",
    "                         y_transform=y_transform,\n",
    "                         x_transform=x_transform)\n",
    "    \n",
    "    \n",
    "    def NLL(y_true, y_hat):\n",
    "        return -y_hat.log_prob(y_true)\n",
    "\n",
    "    #neg_log_likelihood = lambda x, rv_x: tf.math.reduce_mean(-rv_x.log_prob(x))\n",
    "    \n",
    "    model.compile(loss=NLL,\n",
    "                  optimizer=Adam( lr= 1e-2 ))\n",
    "    model.summary()\n",
    "    modelpath_h5 = os.path.join(modelpath,\n",
    "                            modelname+'-{epoch:03d}-{loss:03f}-{val_loss:03f}.h5')\n",
    "\n",
    "    checkpoint = ModelCheckpoint(modelpath_h5,\n",
    "                                 verbose=0,\n",
    "                                 monitor='val_loss',\n",
    "                                 save_best_only=True,\n",
    "                                 mode='auto')\n",
    "\n",
    "    return model,checkpoint,modelpath,train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c8e2791f806e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodelname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMODELNAME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodelpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-3110e93c9fe3>\u001b[0m in \u001b[0;36mgetModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m                          \u001b[0mtimeToPred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                          \u001b[0my_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                          x_transform=x_transform)\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_transform' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "modelpath = MODELPATH\n",
    "modelname = MODELNAME\n",
    "\n",
    "model,checkpoint,modelpath,train,test = getModel()\n",
    "\n",
    "\n",
    "history_path = os.path.join(modelpath,modelname+\"_history\")\n",
    "laststate = getBestState(modelpath,history_path)\n",
    "test.setWiggle_off()\n",
    "train.setWiggle_off()\n",
    "\n",
    "print(model(train[0][0]))\n",
    "#print(model(train[0][0]).prob(train[0][1]))\n",
    "\n",
    "if laststate:\n",
    "    epoch = laststate[\"epoch\"]\n",
    "    model.load_weights(laststate[\"modelpath\"])\n",
    "\n",
    "\n",
    "    loss = model.evaluate(x=test, verbose=2)\n",
    "    print(\"Restored model, loss: {:5.5f}\".format(loss))\n",
    "\n",
    "    history = model.fit(train,\n",
    "                        validation_data = test,\n",
    "                        shuffle         = True,\n",
    "                        epochs          = 100+epoch,\n",
    "                        initial_epoch   = epoch,\n",
    "                        batch_size      = BATCH_SIZE,\n",
    "                        callbacks       = checkpoint)\n",
    "\n",
    "    history = mergeHist(laststate[\"history\"],history.history)\n",
    "\n",
    "else:\n",
    "    history = model.fit(train,\n",
    "                        validation_data = test,\n",
    "                        shuffle         = True,\n",
    "                        epochs          = 100,\n",
    "                        batch_size      = BATCH_SIZE,\n",
    "                        callbacks       = checkpoint)\n",
    "\n",
    "    history = history.history\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "saveHistory(history_path,history)\n",
    "plotHistory(history,history_path,title=\"five_class_categoricall NLL-loss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
